#!/usr/bin/env python3

"""
AnÃ¡lisis AcadÃ©mico: Profundidad Relativa vs Absoluta
====================================================
Clase magistral sobre las diferencias entre tipos de profundidad en pose estimation
"""

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

def analyze_depth_distribution(pose_data, title=""):
    """Analiza la distribuciÃ³n de profundidad en los datos"""
    print(f"\nğŸ“Š ANÃLISIS DE PROFUNDIDAD: {title}")
    print("=" * 60)
    
    # Extraer coordenadas Z (profundidad)
    z_coords = pose_data[..., 2]
    
    if len(pose_data.shape) == 3:  # Multiple poses
        z_coords = z_coords.flatten()
    
    unique_z = np.unique(z_coords)
    
    print(f"ğŸ’ Valores Ãºnicos de Z: {len(unique_z)}")
    print(f"ğŸ“ Rango Z: [{z_coords.min():.1f}, {z_coords.max():.1f}]")
    print(f"ğŸ“ DesviaciÃ³n estÃ¡ndar: {z_coords.std():.1f}")
    print(f"ğŸ“Š Media: {z_coords.mean():.1f}")
    
    if len(unique_z) <= 10:
        print(f"ğŸ” Valores exactos: {unique_z}")
    
    # AnÃ¡lisis por frame si es mÃºltiple
    if len(pose_data.shape) == 3:
        print(f"\nğŸ“ˆ ANÃLISIS POR FRAME:")
        for i in range(min(5, pose_data.shape[0])):
            frame_z = pose_data[i, :, 2]
            unique_frame_z = np.unique(frame_z)
            print(f"   Frame {i}: {len(unique_frame_z)} valores Ãºnicos, rango [{frame_z.min():.1f}, {frame_z.max():.1f}]")
    
    return {
        'unique_count': len(unique_z),
        'range': (z_coords.min(), z_coords.max()),
        'std': z_coords.std(),
        'mean': z_coords.mean(),
        'values': unique_z if len(unique_z) <= 10 else None
    }

def create_depth_comparison_visualization():
    """Crea visualizaciÃ³n educativa de tipos de profundidad"""
    
    fig = plt.figure(figsize=(20, 12))
    
    # Esqueleto ejemplo simplificado (5 puntos)
    # Persona parada de frente
    person_2d = np.array([
        [100, 50],   # cabeza
        [100, 100],  # cuello/torso
        [80, 120],   # brazo izq
        [120, 120],  # brazo der
        [100, 150]   # cadera
    ])
    
    # 1. Profundidad Relativa (ConvNeXtPose)
    ax1 = fig.add_subplot(221, projection='3d')
    
    # Profundidades relativas anatÃ³micamente correctas
    relative_z = np.array([10, 0, 5, 5, -3])  # cabeza adelante, brazos medio, cadera atrÃ¡s
    
    person_3d_relative = np.column_stack([person_2d, relative_z])
    
    colors = ['red', 'green', 'blue', 'blue', 'orange']
    for i, (point, color) in enumerate(zip(person_3d_relative, colors)):
        ax1.scatter(point[0], point[1], point[2], c=color, s=100)
        ax1.text(point[0], point[1], point[2], f'J{i}', fontsize=8)
    
    # Conectar puntos
    connections = [(0,1), (1,2), (1,3), (1,4)]
    for i, j in connections:
        ax1.plot([person_3d_relative[i,0], person_3d_relative[j,0]],
                [person_3d_relative[i,1], person_3d_relative[j,1]],
                [person_3d_relative[i,2], person_3d_relative[j,2]], 'k-', alpha=0.5)
    
    ax1.set_title('PROFUNDIDAD RELATIVA\n(ConvNeXtPose)\nProporciones anatÃ³micas correctas')
    ax1.set_xlabel('X')
    ax1.set_ylabel('Y')
    ax1.set_zlabel('Z relativo')
    
    # 2. Sin profundidad absoluta (problema actual)
    ax2 = fig.add_subplot(222, projection='3d')
    
    # Todas las articulaciones a la misma profundidad absoluta
    absolute_z_constant = np.full(5, 800)  # 800mm de la cÃ¡mara
    person_3d_flat = np.column_stack([person_2d, absolute_z_constant])
    
    for i, (point, color) in enumerate(zip(person_3d_flat, colors)):
        ax2.scatter(point[0], point[1], point[2], c=color, s=100)
        ax2.text(point[0], point[1], point[2], f'J{i}', fontsize=8)
    
    for i, j in connections:
        ax2.plot([person_3d_flat[i,0], person_3d_flat[j,0]],
                [person_3d_flat[i,1], person_3d_flat[j,1]],
                [person_3d_flat[i,2], person_3d_flat[j,2]], 'k-', alpha=0.5)
    
    ax2.set_title('SIN PROFUNDIDAD ABSOLUTA\n(Problema actual)\nTodas las articulaciones planas')
    ax2.set_xlabel('X')
    ax2.set_ylabel('Y')
    ax2.set_zlabel('Z absoluto (mm)')
    
    # 3. Con RootNet - Profundidad absoluta correcta
    ax3 = fig.add_subplot(223, projection='3d')
    
    # RootNet proporciona profundidad absoluta base
    rootnet_depth = 800  # mm desde la cÃ¡mara
    # Combinamos: profundidad absoluta base + profundidad relativa
    person_3d_complete = np.column_stack([person_2d, rootnet_depth + relative_z])
    
    for i, (point, color) in enumerate(zip(person_3d_complete, colors)):
        ax3.scatter(point[0], point[1], point[2], c=color, s=100)
        ax3.text(point[0], point[1], point[2], f'J{i}', fontsize=8)
    
    for i, j in connections:
        ax3.plot([person_3d_complete[i,0], person_3d_complete[j,0]],
                [person_3d_complete[i,1], person_3d_complete[j,1]],
                [person_3d_complete[i,2], person_3d_complete[j,2]], 'k-', alpha=0.5)
    
    ax3.set_title('CON ROOTNET\n(SoluciÃ³n completa)\nProfundidad absoluta + relativa')
    ax3.set_xlabel('X')
    ax3.set_ylabel('Y')
    ax3.set_zlabel('Z absoluto (mm)')
    
    # 4. MÃºltiples personas (ventaja de RootNet)
    ax4 = fig.add_subplot(224, projection='3d')
    
    # Persona 1 cerca (600mm)
    person1_depth = 600
    person1_3d = np.column_stack([person_2d, person1_depth + relative_z])
    
    # Persona 2 lejos (1200mm)
    person2_2d = person_2d + np.array([150, 0])  # Desplazada en X
    person2_depth = 1200
    person2_3d = np.column_stack([person2_2d, person2_depth + relative_z])
    
    # Dibujar persona 1
    for i, point in enumerate(person1_3d):
        ax4.scatter(point[0], point[1], point[2], c='red', s=100, alpha=0.7)
    
    # Dibujar persona 2
    for i, point in enumerate(person2_3d):
        ax4.scatter(point[0], point[1], point[2], c='blue', s=100, alpha=0.7)
    
    ax4.set_title('MÃšLTIPLES PERSONAS\n(Ventaja principal de RootNet)\nPosicionamiento relativo correcto')
    ax4.set_xlabel('X')
    ax4.set_ylabel('Y')
    ax4.set_zlabel('Z absoluto (mm)')
    
    plt.tight_layout()
    return fig

def explain_advantages_disadvantages():
    """ExplicaciÃ³n acadÃ©mica de ventajas y desventajas"""
    
    print("\n" + "="*80)
    print("ğŸ“ ANÃLISIS ACADÃ‰MICO: VENTAJAS Y DESVENTAJAS")
    print("="*80)
    
    print("\nğŸ“š 1. PROFUNDIDAD RELATIVA (ConvNeXtPose)")
    print("-" * 50)
    print("âœ… VENTAJAS:")
    print("   â€¢ Mantiene proporciones anatÃ³micas correctas")
    print("   â€¢ Invariante a la distancia de la cÃ¡mara")
    print("   â€¢ Permite anÃ¡lisis de movimiento y postura")
    print("   â€¢ Eficiente computacionalmente")
    print("   â€¢ Robusto a cambios de escala")
    
    print("\nâŒ DESVENTAJAS:")
    print("   â€¢ No proporciona ubicaciÃ³n real en el espacio")
    print("   â€¢ No permite medidas mÃ©tricas absolutas")
    print("   â€¢ Insuficiente para aplicaciones de realidad aumentada")
    print("   â€¢ No resuelve oclusiones entre mÃºltiples personas")
    
    print("\nğŸ“š 2. PROFUNDIDAD ABSOLUTA (RootNet)")
    print("-" * 50)
    print("âœ… VENTAJAS:")
    print("   â€¢ UbicaciÃ³n real en coordenadas del mundo")
    print("   â€¢ Permite medidas mÃ©tricas (distancias, volÃºmenes)")
    print("   â€¢ Esencial para realidad aumentada/virtual")
    print("   â€¢ Resuelve ambigÃ¼edades entre mÃºltiples personas")
    print("   â€¢ Permite navegaciÃ³n y planificaciÃ³n de rutas")
    
    print("\nâŒ DESVENTAJAS:")
    print("   â€¢ MÃ¡s complejo computacionalmente")
    print("   â€¢ Requiere calibraciÃ³n de cÃ¡mara")
    print("   â€¢ Sensible a condiciones de iluminaciÃ³n")
    print("   â€¢ Puede ser menos preciso en poses complejas")
    
    print("\nğŸ“š 3. COMBINACIÃ“N Ã“PTIMA (ConvNeXtPose + RootNet)")
    print("-" * 50)
    print("âœ… VENTAJAS COMBINADAS:")
    print("   â€¢ Proporciones anatÃ³micas + ubicaciÃ³n real")
    print("   â€¢ MÃ¡xima precisiÃ³n en poses individuales")
    print("   â€¢ Capacidad para mÃºltiples personas")
    print("   â€¢ Aplicable a realidad aumentada")
    print("   â€¢ AnÃ¡lisis biomecÃ¡nico completo")

def demonstrate_use_cases():
    """Demuestra casos de uso especÃ­ficos"""
    
    print("\n" + "="*80)
    print("ğŸ¥ CASOS DE USO PRÃCTICOS")
    print("="*80)
    
    print("\nğŸ’Š CASO 1: ANÃLISIS MÃ‰DICO - RehabilitaciÃ³n")
    print("-" * 50)
    print("ğŸ“‹ Requisito: Medir Ã¡ngulos de flexiÃ³n de rodilla")
    print("ğŸ”§ SoluciÃ³n: PROFUNDIDAD RELATIVA suficiente")
    print("ğŸ’¡ RazÃ³n: Los Ã¡ngulos son independientes de la distancia absoluta")
    print("ğŸ“Š Ejemplo: FlexiÃ³n 90Â° es 90Â° independiente si el paciente estÃ¡ a 1m o 2m")
    
    print("\nğŸƒ CASO 2: ANÃLISIS DEPORTIVO - TÃ©cnica de salto")
    print("-" * 50)
    print("ğŸ“‹ Requisito: Altura mÃ¡xima del salto en metros")
    print("ğŸ”§ SoluciÃ³n: PROFUNDIDAD ABSOLUTA necesaria")
    print("ğŸ’¡ RazÃ³n: Necesitamos medidas mÃ©tricas reales")
    print("ğŸ“Š Ejemplo: Salto de 0.5m vs 0.8m requiere referencia absoluta")
    
    print("\nğŸ® CASO 3: REALIDAD AUMENTADA - Avatar virtual")
    print("-" * 50)
    print("ğŸ“‹ Requisito: Colocar objeto virtual en la mano")
    print("ğŸ”§ SoluciÃ³n: AMBAS profundidades necesarias")
    print("ğŸ’¡ RazÃ³n: UbicaciÃ³n precisa en espacio 3D real")
    print("ğŸ“Š Ejemplo: Mano a 0.8m de cÃ¡mara + 0.1m adelante del torso")
    
    print("\nğŸ‘¥ CASO 4: MÃšLTIPLES PERSONAS - Distancia social")
    print("-" * 50)
    print("ğŸ“‹ Requisito: Medir distancia entre personas")
    print("ğŸ”§ SoluciÃ³n: PROFUNDIDAD ABSOLUTA esencial")
    print("ğŸ’¡ RazÃ³n: Profundidad relativa no resuelve separaciÃ³n entre personas")
    print("ğŸ“Š Ejemplo: Persona A a 2m, Persona B a 3m â†’ distancia 1m")

if __name__ == "__main__":
    print("ğŸ“ CLASE MAGISTRAL: PROFUNDIDAD EN POSE ESTIMATION")
    print("="*80)
    print("Profesor: AI Assistant")
    print("Materia: VisiÃ³n por Computadora Avanzada")
    print("Tema: AnÃ¡lisis de Profundidad en EstimaciÃ³n de Poses Humanas")
    
    # Cargar y analizar datos reales
    try:
        print("\nğŸ“Š ANÃLISIS DE DATOS EXPERIMENTALES")
        print("="*50)
        
        # Analizar datos individuales
        data_single = np.load('output_3d_coords.npz')
        if 'pose3d' in data_single.keys():
            pose_single = data_single['pose3d']
            result_single = analyze_depth_distribution(pose_single, "POSE INDIVIDUAL")
        
        # Analizar datos mÃºltiples
        data_multiple = np.load('all_3d_poses.npz')
        if 'poses' in data_multiple.keys():
            poses_multiple = data_multiple['poses']
            result_multiple = analyze_depth_distribution(poses_multiple, "MÃšLTIPLES POSES")
    
    except FileNotFoundError:
        print("âš ï¸ Archivos de datos no encontrados. Usando ejemplos teÃ³ricos.")
    
    # Crear visualizaciÃ³n educativa
    print("\nğŸ“ˆ GENERANDO VISUALIZACIÃ“N EDUCATIVA...")
    fig = create_depth_comparison_visualization()
    fig.savefig('depth_analysis_educational.png', dpi=150, bbox_inches='tight')
    print("ğŸ“¸ VisualizaciÃ³n guardada: depth_analysis_educational.png")
    
    # Explicaciones acadÃ©micas
    explain_advantages_disadvantages()
    demonstrate_use_cases()
    
    print("\n" + "="*80)
    print("ğŸ¯ CONCLUSIÃ“N DE LA CLASE")
    print("="*80)
    print("1. ConvNeXtPose proporciona PROFUNDIDAD RELATIVA (anatÃ³mica)")
    print("2. RootNet proporciona PROFUNDIDAD ABSOLUTA (ubicaciÃ³n real)")
    print("3. AMBAS son necesarias para aplicaciones completas")
    print("4. Una sola persona AÃšN se beneficia de profundidad absoluta")
    print("5. La combinaciÃ³n es superior a cualquier enfoque individual")
    
    print("\nğŸ’¡ RESPUESTA A TU PREGUNTA:")
    print("Incluso con una sola persona, RootNet proporciona:")
    print("â€¢ UbicaciÃ³n real en el espacio (no solo proporciones)")
    print("â€¢ Capacidad de medidas mÃ©tricas absolutas")
    print("â€¢ Compatibilidad con aplicaciones de realidad aumentada")
    print("â€¢ Base para futuras expansiones a mÃºltiples personas")
    
    plt.close()