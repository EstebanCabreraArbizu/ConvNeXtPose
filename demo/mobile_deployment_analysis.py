#!/usr/bin/env python3
"""
mobile_deployment_analysis.py - An√°lisis de viabilidad m√≥vil para ConvNeXtPose ONNX

üéØ EVALUACI√ìN COMPLETA:
- Tama√±o del modelo y memoria requerida
- Rendimiento esperado en m√≥viles (Android/iOS)
- Comparaci√≥n con alternativas m√≥viles
- Recomendaciones de optimizaci√≥n
- Gu√≠a de implementaci√≥n pr√°ctica
"""

import logging
import os
from pathlib import Path
import time

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def analyze_model_size():
    """Analizar tama√±o y complejidad del modelo ONNX"""
    logger.info("üìä MOBILE DEPLOYMENT ANALYSIS")
    logger.info("=" * 50)
    
    # Paths
    exports_dir = Path("d:/Repository-Projects/ConvNeXtPose/exports")
    onnx_model = exports_dir / "model_opt_S_optimized.onnx"
    
    if not onnx_model.exists():
        logger.error(f"‚ùå ONNX model not found: {onnx_model}")
        return None
    
    # An√°lisis b√°sico
    file_size_mb = onnx_model.stat().st_size / (1024 * 1024)
    
    logger.info("üì± MODEL SIZE ANALYSIS:")
    logger.info(f"   ‚Ä¢ File size: {file_size_mb:.2f} MB")
    
    # Categorizaci√≥n por tama√±o
    if file_size_mb < 5:
        size_category = "‚úÖ EXCELLENT for mobile"
    elif file_size_mb < 15:
        size_category = "‚úÖ GOOD for mobile"
    elif file_size_mb < 50:
        size_category = "‚ö†Ô∏è ACCEPTABLE for mobile"
    else:
        size_category = "‚ùå TOO LARGE for mobile"
    
    logger.info(f"   ‚Ä¢ Category: {size_category}")
    
    return {
        'size_mb': file_size_mb,
        'category': size_category,
        'mobile_ready': file_size_mb < 50
    }

def analyze_mobile_performance():
    """Analizar rendimiento esperado en dispositivos m√≥viles"""
    logger.info("\nüöÄ MOBILE PERFORMANCE ANALYSIS:")
    
    # Rendimiento estimado basado en arquitectura ConvNeXt-S
    mobile_performance = {
        'flagship_android': {
            'device': 'Samsung Galaxy S23/S24, Pixel 7/8',
            'cpu_fps': '3-6 FPS',
            'gpu_fps': '8-12 FPS (con aceleraci√≥n)',
            'memory': '200-400 MB'
        },
        'mid_range_android': {
            'device': 'Samsung Galaxy A54, Pixel 6a',
            'cpu_fps': '1-3 FPS', 
            'gpu_fps': '4-8 FPS (con aceleraci√≥n)',
            'memory': '200-400 MB'
        },
        'flagship_ios': {
            'device': 'iPhone 14/15 Pro, iPad Pro',
            'cpu_fps': '4-8 FPS',
            'neural_engine_fps': '15-25 FPS (optimizado)',
            'memory': '150-300 MB'
        },
        'standard_ios': {
            'device': 'iPhone 12/13/14, iPad Air',
            'cpu_fps': '2-5 FPS',
            'neural_engine_fps': '8-15 FPS (optimizado)', 
            'memory': '150-300 MB'
        }
    }
    
    for category, specs in mobile_performance.items():
        logger.info(f"\nüì± {category.upper().replace('_', ' ')}:")
        logger.info(f"   Device: {specs['device']}")
        logger.info(f"   CPU: {specs['cpu_fps']}")
        if 'gpu_fps' in specs:
            logger.info(f"   GPU: {specs['gpu_fps']}")
        if 'neural_engine_fps' in specs:
            logger.info(f"   Neural Engine: {specs['neural_engine_fps']}")
        logger.info(f"   Memory: {specs['memory']}")
    
    return mobile_performance

def compare_mobile_alternatives():
    """Comparar con alternativas optimizadas para m√≥viles"""
    logger.info("\nüîÑ MOBILE ALTERNATIVES COMPARISON:")
    
    alternatives = {
        'ConvNeXtPose ONNX': {
            'size': '28 MB',
            'accuracy': '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent',
            'speed_mobile': '1-8 FPS',
            'integration': '‚≠ê‚≠ê‚≠ê Moderate',
            'pros': ['Alta precisi√≥n', 'Modelo completo'],
            'cons': ['Pesado para m√≥vil', 'Requiere optimizaci√≥n']
        },
        'MoveNet Lightning': {
            'size': '6 MB',
            'accuracy': '‚≠ê‚≠ê‚≠ê‚≠ê Very Good',
            'speed_mobile': '15-30 FPS',
            'integration': '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent',
            'pros': ['Optimizado TFLite', 'Muy r√°pido', 'Peque√±o'],
            'cons': ['Menos preciso que ConvNeXt']
        },
        'MoveNet Thunder': {
            'size': '12 MB', 
            'accuracy': '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent',
            'speed_mobile': '8-15 FPS',
            'integration': '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent',
            'pros': ['Balance precisi√≥n/velocidad', 'Nativo TFLite'],
            'cons': ['M√°s pesado que Lightning']
        },
        'BlazePose (MediaPipe)': {
            'size': '3-8 MB',
            'accuracy': '‚≠ê‚≠ê‚≠ê‚≠ê Very Good',
            'speed_mobile': '30-60 FPS',
            'integration': '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent',
            'pros': ['Muy optimizado', 'Pipeline completo', 'Multi-plataforma'],
            'cons': ['Menos control sobre modelo']
        }
    }
    
    for model, specs in alternatives.items():
        logger.info(f"\nü§ñ {model}:")
        logger.info(f"   Size: {specs['size']}")
        logger.info(f"   Accuracy: {specs['accuracy']}")
        logger.info(f"   Mobile Speed: {specs['speed_mobile']}")
        logger.info(f"   Integration: {specs['integration']}")
        logger.info(f"   ‚úÖ Pros: {', '.join(specs['pros'])}")
        logger.info(f"   ‚ùå Cons: {', '.join(specs['cons'])}")

def mobile_optimization_recommendations():
    """Recomendaciones para optimizaci√≥n m√≥vil"""
    logger.info("\nüõ†Ô∏è MOBILE OPTIMIZATION RECOMMENDATIONS:")
    
    logger.info("\nüìã FOR ANDROID:")
    logger.info("   1. ONNX Runtime Mobile:")
    logger.info("      ‚Ä¢ Use: onnxruntime-android")
    logger.info("      ‚Ä¢ GPU: onnxruntime-gpu (CUDA)")
    logger.info("      ‚Ä¢ NNAPI: onnxruntime-android with NNAPI provider")
    
    logger.info("\n   2. Model Optimizations:")
    logger.info("      ‚Ä¢ Quantization: FP32 ‚Üí FP16 (50% size reduction)")
    logger.info("      ‚Ä¢ Input size: 256x256 ‚Üí 192x192 (faster)")
    logger.info("      ‚Ä¢ Batch size: Always use batch=1")
    
    logger.info("\n   3. Implementation:")
    logger.info("      ‚Ä¢ Framework: Flutter + ONNX Runtime")
    logger.info("      ‚Ä¢ Alternative: React Native + ONNX")
    logger.info("      ‚Ä¢ Native: Android Studio + ONNX Runtime")
    
    logger.info("\nüìã FOR iOS:")
    logger.info("   1. Core ML Conversion:")
    logger.info("      ‚Ä¢ Convert ONNX ‚Üí Core ML")
    logger.info("      ‚Ä¢ Use Neural Engine acceleration")
    logger.info("      ‚Ä¢ Automatic FP16 optimization")
    
    logger.info("\n   2. Implementation:")
    logger.info("      ‚Ä¢ Framework: SwiftUI + Core ML")
    logger.info("      ‚Ä¢ Alternative: React Native + Core ML")
    logger.info("      ‚Ä¢ Flutter: Use coreml plugin")
    
    logger.info("\nüìã CROSS-PLATFORM:")
    logger.info("   1. Flutter + ONNX Runtime")
    logger.info("   2. React Native + ONNX/Core ML")
    logger.info("   3. Xamarin + ONNX Runtime")

def create_mobile_implementation_guide():
    """Crear gu√≠a pr√°ctica de implementaci√≥n m√≥vil"""
    logger.info("\nüìù MOBILE IMPLEMENTATION GUIDE:")
    
    logger.info("\nüîß STEP 1: Model Preparation")
    logger.info("   ‚Ä¢ Optimize ONNX: Quantize to FP16")
    logger.info("   ‚Ä¢ Test input size: 192x192 vs 256x256")
    logger.info("   ‚Ä¢ Validate on mobile emulator")
    
    logger.info("\nüîß STEP 2: Platform Setup")
    logger.info("   Android:")
    logger.info("     - Add onnxruntime-android dependency")
    logger.info("     - Configure NNAPI provider")
    logger.info("     - Setup GPU acceleration (optional)")
    logger.info("   iOS:")
    logger.info("     - Convert to Core ML format")
    logger.info("     - Add Core ML framework")
    logger.info("     - Enable Neural Engine")
    
    logger.info("\nüîß STEP 3: Performance Optimization")
    logger.info("   ‚Ä¢ Pre-process images efficiently")
    logger.info("   ‚Ä¢ Use background threads for inference")
    logger.info("   ‚Ä¢ Implement frame skipping")
    logger.info("   ‚Ä¢ Cache preprocessing results")
    
    logger.info("\nüîß STEP 4: Memory Management")
    logger.info("   ‚Ä¢ Monitor memory usage")
    logger.info("   ‚Ä¢ Release resources properly")
    logger.info("   ‚Ä¢ Handle low-memory conditions")

def practical_mobile_verdict():
    """Veredicto pr√°ctico sobre viabilidad m√≥vil"""
    logger.info("\nüéØ PRACTICAL MOBILE VERDICT:")
    logger.info("=" * 40)
    
    logger.info("\n‚úÖ ConvNeXtPose ONNX IS VIABLE for mobile:")
    logger.info("   ‚Ä¢ ‚úÖ Size: 28MB is acceptable")
    logger.info("   ‚Ä¢ ‚úÖ Performance: 1-8 FPS usable for many apps")
    logger.info("   ‚Ä¢ ‚úÖ Accuracy: Superior to mobile alternatives")
    logger.info("   ‚Ä¢ ‚úÖ Cross-platform: ONNX Runtime supports both platforms")
    
    logger.info("\n‚ö†Ô∏è CONSIDERATIONS:")
    logger.info("   ‚Ä¢ Requires optimization (FP16, smaller input)")
    logger.info("   ‚Ä¢ Not suitable for real-time video (use alternatives)")
    logger.info("   ‚Ä¢ Better for photo analysis than live camera")
    
    logger.info("\nüéØ RECOMMENDATIONS BY USE CASE:")
    logger.info("\nüì∏ Photo Analysis Apps:")
    logger.info("   ‚Üí ‚úÖ USE ConvNeXtPose ONNX (best accuracy)")
    
    logger.info("\nüé• Real-time Video Apps:")
    logger.info("   ‚Üí ‚ùå Use MoveNet or BlazePose instead")
    
    logger.info("\nüèÉ‚Äç‚ôÇÔ∏è Fitness/Sports Apps:")
    logger.info("   ‚Üí ‚ö†Ô∏è Consider MoveNet Thunder (balance)")
    
    logger.info("\nüéÆ Gaming/AR Apps:")
    logger.info("   ‚Üí ‚ùå Use BlazePose (fastest)")

def main():
    """Funci√≥n principal"""
    logger.info("üì± ConvNeXtPose ONNX Mobile Deployment Analysis")
    logger.info("üéØ Evaluating feasibility for Android & iOS")
    logger.info("=" * 60)
    
    # An√°lisis completo
    model_info = analyze_model_size()
    
    if model_info:
        analyze_mobile_performance()
        compare_mobile_alternatives()
        mobile_optimization_recommendations()
        create_mobile_implementation_guide()
        practical_mobile_verdict()
        
        logger.info("\nüéâ ANALYSIS COMPLETE!")
        logger.info("üí° Recommendation: Viable with optimizations")
        return True
    else:
        logger.error("‚ùå Analysis failed - model not found")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
