#!/usr/bin/env python3
"""
Script de comparaci√≥n entre v3 y v4 usando la misma imagen
"""

import sys
import os
import time
import cv2
import numpy as np
from pathlib import Path

# Add paths for imports
sys.path.insert(0, '/home/fabri/ConvNeXtPose/main')
sys.path.insert(0, '/home/fabri/ConvNeXtPose/common')
sys.path.insert(0, '/home/fabri/ConvNeXtPose/data')
sys.path.insert(0, '/home/fabri/ConvNeXtPose/demo')

# Suppress warnings
import warnings
warnings.filterwarnings("ignore")
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

print("üî¨ COMPARACI√ìN EXHAUSTIVA v3 vs v4")
print("="*50)

# Load test image
image_path = '/home/fabri/ConvNeXtPose/demo/input.jpg'
frame = cv2.imread(image_path)
if frame is None:
    print(f"‚ùå No se pudo cargar la imagen: {image_path}")
    sys.exit(1)

print(f"üì∏ Imagen de prueba: {frame.shape}")
print()

# ========================================
# V4 TESTING (ONNX)
# ========================================
print("üîß TESTING V4 (ONNX)...")
try:
    from convnext_realtime_v4_threading_fixed import ThreadSafeFrameProcessor
    
    # Create v4 processor
    v4_processor = ThreadSafeFrameProcessor(
        '/home/fabri/ConvNeXtPose/exports/model_opt_S.pth', 
        use_tflite=False
    )
    
    # Test v4
    start_time = time.time()
    v4_processor.add_frame(frame)
    
    # Wait for result
    v4_result = None
    max_wait = 5.0
    wait_start = time.time()
    
    while (time.time() - wait_start) < max_wait:
        result = v4_processor.get_result()
        if result:
            v4_result = result
            break
        time.sleep(0.1)
    
    v4_total_time = (time.time() - start_time) * 1000
    v4_stats = v4_processor.get_performance_stats()
    
    # Stop processor
    v4_processor.stop()
    
    if v4_result:
        frame_id, (pose_coords, root_depth) = v4_result
        print(f"‚úÖ V4 SUCCESS:")
        print(f"   Total time: {v4_total_time:.1f}ms")
        print(f"   Processing time: {v4_stats['avg_processing_time_ms']:.1f}ms")
        print(f"   Engine: {v4_stats['engine_type']}")
        print(f"   Pose shape: {pose_coords.shape}")
        print(f"   Root depth: {root_depth:.1f}mm")
        print(f"   Workers: {v4_stats['workers']}")
        print(f"   Cache hits: {v4_stats['cache_hits']}")
        v4_success = True
    else:
        print("‚ùå V4 FAILED")
        v4_success = False
        
except Exception as e:
    print(f"‚ùå V4 ERROR: {e}")
    v4_success = False

print()

# ========================================
# V4 TESTING (TFLite)
# ========================================
print("üîß TESTING V4 (TFLite)...")
try:
    from convnext_realtime_v4_threading_fixed import ThreadSafeFrameProcessor
    
    # Create v4 TFLite processor
    v4_tflite_processor = ThreadSafeFrameProcessor(
        '/home/fabri/ConvNeXtPose/exports/model_opt_S.pth', 
        use_tflite=True
    )
    
    # Test v4 TFLite
    start_time = time.time()
    v4_tflite_processor.add_frame(frame)
    
    # Wait for result
    v4_tflite_result = None
    max_wait = 10.0
    wait_start = time.time()
    
    while (time.time() - wait_start) < max_wait:
        result = v4_tflite_processor.get_result()
        if result:
            v4_tflite_result = result
            break
        time.sleep(0.1)
    
    v4_tflite_total_time = (time.time() - start_time) * 1000
    v4_tflite_stats = v4_tflite_processor.get_performance_stats()
    
    # Stop processor
    v4_tflite_processor.stop()
    
    if v4_tflite_result:
        frame_id, (pose_coords, root_depth) = v4_tflite_result
        print(f"‚úÖ V4 TFLite SUCCESS:")
        print(f"   Total time: {v4_tflite_total_time:.1f}ms")
        print(f"   Processing time: {v4_tflite_stats['avg_processing_time_ms']:.1f}ms")
        print(f"   Engine: {v4_tflite_stats['engine_type']}")
        print(f"   Pose shape: {pose_coords.shape}")
        print(f"   Root depth: {root_depth:.1f}mm")
        print(f"   Workers: {v4_tflite_stats['workers']}")
        print(f"   Cache hits: {v4_tflite_stats['cache_hits']}")
        v4_tflite_success = True
    else:
        print("‚ùå V4 TFLite FAILED")
        v4_tflite_success = False
        
except Exception as e:
    print(f"‚ùå V4 TFLite ERROR: {e}")
    v4_tflite_success = False

print()

# ========================================
# V3 CORE TESTING
# ========================================
print("üîß TESTING V3 CORE...")
try:
    # Import v3 core components
    import torch
    import torchvision.transforms as transforms
    from config import cfg
    from model import get_pose_net
    from dataset import generate_patch_image
    import utils.pose_utils as pose_utils
    
    # Setup v3 model manually
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = get_pose_net(cfg, is_train=False, joint_num=18)
    
    # Load model
    model_path = '/home/fabri/ConvNeXtPose/exports/model_opt_S.pth'
    state = torch.load(model_path, map_location=device)
    state_dict = state.get('network', state) 
    model.load_state_dict(state_dict, strict=False)
    model = model.to(device).eval()
    
    # Process frame (v3 style)
    start_time = time.time()
    
    h, w = frame.shape[:2]
    bbox = [0, 0, w, h]
    bbox_xywh = [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]]
    
    proc_bbox = pose_utils.process_bbox(np.array(bbox_xywh), w, h)
    if proc_bbox is not None:
        img_patch, img2bb_trans = generate_patch_image(frame, proc_bbox, False, 1.0, 0.0, False)
        
        # Ensure correct data type
        if img_patch.dtype != np.uint8:
            img_patch = (img_patch * 255).astype(np.uint8)
        
        # Transform for PyTorch
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=cfg.pixel_mean, std=cfg.pixel_std),
        ])
        
        from PIL import Image
        pil_img = Image.fromarray(cv2.cvtColor(img_patch, cv2.COLOR_BGR2RGB))
        input_tensor = transform(pil_img).unsqueeze(0).to(device)
        
        # Inference
        with torch.no_grad():
            pose_3d = model(input_tensor)
            pose_3d_np = pose_3d.cpu().numpy().squeeze()
        
        # Post-process coordinates (simplified)
        if len(pose_3d_np.shape) == 3:  # Heatmap format
            joint_num, output_h, output_w = pose_3d_np.shape
            heatmaps = pose_3d_np.reshape(joint_num, -1)
            max_indices = np.argmax(heatmaps, axis=1)
            pose_y = max_indices // output_w
            pose_x = max_indices % output_w
            pose_2d = np.stack([pose_x, pose_y], axis=1).astype(np.float32)
        else:
            pose_2d = pose_3d_np[:, :2]
        
        # Scale coordinates
        pose_2d[:, 0] = pose_2d[:, 0] / cfg.output_shape[1] * cfg.input_shape[1]
        pose_2d[:, 1] = pose_2d[:, 1] / cfg.output_shape[0] * cfg.input_shape[0]
        
        # Apply transformation
        pose_2d_homo = np.column_stack((pose_2d, np.ones(len(pose_2d))))
        img2bb_trans_full = np.vstack((img2bb_trans, [0, 0, 1]))
        
        try:
            final_coords = np.linalg.solve(img2bb_trans_full, pose_2d_homo.T).T[:, :2]
        except:
            final_coords = pose_2d
        
        v3_total_time = (time.time() - start_time) * 1000
        
        print(f"‚úÖ V3 CORE SUCCESS:")
        print(f"   Total time: {v3_total_time:.1f}ms")
        print(f"   Engine: PyTorch")
        print(f"   Pose shape: {final_coords.shape}")
        print(f"   Device: {device}")
        print(f"   Architecture: Single-threaded")
        
        v3_success = True
        v3_coords = final_coords
        
    else:
        print("‚ùå V3 BBOX processing failed")
        v3_success = False
        
except Exception as e:
    print(f"‚ùå V3 CORE ERROR: {e}")
    import traceback
    traceback.print_exc()
    v3_success = False

print()

# ========================================
# COMPARISON SUMMARY
# ========================================
print("üèÜ RESUMEN COMPARATIVO")
print("="*50)

if v4_success:
    print(f"ü•á V4 ONNX:     {v4_total_time:.1f}ms total, {v4_stats['avg_processing_time_ms']:.1f}ms proceso")
    
if v4_tflite_success:
    print(f"ü•à V4 TFLite:   {v4_tflite_total_time:.1f}ms total, {v4_tflite_stats['avg_processing_time_ms']:.1f}ms proceso")
    
if v3_success:
    print(f"ü•â V3 PyTorch:  {v3_total_time:.1f}ms total (single-threaded)")

print()
print("üìä CARACTER√çSTICAS:")
print("V4 ONNX:")
print("  ‚úÖ Thread-safe, parallel")
print("  ‚úÖ ONNX Runtime optimizado")
print("  ‚úÖ Cache inteligente")
print("  ‚úÖ RootNet integrado")
print("  ‚úÖ Manejo robusto de errores")

print("\nV4 TFLite:")
print("  ‚úÖ Thread-safe, parallel")
print("  ‚úÖ Optimizado para mobile/edge")
print("  ‚úÖ Cache inteligente")
print("  ‚úÖ RootNet integrado")
print("  ‚ö†Ô∏è  M√°s lento que ONNX")

print("\nV3 PyTorch:")
print("  ‚úÖ Estable y simple")
print("  ‚ö†Ô∏è  Single-threaded")
print("  ‚ö†Ô∏è  Sin optimizaciones ONNX")
print("  ‚ö†Ô∏è  Menos robusto")

print()
print("üéØ CONCLUSI√ìN:")
if v4_success and v3_success:
    speedup = v3_total_time / v4_total_time
    print(f"V4 es {speedup:.1f}x m√°s r√°pido que V3")
    
print("‚úÖ V4 ONNX es la mejor opci√≥n para producci√≥n")
print("‚úÖ V4 TFLite es ideal para dispositivos m√≥viles")
print("‚úÖ V3 sirve como baseline estable")
