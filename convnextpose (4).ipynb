{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5116687,"sourceType":"datasetVersion","datasetId":2200515},{"sourceId":13341353,"sourceType":"datasetVersion","datasetId":8460258}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🎯 ConvNeXtPose Testing en Kaggle - Modelos L y M\n\nEste notebook evalúa los modelos ConvNeXtPose L y M en Human3.6M Protocol 2.\n\n**Datasets requeridos:**\n- Human3.6M Dataset (con S9_ACT2_16, S11_ACT2_16, annotations)\n- ConvNeXtPose Pre-trained Models (checkpoints .tar)\n\n**GPU recomendada:** T4 x2 o P100","metadata":{}},{"cell_type":"markdown","source":"## 📦 PASO 1: Setup Inicial","metadata":{}},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:45:35.465747Z","iopub.execute_input":"2025-10-14T16:45:35.466043Z","iopub.status.idle":"2025-10-14T16:45:35.582735Z","shell.execute_reply.started":"2025-10-14T16:45:35.466020Z","shell.execute_reply":"2025-10-14T16:45:35.581668Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#!rm -r ConvNeXtPose ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:45:52.497540Z","iopub.execute_input":"2025-10-14T16:45:52.497867Z","iopub.status.idle":"2025-10-14T16:45:52.857792Z","shell.execute_reply.started":"2025-10-14T16:45:52.497837Z","shell.execute_reply":"2025-10-14T16:45:52.856598Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Clonar repositorio\n!git clone https://github.com/EstebanCabreraArbizu/ConvNeXtPose.git\n%cd ConvNeXtPose\n!git fetch origin\n\n# Verificar versiones\nimport torch\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA disponible: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:46:28.543379Z","iopub.execute_input":"2025-10-14T16:46:28.543669Z","iopub.status.idle":"2025-10-14T16:46:45.055415Z","shell.execute_reply.started":"2025-10-14T16:46:28.543644Z","shell.execute_reply":"2025-10-14T16:46:45.054509Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'ConvNeXtPose'...\nremote: Enumerating objects: 1166, done.\u001b[K\nremote: Counting objects: 100% (288/288), done.\u001b[K\nremote: Compressing objects: 100% (225/225), done.\u001b[K\nremote: Total 1166 (delta 103), reused 222 (delta 62), pack-reused 878 (from 1)\u001b[K\nReceiving objects: 100% (1166/1166), 318.73 MiB | 39.40 MiB/s, done.\nResolving deltas: 100% (341/341), done.\nUpdating files: 100% (207/207), done.\n/kaggle/working/ConvNeXtPose\nPyTorch: 2.5.1+cu121\nCUDA disponible: True\nGPU: Tesla T4\nMemoria GPU: 15.83 GB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 🗂️ PASO 2: Configurar Dataset Human3.6M\n\nUsamos enlaces simbólicos para evitar copiar ~30GB de datos.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# IMPORTANTE: Ajusta este path al nombre real de tu dataset en Kaggle\nKAGGLE_DATASET_PATH = '/kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net'  # ← CAMBIAR SEGÚN TU DATASET\n\n# Verificar que el dataset existe\nimport os\nif not os.path.exists(KAGGLE_DATASET_PATH):\n    print(f\"❌ Dataset no encontrado en {KAGGLE_DATASET_PATH}\")\n    print(\"\\n📂 Datasets disponibles:\")\n    !ls /kaggle/input/\n    raise FileNotFoundError(\"Verifica el nombre del dataset y actualiza KAGGLE_DATASET_PATH\")\nelse:\n    print(f\"✓ Dataset encontrado en {KAGGLE_DATASET_PATH}\")\n    print(\"\\n📂 Contenido:\")\n    !ls {KAGGLE_DATASET_PATH}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:46:45.056873Z","iopub.execute_input":"2025-10-14T16:46:45.057533Z","iopub.status.idle":"2025-10-14T16:46:45.198008Z","shell.execute_reply.started":"2025-10-14T16:46:45.057495Z","shell.execute_reply":"2025-10-14T16:46:45.197242Z"}},"outputs":[{"name":"stdout","text":"✓ Dataset encontrado en /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net\n\n📂 Contenido:\n'annotations (1)'   S11_ACT2_16   S9_ACT2_16\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### (Opcional) Diagnosticar Estructura del Dataset\n\nSi tienes dudas sobre la estructura de tu dataset, ejecuta esta celda primero para ver cómo están organizadas las carpetas.","metadata":{}},{"cell_type":"code","source":"# Diagnosticar estructura del dataset (útil para identificar carpetas anidadas)\n# !python diagnose_kaggle_dataset.py {KAGGLE_DATASET_PATH}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:46:45.199795Z","iopub.execute_input":"2025-10-14T16:46:45.200032Z","iopub.status.idle":"2025-10-14T16:46:45.203182Z","shell.execute_reply.started":"2025-10-14T16:46:45.200009Z","shell.execute_reply":"2025-10-14T16:46:45.202381Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Ejecutar script de configuración\n# IMPORTANTE: Esto enlaza el dataset DENTRO de data/Human36M/, NO reemplaza data/\n# El script detecta automáticamente carpetas anidadas (ej: annotations (1)/annotations/)\n!python setup_kaggle_dataset.py --kaggle-input {KAGGLE_DATASET_PATH} --project-root /kaggle/working/ConvNeXtPose\n\nprint(\"\\n✅ Dataset enlazado en data/Human36M/\")\nprint(\"✅ Módulos Python originales intactos en data/\")\nprint(\"✅ Carpetas anidadas detectadas automáticamente\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:46:45.204536Z","iopub.execute_input":"2025-10-14T16:46:45.204788Z","iopub.status.idle":"2025-10-14T16:46:45.470004Z","shell.execute_reply.started":"2025-10-14T16:46:45.204768Z","shell.execute_reply":"2025-10-14T16:46:45.469225Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\n  Configuración de Dataset Human3.6M para ConvNeXtPose\n======================================================================\n📂 Dataset Kaggle:     /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net\n📂 Proyecto ConvNeXt:  /kaggle/working/ConvNeXtPose\n\n✓ Directorio del proyecto encontrado: /kaggle/working/ConvNeXtPose/data/Human36M\n✓ Manteniendo módulos Python originales en /kaggle/working/ConvNeXtPose/data\n\n📁 [1/3] Configurando annotations...\n  ✓ Encontrado: annotations (1)/annotations\n    (21 archivos JSON detectados)\n  ✓ Creado: annotations -> /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net/annotations (1)/annotations\n\n👥 [2/3] Configurando sujetos S9 y S11...\n  ✓ Creado: S9 -> /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net/S9_ACT2_16\n  ✓ Creado: S11 -> /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net/S11_ACT2_16\n\n📦 [3/3] Configurando bbox_root...\n  ⚠️  No se encontró bbox_root (opcional)\n\n======================================================================\n  ✅ Configuración Completada\n======================================================================\n\n📂 Estructura creada en: /kaggle/working/ConvNeXtPose/data/Human36M\n\nContenido:\n  📁 __pycache__/\n  🔗 annotations -> annotations\n  📁 bbox_root/\n  📁 bbox_root/Subject 9,11 (trained on subject 1,5,6,7,8)/\n  📁 images/\n  🔗 images/S11 -> S11_ACT2_16\n  🔗 images/S9 -> S9_ACT2_16\n\n======================================================================\n  ✅ LISTO - NO necesitas configurar CONVNEXPOSE_DATA_DIR\n======================================================================\n\n✅ Los módulos Python originales están intactos en:\n   /kaggle/working/ConvNeXtPose/data/dataset.py\n   /kaggle/working/ConvNeXtPose/data/Human36M/Human36M.py\n\n✅ El dataset de Kaggle está enlazado en:\n   /kaggle/working/ConvNeXtPose/data/Human36M/images\n   /kaggle/working/ConvNeXtPose/data/Human36M/annotations\n   /kaggle/working/ConvNeXtPose/data/Human36M/bbox_root (si existe)\n\n🚀 Puedes ejecutar el testing directamente:\n   %cd /kaggle/working/ConvNeXtPose/main\n   !python test.py --gpu 0 --epochs 70 --variant L\n\n\n🎉 Setup completado exitosamente!\n\n💡 Tip: Ejecuta con --verify para verificar la estructura:\n   !python setup_kaggle_dataset.py --verify /kaggle/working/ConvNeXtPose\n\n✅ Dataset enlazado en data/Human36M/\n✅ Módulos Python originales intactos en data/\n✅ Carpetas anidadas detectadas automáticamente\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from pathlib import Path\n\nimages_dir = Path('/kaggle/working/ConvNeXtPose/data/Human36M/images')\n\nfor subject in ['S9', 'S11']:\n    subj_dir = images_dir / subject\n    if not subj_dir.exists():\n        continue\n    for seq_dir in subj_dir.iterdir():\n        target = images_dir / seq_dir.name\n        if target.exists():\n            continue      # ya estaba creado\n        target.symlink_to(seq_dir, target_is_directory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:46:45.471014Z","iopub.execute_input":"2025-10-14T16:46:45.471373Z","iopub.status.idle":"2025-10-14T16:46:45.527148Z","shell.execute_reply.started":"2025-10-14T16:46:45.471326Z","shell.execute_reply":"2025-10-14T16:46:45.526568Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"!find /kaggle/working/ConvNeXtPose/data/Human36M/images -maxdepth 1 -type l | head","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:46:45.527869Z","iopub.execute_input":"2025-10-14T16:46:45.528074Z","iopub.status.idle":"2025-10-14T16:46:45.657425Z","shell.execute_reply.started":"2025-10-14T16:46:45.528042Z","shell.execute_reply":"2025-10-14T16:46:45.656651Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ConvNeXtPose/data/Human36M/images/s_09_act_05_subact_01_ca_04\n/kaggle/working/ConvNeXtPose/data/Human36M/images/s_09_act_13_subact_02_ca_02\n/kaggle/working/ConvNeXtPose/data/Human36M/images/s_09_act_15_subact_02_ca_03\n/kaggle/working/ConvNeXtPose/data/Human36M/images/s_09_act_10_subact_02_ca_02\n/kaggle/working/ConvNeXtPose/data/Human36M/images/s_09_act_02_subact_01_ca_04\n/kaggle/working/ConvNeXtPose/data/Human36M/images/s_11_act_16_subact_02_ca_01\n/kaggle/working/ConvNeXtPose/data/Human36M/images/s_11_act_08_subact_02_ca_04\n/kaggle/working/ConvNeXtPose/data/Human36M/images/s_11_act_06_subact_01_ca_01\n/kaggle/working/ConvNeXtPose/data/Human36M/images/s_11_act_12_subact_01_ca_02\n/kaggle/working/ConvNeXtPose/data/Human36M/images/s_11_act_03_subact_02_ca_03\nfind: ‘standard output’: Broken pipe\nfind: write error\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Verificar que la estructura es correcta\n!python setup_kaggle_dataset.py --verify /kaggle/working/ConvNeXtPose","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:46:45.658266Z","iopub.execute_input":"2025-10-14T16:46:45.658486Z","iopub.status.idle":"2025-10-14T16:46:45.869096Z","shell.execute_reply.started":"2025-10-14T16:46:45.658465Z","shell.execute_reply":"2025-10-14T16:46:45.868370Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\n  🔍 Verificación de Estructura\n======================================================================\n  ✓ data/dataset.py\n  ✓ data/Human36M/Human36M.py\n  ✓ data/Human36M/annotations\n  ✓ data/Human36M/images\n  ✓ data/Human36M/images/S9\n  ✓ data/Human36M/images/S11\n  ✓ data/Human36M/bbox_root (optional)\n\n  ✅ Estructura verificada correctamente\n  ✅ Módulos Python intactos en data/\n  ✅ Dataset enlazado en data/Human36M/\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Verificar que la estructura es correcta\n!python verify_kaggle_structure.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:46:45.870061Z","iopub.execute_input":"2025-10-14T16:46:45.870293Z","iopub.status.idle":"2025-10-14T16:46:46.073253Z","shell.execute_reply.started":"2025-10-14T16:46:45.870271Z","shell.execute_reply":"2025-10-14T16:46:46.072470Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\n  🔍 VERIFICACIÓN RÁPIDA - Estructura del Proyecto\n======================================================================\n\n📄 Módulos Python originales:\n  ✓ data/dataset.py\n  ✓ data/multiple_datasets.py\n  ✓ data/Human36M/Human36M.py\n  ✓ common/base.py\n  ✓ main/config.py\n\n📂 Dataset de Kaggle (enlaces):\n  ✓ data/Human36M/images/S9\n  ✓ data/Human36M/images/S11\n  ✓ data/Human36M/annotations\n  ✓ data/Human36M/bbox_root\n\n======================================================================\n✅ ESTRUCTURA CORRECTA - Listo para testing\n\n🚀 Siguiente paso:\n   %cd /kaggle/working/ConvNeXtPose/main\n   !python test.py --gpu 0 --epochs 83 --variant L\n======================================================================\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## 🎯 PASO 3: Preparar Checkpoints\n\nExtraer los modelos pre-entrenados.","metadata":{}},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:46:46.075813Z","iopub.execute_input":"2025-10-14T16:46:46.076030Z","iopub.status.idle":"2025-10-14T16:46:46.198934Z","shell.execute_reply.started":"2025-10-14T16:46:46.076009Z","shell.execute_reply":"2025-10-14T16:46:46.198211Z"}},"outputs":[{"name":"stdout","text":"ARCHITECTURE_ADAPTATION_COMPLETE.md  KAGGLE_TESTING_GUIDE.md\nassets\t\t\t\t     kaggle_testing_notebook.ipynb\nAUTHOR_CONTACT_GUIDE.md\t\t     LICENSE\nCHECKLIST_TESTING.md\t\t     list_google_drive_contents.py\nCHECKPOINT_EXTRACTION_FIX.md\t     log2.txt\nCHECKPOINT_INVESTIGATION_REPORT.md   log.txt\nCHECKPOINT_MISLABELING_ISSUE.md      main\ncommon\t\t\t\t     NESTED_FOLDERS_SOLUTION.md\nCORRECCION_CONFIG_S.md\t\t     output\ndata\t\t\t\t     PASOS_TESTING.md\ndemo\t\t\t\t     PLAN_ACCION_INMEDIATO.md\ndiagnose_kaggle_dataset.py\t     quick_start.sh\nEMAIL_TEMPLATE_AUTHORS.md\t     README.md\nESTADO_PROYECTO.md\t\t     README_TESTING.md\nEXPLICACION_DIMS_INCORRECTOS.md      requirements.txt\nexports\t\t\t\t     RESUMEN_EJECUTIVO.md\nGITHUB_ISSUE_TEMPLATE.md\t     RESUMEN_RETESTING.md\nGUIA_TESTING_MODELOS_L_M.md\t     setup_kaggle_dataset.py\nidentify_model_variant.py\t     tool\nKAGGLE_DATASET_FIX.md\t\t     UBUNTU_QUICKSTART.md\nKAGGLE_EXECUTION_GUIDE.md\t     ubuntu_quickstart.sh\nKAGGLE_QUICK_SOLUTION.md\t     verify_kaggle_structure.py\nKAGGLE_QUICKSTART.md\t\t     vis\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!pip install gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:46:46.200943Z","iopub.execute_input":"2025-10-14T16:46:46.201220Z","iopub.status.idle":"2025-10-14T16:46:50.416654Z","shell.execute_reply.started":"2025-10-14T16:46:46.201195Z","shell.execute_reply":"2025-10-14T16:46:50.415623Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import gdown\n\nfolder_id = \"12H7zkLvmJtrkCmAUAPkQ6788WAnO60gI\"\noutput = \"models_tar\"\n\ngdown.download_folder(id=folder_id, output=output, quiet=False, use_cookies=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:46:50.418192Z","iopub.execute_input":"2025-10-14T16:46:50.418560Z","iopub.status.idle":"2025-10-14T16:47:34.444852Z","shell.execute_reply.started":"2025-10-14T16:46:50.418522Z","shell.execute_reply":"2025-10-14T16:47:34.444173Z"}},"outputs":[{"name":"stderr","text":"Retrieving folder contents\n","output_type":"stream"},{"name":"stdout","text":"Processing file 1eIaMqTYG-30CuPULs9LzSfeouAzYYHQW ConvNeXtPose_L.tar\nProcessing file 1X_H-6S4xrQjW9GhJ3yWB-AXqUHddvkOI ConvNeXtPose_M.tar\nProcessing file 1OriQPQ3uRY8MWPHP9KnwPaKawzrontqH ConvNeXtPose_S.tar\nProcessing file 165D0rU2GImmRe7u7DNe6eKJG8voBIcGh ConvNeXtPose_XS.tar\n","output_type":"stream"},{"name":"stderr","text":"Retrieving folder contents completed\nBuilding directory structure\nBuilding directory structure completed\nDownloading...\nFrom: https://drive.google.com/uc?id=1eIaMqTYG-30CuPULs9LzSfeouAzYYHQW\nTo: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_L.tar\n100%|██████████| 101M/101M [00:02<00:00, 49.1MB/s] \nDownloading...\nFrom: https://drive.google.com/uc?id=1X_H-6S4xrQjW9GhJ3yWB-AXqUHddvkOI\nTo: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_M.tar\n100%|██████████| 91.3M/91.3M [00:01<00:00, 68.3MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1OriQPQ3uRY8MWPHP9KnwPaKawzrontqH\nTo: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_S.tar\n100%|██████████| 89.6M/89.6M [00:00<00:00, 110MB/s] \nDownloading...\nFrom: https://drive.google.com/uc?id=165D0rU2GImmRe7u7DNe6eKJG8voBIcGh\nTo: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_XS.tar\n100%|██████████| 42.5M/42.5M [00:00<00:00, 172MB/s]\nDownload completed\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['models_tar/ConvNeXtPose_L.tar',\n 'models_tar/ConvNeXtPose_M.tar',\n 'models_tar/ConvNeXtPose_S.tar',\n 'models_tar/ConvNeXtPose_XS.tar']"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:34.445619Z","iopub.execute_input":"2025-10-14T16:47:34.446033Z","iopub.status.idle":"2025-10-14T16:47:34.570001Z","shell.execute_reply.started":"2025-10-14T16:47:34.446009Z","shell.execute_reply":"2025-10-14T16:47:34.569036Z"}},"outputs":[{"name":"stdout","text":"ARCHITECTURE_ADAPTATION_COMPLETE.md  kaggle_testing_notebook.ipynb\nassets\t\t\t\t     LICENSE\nAUTHOR_CONTACT_GUIDE.md\t\t     list_google_drive_contents.py\nCHECKLIST_TESTING.md\t\t     log2.txt\nCHECKPOINT_EXTRACTION_FIX.md\t     log.txt\nCHECKPOINT_INVESTIGATION_REPORT.md   main\nCHECKPOINT_MISLABELING_ISSUE.md      models_tar\ncommon\t\t\t\t     NESTED_FOLDERS_SOLUTION.md\nCORRECCION_CONFIG_S.md\t\t     output\ndata\t\t\t\t     PASOS_TESTING.md\ndemo\t\t\t\t     PLAN_ACCION_INMEDIATO.md\ndiagnose_kaggle_dataset.py\t     quick_start.sh\nEMAIL_TEMPLATE_AUTHORS.md\t     README.md\nESTADO_PROYECTO.md\t\t     README_TESTING.md\nEXPLICACION_DIMS_INCORRECTOS.md      requirements.txt\nexports\t\t\t\t     RESUMEN_EJECUTIVO.md\nGITHUB_ISSUE_TEMPLATE.md\t     RESUMEN_RETESTING.md\nGUIA_TESTING_MODELOS_L_M.md\t     setup_kaggle_dataset.py\nidentify_model_variant.py\t     tool\nKAGGLE_DATASET_FIX.md\t\t     UBUNTU_QUICKSTART.md\nKAGGLE_EXECUTION_GUIDE.md\t     ubuntu_quickstart.sh\nKAGGLE_QUICK_SOLUTION.md\t     verify_kaggle_structure.py\nKAGGLE_QUICKSTART.md\t\t     vis\nKAGGLE_TESTING_GUIDE.md\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!ls src","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:34.570917Z","iopub.execute_input":"2025-10-14T16:47:34.571123Z","iopub.status.idle":"2025-10-14T16:47:34.692625Z","shell.execute_reply.started":"2025-10-14T16:47:34.571104Z","shell.execute_reply":"2025-10-14T16:47:34.691851Z"}},"outputs":[{"name":"stdout","text":"ls: cannot access 'src': No such file or directory\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:34.693548Z","iopub.execute_input":"2025-10-14T16:47:34.693756Z","iopub.status.idle":"2025-10-14T16:47:34.812981Z","shell.execute_reply.started":"2025-10-14T16:47:34.693736Z","shell.execute_reply":"2025-10-14T16:47:34.812254Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ConvNeXtPose\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!ls -lh /kaggle/working/ConvNeXtPose/models_tar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:34.813836Z","iopub.execute_input":"2025-10-14T16:47:34.814060Z","iopub.status.idle":"2025-10-14T16:47:34.935416Z","shell.execute_reply.started":"2025-10-14T16:47:34.814038Z","shell.execute_reply":"2025-10-14T16:47:34.934458Z"}},"outputs":[{"name":"stdout","text":"total 310M\n-rw-r--r-- 1 root root 97M Oct  4  2023 ConvNeXtPose_L.tar\n-rw-r--r-- 1 root root 88M Oct  4  2023 ConvNeXtPose_M.tar\n-rw-r--r-- 1 root root 86M Oct  4  2023 ConvNeXtPose_S.tar\n-rw-r--r-- 1 root root 41M Oct  4  2023 ConvNeXtPose_XS.tar\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import os\n# IMPORTANTE: Ajusta según el nombre de tu dataset de modelos\nMODELS_DATASET_PATH = '/kaggle/working/ConvNeXtPose/models_tar'\n# Verificar modelos disponibles\nif os.path.exists(MODELS_DATASET_PATH):\n    print(\"📦 Modelos disponibles:\")\n    !ls -lh {MODELS_DATASET_PATH}\nelse:\n    print(f\"❌ Dataset de modelos no encontrado: {MODELS_DATASET_PATH}\")\n    print(\"\\n📂 Datasets disponibles:\")\n    !ls /kaggle/input/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:34.936434Z","iopub.execute_input":"2025-10-14T16:47:34.936717Z","iopub.status.idle":"2025-10-14T16:47:35.059418Z","shell.execute_reply.started":"2025-10-14T16:47:34.936689Z","shell.execute_reply":"2025-10-14T16:47:35.058668Z"}},"outputs":[{"name":"stdout","text":"📦 Modelos disponibles:\ntotal 310M\n-rw-r--r-- 1 root root 97M Oct  4  2023 ConvNeXtPose_L.tar\n-rw-r--r-- 1 root root 88M Oct  4  2023 ConvNeXtPose_M.tar\n-rw-r--r-- 1 root root 86M Oct  4  2023 ConvNeXtPose_S.tar\n-rw-r--r-- 1 root root 41M Oct  4  2023 ConvNeXtPose_XS.tar\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import os\nimport zipfile\nimport shutil\nimport tarfile\nimport torch\n\n# Crear directorio para modelos\nos.makedirs('output/model_dump', exist_ok=True)\n\n# Función para extraer y convertir checkpoints\ndef extract_checkpoint(tar_path, model_name, expected_epoch=None):\n    \"\"\"Extrae checkpoint desde .tar/.zip y lo convierte en archivo .pth válido\n    \n    Los archivos .tar de ConvNeXtPose son ZIP con estructura de directorio en formato legacy.\n    Usamos una conversión simple: empaquetar el directorio como TAR que PyTorch puede leer.\n    \"\"\"\n    if not os.path.exists(tar_path):\n        print(f\"⚠️  Modelo {model_name} no encontrado en {tar_path}\")\n        return None\n    \n    print(f\"📦 Extrayendo modelo {model_name} desde {tar_path}...\")\n    \n    # Verificar tamaño del archivo\n    file_size = os.path.getsize(tar_path)\n    print(f\"   📏 Tamaño del archivo: {file_size / (1024*1024):.2f} MB\")\n    \n    # Leer primeros bytes para diagnosticar el formato\n    with open(tar_path, 'rb') as f:\n        header = f.read(512)\n        print(f\"   🔍 Primeros bytes (hex): {header[:50].hex()}\")\n    \n    # Si el archivo es muy pequeño o empieza con HTML, es un error de descarga\n    if file_size < 1000 or header.startswith(b'<!DOCTYPE') or header.startswith(b'<html'):\n        print(f\"   ❌ ERROR: El archivo parece ser HTML (error de descarga)\")\n        print(f\"   💡 Solución: Revisa que el folder de Google Drive sea público\")\n        return None\n    \n    # Extraer a directorio temporal\n    temp_dir = 'output/model_dump/temp_extract'\n    os.makedirs(temp_dir, exist_ok=True)\n    \n    # Detectar formato: intentar ZIP primero, luego TAR\n    extracted = False\n    try:\n        with zipfile.ZipFile(tar_path, 'r') as zip_ref:\n            zip_ref.extractall(temp_dir)\n            files = zip_ref.namelist()\n            print(f\"   ✓ Formato: ZIP - Extraído: {len(files)} archivos\")\n            extracted = True\n    except zipfile.BadZipFile:\n        try:\n            with tarfile.open(tar_path, 'r') as tar_ref:\n                tar_ref.extractall(temp_dir)\n                files = tar_ref.getnames()\n                print(f\"   ✓ Formato: TAR - Extraído: {len(files)} archivos\")\n                extracted = True\n        except (tarfile.ReadError, Exception) as e:\n            print(f\"   ❌ ERROR: No se pudo extraer el archivo\")\n            print(f\"   💡 Formato no reconocido: {type(e).__name__}: {e}\")\n            shutil.rmtree(temp_dir, ignore_errors=True)\n            return None\n    \n    if not extracted:\n        shutil.rmtree(temp_dir, ignore_errors=True)\n        return None\n    \n    # Buscar la carpeta del checkpoint (snapshot_XX.pth/ o archive/)\n    found_checkpoints = []\n    for item in os.listdir(temp_dir):\n        item_path = os.path.join(temp_dir, item)\n        if os.path.isdir(item_path):\n            # Verificar que tenga data.pkl (indicador de checkpoint PyTorch)\n            if os.path.exists(os.path.join(item_path, 'data.pkl')):\n                found_checkpoints.append((item, item_path))\n                print(f\"   ✓ Checkpoint encontrado: {item}/\")\n    \n    if not found_checkpoints:\n        print(f\"   ❌ No se encontró estructura de checkpoint válida\")\n        print(f\"   📂 Contenido extraído:\")\n        for item in os.listdir(temp_dir)[:10]:\n            print(f\"      - {item}\")\n        shutil.rmtree(temp_dir, ignore_errors=True)\n        return None\n    \n    # Convertir el checkpoint legacy a formato moderno\n    epoch = None\n    for ckpt_name, ckpt_path in found_checkpoints:\n        # Determinar el epoch desde el nombre\n        import re\n        match = re.search(r'snapshot_(\\d+)', ckpt_name)\n        if match:\n            epoch = match.group(1)\n            final_name = f'snapshot_{epoch}.pth'\n        else:\n            # Si no tiene snapshot_XX, usar archive/ con epoch esperado\n            if expected_epoch:\n                epoch = str(expected_epoch)\n                final_name = f'snapshot_{epoch}.pth'\n            else:\n                epoch = '0'\n                final_name = f'{model_name}_checkpoint.pth'\n        \n        dest_path = os.path.join('output/model_dump', final_name)\n        \n        print(f\"   🔄 Convirtiendo formato legacy → formato moderno...\")\n        \n        try:\n            # SOLUCIÓN DEFINITIVA: Cargar manualmente el formato legacy y guardar como moderno\n            import pickle\n            import io\n            \n            # Cargar data.pkl\n            data_pkl_path = os.path.join(ckpt_path, 'data.pkl')\n            data_dir = os.path.join(ckpt_path, 'data')\n            \n            # Crear un unpickler personalizado que resuelve persistent IDs\n            class LegacyUnpickler(pickle.Unpickler):\n                def __init__(self, file, data_dir):\n                    super().__init__(file)\n                    self.data_dir = data_dir\n                    self.storage_cache = {}\n                \n                def persistent_load(self, pid):\n                    # pid es una tupla: ('storage', <type>, <key>, <location>, <size>)\n                    if isinstance(pid, tuple) and len(pid) >= 2 and pid[0] == 'storage':\n                        typename, key = pid[1:3]\n                        location = pid[3] if len(pid) > 3 else None\n                        \n                        # Cachear storages para evitar recargar\n                        if key in self.storage_cache:\n                            return self.storage_cache[key]\n                        \n                        # Leer el archivo de storage\n                        storage_file = os.path.join(self.data_dir, str(key))\n                        \n                        # Leer el contenido como raw binary\n                        with open(storage_file, 'rb') as f:\n                            raw_data = f.read()\n                            \n                            # Crear UntypedStorage desde el buffer\n                            untyped_storage = torch.UntypedStorage.from_buffer(raw_data, dtype=torch.uint8)\n                            \n                            # Mapear typename a dtype de PyTorch\n                            dtype_map = {\n                                'FloatStorage': torch.float32,\n                                'DoubleStorage': torch.float64,\n                                'HalfStorage': torch.float16,\n                                'LongStorage': torch.int64,\n                                'IntStorage': torch.int32,\n                                'ShortStorage': torch.int16,\n                                'CharStorage': torch.int8,\n                                'ByteStorage': torch.uint8,\n                                'BoolStorage': torch.bool,\n                            }\n                            \n                            # Obtener dtype desde typename\n                            # typename puede ser un objeto _LegacyStorageMeta, extraer el nombre\n                            type_str = str(typename).split('.')[-1].replace(\"'>\", \"\")\n                            dtype = dtype_map.get(type_str, torch.float32)\n                            \n                            # Crear TypedStorage desde UntypedStorage\n                            typed_storage = torch.storage.TypedStorage(\n                                wrap_storage=untyped_storage,\n                                dtype=dtype\n                            )\n                            \n                            self.storage_cache[key] = typed_storage\n                            return typed_storage\n                    \n                    raise pickle.UnpicklingError(f\"unsupported persistent id: {pid}\")\n            \n            # Cargar el checkpoint usando el unpickler personalizado\n            with open(data_pkl_path, 'rb') as f:\n                unpickler = LegacyUnpickler(f, data_dir)\n                checkpoint = unpickler.load()\n            \n            # Guardar en formato moderno\n            torch.save(checkpoint, dest_path)\n            \n            # Verificar tamaño\n            size_mb = os.path.getsize(dest_path) / (1024 * 1024)\n            print(f\"   ✓ Archivo creado: {final_name} ({size_mb:.1f} MB)\")\n            \n            # Verificar que se puede cargar\n            test_load = torch.load(dest_path, map_location='cpu', weights_only=False)\n            keys = list(test_load.keys())\n            print(f\"   ✓ Verificación exitosa - Keys: {keys}\")\n            \n        except Exception as e:\n            print(f\"   ❌ ERROR al convertir checkpoint: {type(e).__name__}\")\n            print(f\"      {str(e)[:200]}\")\n            import traceback\n            traceback.print_exc()\n            shutil.rmtree(temp_dir, ignore_errors=True)\n            return None\n    \n    # Limpiar temporal\n    shutil.rmtree(temp_dir, ignore_errors=True)\n    print(f\"   ✓ Conversión completada\")\n    \n    return epoch\n\n# Extraer modelo L (epoch 83 según el paper)\nprint(\"=\"*60)\nmodel_l_path = f'{MODELS_DATASET_PATH}/ConvNeXtPose_L.tar'\nepoch_l = extract_checkpoint(model_l_path, 'L', expected_epoch=83)\n\nprint()\n\n# Extraer modelo M (epoch 70 según el paper)\nmodel_m_path = f'{MODELS_DATASET_PATH}/ConvNeXtPose_M.tar'\nepoch_m = extract_checkpoint(model_m_path, 'M', expected_epoch=70)\nprint(\"=\"*60)\n\n# Verificar checkpoints extraídos\nprint(\"\\n📂 Checkpoints disponibles:\")\ncheckpoints = [f for f in os.listdir('output/model_dump') \n               if f.endswith('.pth') and os.path.isfile(os.path.join('output/model_dump', f))]\n\nif checkpoints:\n    for ckpt in sorted(checkpoints):\n        ckpt_path = os.path.join('output/model_dump', ckpt)\n        size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n        print(f\"  ✓ {ckpt} ({size_mb:.1f} MB)\")\n        \n        # Verificar contenido\n        try:\n            test_load = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n            keys = list(test_load.keys())\n            print(f\"    → Keys: {keys}\")\n            if 'network' in test_load:\n                # Contar parámetros\n                num_params = sum(p.numel() for p in test_load['network'].values() \n                                 if isinstance(p, torch.Tensor))\n                print(f\"    → ✅ Formato válido ({num_params:,} parámetros)\")\n            else:\n                print(f\"    → ⚠️  Falta key 'network'\")\n        except Exception as e:\n            print(f\"    → ❌ Error: {type(e).__name__}: {str(e)[:80]}\")\n\n# Mostrar información de epochs\nif epoch_l:\n    print(f\"\\n💡 Modelo L: Usa CHECKPOINT_EPOCH = {epoch_l}\")\nif epoch_m:\n    print(f\"💡 Modelo M: Usa CHECKPOINT_EPOCH = {epoch_m}\")\n\nif epoch_l or epoch_m:\n    print(\"\\n✅ Los checkpoints están listos para torch.load()\")\n    print(\"   Formato: PyTorch moderno (.pth)\")\nelse:\n    print(\"\\n❌ No se pudieron extraer los checkpoints\")\n    print(\"💡 Verifica que los archivos .tar se descargaron correctamente\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:35.060407Z","iopub.execute_input":"2025-10-14T16:47:35.060688Z","iopub.status.idle":"2025-10-14T16:47:36.438155Z","shell.execute_reply.started":"2025-10-14T16:47:35.060664Z","shell.execute_reply":"2025-10-14T16:47:36.437433Z"}},"outputs":[{"name":"stdout","text":"============================================================\n📦 Extrayendo modelo L desde /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_L.tar...\n   📏 Tamaño del archivo: 96.19 MB\n   🔍 Primeros bytes (hex): 504b03040000080800000000000000000000000000000000000018000a00736e617073686f745f38332e7074682f64617461\n   ✓ Formato: ZIP - Extraído: 808 archivos\n   ✓ Checkpoint encontrado: snapshot_83.pth/\n   🔄 Convirtiendo formato legacy → formato moderno...\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-19-2ab6ed486f7e>:162: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  typed_storage = torch.storage.TypedStorage(\n","output_type":"stream"},{"name":"stdout","text":"   ✓ Archivo creado: snapshot_83.pth (96.2 MB)\n   ✓ Verificación exitosa - Keys: ['epoch', 'network', 'optimizer']\n   ✓ Conversión completada\n\n📦 Extrayendo modelo M desde /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_M.tar...\n   📏 Tamaño del archivo: 87.10 MB\n   🔍 Primeros bytes (hex): 504b03040000080800000000000000000000000000000000000010001200617263686976652f646174612e706b6c46420e00\n   ✓ Formato: ZIP - Extraído: 808 archivos\n   ✓ Checkpoint encontrado: archive/\n   🔄 Convirtiendo formato legacy → formato moderno...\n   ✓ Archivo creado: snapshot_70.pth (87.1 MB)\n   ✓ Verificación exitosa - Keys: ['epoch', 'network', 'optimizer']\n   ✓ Conversión completada\n============================================================\n\n📂 Checkpoints disponibles:\n  ✓ snapshot_70.pth (87.1 MB)\n    → Keys: ['epoch', 'network', 'optimizer']\n    → ✅ Formato válido (7,596,986 parámetros)\n  ✓ snapshot_83.pth (96.2 MB)\n    → Keys: ['epoch', 'network', 'optimizer']\n    → ✅ Formato válido (8,391,354 parámetros)\n\n💡 Modelo L: Usa CHECKPOINT_EPOCH = 83\n💡 Modelo M: Usa CHECKPOINT_EPOCH = 70\n\n✅ Los checkpoints están listos para torch.load()\n   Formato: PyTorch moderno (.pth)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"### ⚠️ Nota sobre Extracción de Checkpoints\n\nLos archivos `.tar` de ConvNeXtPose son en realidad **archivos ZIP** con estructura anidada:\n```\nConvNeXtPose_L.tar (archivo zip)\n└── snapshot_83.pth/        ← Directorio\n    ├── data.pkl\n    ├── version\n    └── data/               ← Carpeta con el checkpoint real\n        └── 0, 1, 2...      ← Archivos binarios\n```\n\nLa siguiente celda extrae y reorganiza correctamente el archivo `.pth` real.","metadata":{}},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:36.438928Z","iopub.execute_input":"2025-10-14T16:47:36.439193Z","iopub.status.idle":"2025-10-14T16:47:36.566305Z","shell.execute_reply.started":"2025-10-14T16:47:36.439158Z","shell.execute_reply":"2025-10-14T16:47:36.565355Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ConvNeXtPose\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Verificar checkpoints extraídos y detectar epoch\nimport glob\nimport re\nimport os\nimport torch\n\nprint(\"🔍 Verificación de Checkpoints:\\n\")\n\n# Buscar ARCHIVOS .pth\ncheckpoint_dir = 'output/model_dump'\nif os.path.exists(checkpoint_dir):\n    checkpoints = [f for f in os.listdir(checkpoint_dir) \n                   if f.endswith('.pth') and os.path.isfile(os.path.join(checkpoint_dir, f))]\nelse:\n    checkpoints = []\n\nif checkpoints:\n    print(\"✅ Checkpoints encontrados:\\n\")\n    for ckpt in sorted(checkpoints):\n        ckpt_path = os.path.join(checkpoint_dir, ckpt)\n        size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n        \n        # Extraer epoch\n        match = re.search(r'snapshot_(\\d+)', ckpt)\n        if match:\n            epoch = match.group(1)\n            print(f\"  ✓ {ckpt} ({size_mb:.1f} MB)\")\n            print(f\"    → Usa CHECKPOINT_EPOCH = {epoch}\")\n            \n            # Verificar contenido del checkpoint\n            try:\n                test_load = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n                keys = list(test_load.keys())\n                print(f\"    → Keys: {keys}\")\n                \n                if 'network' in test_load:\n                    # Contar parámetros del modelo\n                    num_params = sum(p.numel() for p in test_load['network'].values() \n                                     if isinstance(p, torch.Tensor))\n                    print(f\"    → ✅ Formato válido ({num_params:,} parámetros)\")\n                else:\n                    print(f\"    → ⚠️  Falta key 'network'\")\n                    \n            except Exception as e:\n                print(f\"    → ❌ Error al verificar: {type(e).__name__}: {str(e)[:50]}\")\n            print()\nelse:\n    print(\"❌ No se encontraron checkpoints válidos\\n\")\n    \n    # Diagnosticar problema\n    if os.path.exists(checkpoint_dir):\n        all_items = os.listdir(checkpoint_dir)\n        if all_items:\n            print(\"📂 Contenido de output/model_dump/:\")\n            for item in all_items[:15]:\n                item_path = os.path.join(checkpoint_dir, item)\n                if os.path.isdir(item_path):\n                    print(f\"    📁 {item}/ (directorio - no válido)\")\n                else:\n                    size_mb = os.path.getsize(item_path) / (1024 * 1024)\n                    print(f\"    📄 {item} ({size_mb:.1f} MB)\")\n            \n            print(\"\\n💡 Solución: Re-ejecuta la celda anterior de extracción\")\n        else:\n            print(\"💡 Directorio vacío - verifica MODELS_DATASET_PATH\")\n    else:\n        print(\"💡 Solución: Verifica que MODELS_DATASET_PATH es correcto\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"💡 IMPORTANTE: Los checkpoints son archivos .pth modernos\")\nprint(\"   Convertidos desde formato legacy a formato PyTorch estándar\")\nprint(\"=\"*60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:36.567521Z","iopub.execute_input":"2025-10-14T16:47:36.567775Z","iopub.status.idle":"2025-10-14T16:47:36.742784Z","shell.execute_reply.started":"2025-10-14T16:47:36.567753Z","shell.execute_reply":"2025-10-14T16:47:36.742101Z"}},"outputs":[{"name":"stdout","text":"🔍 Verificación de Checkpoints:\n\n✅ Checkpoints encontrados:\n\n  ✓ snapshot_70.pth (87.1 MB)\n    → Usa CHECKPOINT_EPOCH = 70\n    → Keys: ['epoch', 'network', 'optimizer']\n    → ✅ Formato válido (7,596,986 parámetros)\n\n  ✓ snapshot_83.pth (96.2 MB)\n    → Usa CHECKPOINT_EPOCH = 83\n    → Keys: ['epoch', 'network', 'optimizer']\n    → ✅ Formato válido (8,391,354 parámetros)\n\n\n============================================================\n💡 IMPORTANTE: Los checkpoints son archivos .pth modernos\n   Convertidos desde formato legacy a formato PyTorch estándar\n============================================================\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"**⚠️ IMPORTANTE:** Ajusta el valor de `CHECKPOINT_EPOCH` en las siguientes celdas según el epoch de tu checkpoint extraído. En este caso detectamos `snapshot_83.pth`, así que usa `CHECKPOINT_EPOCH = 83`.","metadata":{}},{"cell_type":"markdown","source":"## 🚀 PASO 4: Ejecutar Testing\n\n### Modelo L (Large)","metadata":{}},{"cell_type":"code","source":"# Diagnóstico: Verificar que todos los componentes están listos\nimport sys\nimport os\n\nprint(\"🔍 Verificación de Componentes:\\n\")\n\n# 1. Dataset - Verificar estructura DENTRO del proyecto\nproject_root = '/kaggle/working/ConvNeXtPose'\ndata_dir = os.path.join(project_root, 'data')\nh36m_path = os.path.join(data_dir, 'Human36M')\n\nprint(f\"1. Dataset (estructura del proyecto):\")\nprint(f\"   Project root: {project_root}\")\nprint(f\"   data/ exists: {os.path.exists(data_dir)}\")\nprint(f\"   data/dataset.py: {os.path.exists(os.path.join(data_dir, 'dataset.py'))}\")\nprint(f\"   data/Human36M/ exists: {os.path.exists(h36m_path)}\")\n\nif os.path.exists(h36m_path):\n    print(f\"   - Human36M.py: {os.path.exists(os.path.join(h36m_path, 'Human36M.py'))}\")\n    print(f\"   - annotations: {os.path.exists(os.path.join(h36m_path, 'annotations'))}\")\n    print(f\"   - images/S9: {os.path.exists(os.path.join(h36m_path, 'images', 'S9'))}\")\n    print(f\"   - images/S11: {os.path.exists(os.path.join(h36m_path, 'images', 'S11'))}\")\n\n# 2. Checkpoints\ncheckpoint_dir = os.path.join(project_root, 'output/model_dump')\nprint(f\"\\n2. Checkpoints: {checkpoint_dir}\")\nif os.path.exists(checkpoint_dir):\n    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith('snapshot_')]\n    if checkpoints:\n        print(f\"   Disponibles: {', '.join(checkpoints)}\")\n        # Extraer epoch del checkpoint\n        import re\n        for ckpt in checkpoints:\n            match = re.search(r'snapshot_(\\d+)', ckpt)\n            if match:\n                epoch = match.group(1)\n                print(f\"   💡 Usa CHECKPOINT_EPOCH = {epoch} en la siguiente celda\")\n    else:\n        print(\"   ⚠️  No se encontraron checkpoints\")\nelse:\n    print(\"   ❌ Directorio no existe\")\n\n# 3. Estructura del proyecto\nprint(f\"\\n3. Estructura del proyecto:\")\ncritical_files = ['main/config.py', 'common/base.py', 'data/dataset.py', 'data/Human36M/Human36M.py']\nfor file_path in critical_files:\n    full_path = os.path.join(project_root, file_path)\n    exists = os.path.exists(full_path)\n    status = \"✓\" if exists else \"❌\"\n    print(f\"   {status} {file_path}\")\n\nprint(\"\\n\" + \"=\"*60)\nif all(os.path.exists(os.path.join(project_root, f)) for f in critical_files):\n    print(\"✅ Todos los checks pasaron - Listo para testing\")\nelse:\n    print(\"❌ Algunos archivos faltan - Revisa la configuración\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:36.743601Z","iopub.execute_input":"2025-10-14T16:47:36.743876Z","iopub.status.idle":"2025-10-14T16:47:36.760980Z","shell.execute_reply.started":"2025-10-14T16:47:36.743840Z","shell.execute_reply":"2025-10-14T16:47:36.760168Z"}},"outputs":[{"name":"stdout","text":"🔍 Verificación de Componentes:\n\n1. Dataset (estructura del proyecto):\n   Project root: /kaggle/working/ConvNeXtPose\n   data/ exists: True\n   data/dataset.py: True\n   data/Human36M/ exists: True\n   - Human36M.py: True\n   - annotations: True\n   - images/S9: True\n   - images/S11: True\n\n2. Checkpoints: /kaggle/working/ConvNeXtPose/output/model_dump\n   Disponibles: snapshot_70.pth, snapshot_83.pth\n   💡 Usa CHECKPOINT_EPOCH = 70 en la siguiente celda\n   💡 Usa CHECKPOINT_EPOCH = 83 en la siguiente celda\n\n3. Estructura del proyecto:\n   ✓ main/config.py\n   ✓ common/base.py\n   ✓ data/dataset.py\n   ✓ data/Human36M/Human36M.py\n\n============================================================\n✅ Todos los checks pasaron - Listo para testing\n============================================================\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"### Ejecutar Testing desde Python\n\n**Estructura correcta:**\n- ✅ Módulos Python originales en `data/` (dataset.py, Human36M.py)\n- ✅ Dataset de Kaggle enlazado en `data/Human36M/` (images, annotations)\n- ✅ `config.py` configura automáticamente los paths","metadata":{}},{"cell_type":"markdown","source":"### ⚠️ IMPORTANTE: Verificar GPU Antes de Testing\n\n**El modelo REQUIERE GPU para correr en tiempo razonable.**\n\n- ✅ **Con GPU T4 x2**: ~10-20 minutos\n- ❌ **Con CPU**: ~10-20 HORAS (no recomendado)\n\n**Cómo activar GPU en Kaggle:**\n1. Panel derecho → **Settings**\n2. **Accelerator** → Selecciona **GPU T4 x2** o **GPU P100**\n3. Click **Save**\n4. El notebook se reiniciará con GPU habilitada","metadata":{}},{"cell_type":"code","source":"# Verificar disponibilidad de GPU\nimport torch\n\nprint(\"🔍 Verificando hardware disponible...\\n\")\nif torch.cuda.is_available():\n    print(f\"✅ GPU disponible: {torch.cuda.get_device_name(0)}\")\n    print(f\"   Memoria: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n    print(f\"\\n💡 Tiempo estimado: 10-20 minutos\")\n    USE_GPU = True\nelse:\n    print(\"❌ GPU NO disponible - usando CPU\")\n    print(\"\\n⚠️  ADVERTENCIA: El testing en CPU puede tomar HORAS\")\n    print(\"   Se recomienda activar GPU T4 x2 en Kaggle\")\n    print(\"\\n¿Continuar de todas formas? (no recomendado)\")\n    USE_GPU = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:36.761881Z","iopub.execute_input":"2025-10-14T16:47:36.762180Z","iopub.status.idle":"2025-10-14T16:47:36.769521Z","shell.execute_reply.started":"2025-10-14T16:47:36.762127Z","shell.execute_reply":"2025-10-14T16:47:36.768709Z"}},"outputs":[{"name":"stdout","text":"🔍 Verificando hardware disponible...\n\n✅ GPU disponible: Tesla T4\n   Memoria: 15.8 GB\n\n💡 Tiempo estimado: 10-20 minutos\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Testing con estructura correcta del proyecto\nimport sys\nimport os\n\nos.chdir('/kaggle/working/ConvNeXtPose/main')\nfrom config import cfg\n\n# No llamar cfg.load_variant_config(...) por ahora\ncfg.head_cfg = None\ncfg.backbone_cfg = ([3,3,9,3],[48,96,192,384])\ncfg.variant = 'XS'\ncfg.depth_dim = 64\n\n# cfg.load_variant_config(VARIANT)\ncfg.set_args('0')\nCHECKPOINT_EPOCH = 83  # ← AJUSTAR según tu checkpoint\n\nprint(f\"\\n{'='*60}\")\nprint(f\"  Testing ConvNeXtPose-{cfg.variant}\")\nprint(f\"{'='*60}\\n\")\n\n# 4. AHORA importar los demás módulos (config ya configuró sys.path)\nimport torch\nimport torch.backends.cudnn as cudnn\nfrom base import Tester\nimport numpy as np\nfrom tqdm import tqdm\n\n# Configurar CUDA solo si está disponible\nif torch.cuda.is_available():\n    cudnn.benchmark = True\n    cudnn.deterministic = False\n    cudnn.enabled = True\n    print(\"✅ CUDA habilitado\")\nelse:\n    print(\"⚠️  Ejecutando en CPU (será muy lento)\")\nfrom collections import OrderedDict\nimport torch\n\ndef map_legacy_head_keys(state_dict):\n    new_state = OrderedDict()\n    for k, v in state_dict.items():\n        if k.startswith('module.head.deconv_layers_'):\n            layer = k.split('.')[2]           # deconv_layers_1 / 2 / 3\n            suffix = k.split('.', 3)[-1]      # 0.weight, 1.bias, 2.weight…\n            if suffix.startswith('0.'):\n                new_k = k.replace('.0.', '.dwconv.')\n            elif suffix.startswith('1.'):\n                new_k = k.replace('.1.', '.norm.')\n            elif suffix.startswith('2.'):\n                new_k = k.replace('.2.', '.pwconv.')\n            else:\n                new_k = k\n            new_state[new_k] = v\n        else:\n            new_state[k] = v\n    return new_state\norig_make_model = Tester._make_model\n\ndef legacy_make_model(self, test_epoch):\n    import os\n    from torch.nn.parallel import DataParallel\n    from model import get_pose_net\n    from config import cfg\n\n    self.test_epoch = test_epoch\n    base = os.path.join(cfg.model_dir, f'snapshot_{test_epoch}')\n    model_path = base + '.pth'\n    if not os.path.exists(model_path):\n        model_path = base + '.pth.tar'\n    self.logger.info(f'Load checkpoint from {model_path}')\n\n    model = get_pose_net(cfg, False, self.joint_num)\n    model = DataParallel(model).cuda()\n\n    ckpt = torch.load(model_path, map_location='cpu')\n    state_dict = ckpt['network']\n    state_dict = map_legacy_head_keys(state_dict)  # <-- renombrar claves\n\n    model.load_state_dict(state_dict)\n    self.logger.info('✓ Checkpoint cargado (modo legacy)')\n    model.eval()\n    self.model = model\n\n# 5. Crear tester y ejecutar\nTester._make_model = legacy_make_model\ntester = Tester()\ntester._make_batch_generator()\ntester._make_model(CHECKPOINT_EPOCH)\nprint(f\"\\n🚀 Ejecutando testing en epoch {CHECKPOINT_EPOCH}...\\n\")\n\npreds = []\nwith torch.no_grad():\n    for itr, input_img in enumerate(tqdm(tester.batch_generator)):\n        coord_out = tester.model(input_img)\n        \n        if cfg.flip_test:\n            from utils.pose_utils import flip\n            flipped_input_img = flip(input_img, dims=3)\n            flipped_coord_out = tester.model(flipped_input_img)\n            flipped_coord_out[:, :, 0] = cfg.output_shape[1] - flipped_coord_out[:, :, 0] - 1\n            for pair in tester.flip_pairs:\n                flipped_coord_out[:, pair[0], :], flipped_coord_out[:, pair[1], :] = \\\n                    flipped_coord_out[:, pair[1], :].clone(), flipped_coord_out[:, pair[0], :].clone()\n            coord_out = (coord_out + flipped_coord_out)/2.\n        \n        coord_out = coord_out.cpu().numpy()\n        preds.append(coord_out)\n\n# Evaluar\npreds = np.concatenate(preds, axis=0)\nprint(f\"\\n📊 Evaluando {len(preds)} predicciones...\\n\")\ntester._evaluate(preds, cfg.result_dir)\n\nprint(f\"\\n✅ Testing completado!\")\nprint(f\"📂 Resultados guardados en: {cfg.result_dir}\")\nprint(f\"\\n💡 MPJPE esperado para XS: ~52.0 mm (Protocol 2)\")\nprint(f\"💡 PA-MPJPE esperado para XS: ~36.5 mm (Protocol 1)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:56:12.167343Z","iopub.execute_input":"2025-10-14T16:56:12.167675Z","iopub.status.idle":"2025-10-14T16:56:29.506354Z","shell.execute_reply.started":"2025-10-14T16:56:12.167652Z","shell.execute_reply":"2025-10-14T16:56:29.504962Z"}},"outputs":[{"name":"stderr","text":"\u001b[92m10-14 16:56:12\u001b[0m Creating dataset...\n","output_type":"stream"},{"name":"stdout","text":">>> Using GPU: 0\n\n============================================================\n  Testing ConvNeXtPose-XS\n============================================================\n\n✅ CUDA habilitado\nLoad data of H36M Protocol 2\ncreating index...\nindex created!\nGet bounding box and root from groundtruth\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(\n\u001b[92m10-14 16:56:28\u001b[0m Load checkpoint from /kaggle/working/ConvNeXtPose/main/../output/model_dump/snapshot_83.pth\n","output_type":"stream"},{"name":"stdout","text":"📐 Arquitectura: ConvNeXtPose-XS\n   Backbone: 384 canales de salida\n   HeadNet: Legacy (2-UP + 1 sin upsampling)\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-25-bb4940fbf4cf>:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(model_path, map_location='cpu')\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-bb4940fbf4cf>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mtester\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_batch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHECKPOINT_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🚀 Ejecutando testing en epoch {CHECKPOINT_EPOCH}...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-bb4940fbf4cf>\u001b[0m in \u001b[0;36mlegacy_make_model\u001b[0;34m(self, test_epoch)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_legacy_head_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# <-- renombrar claves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'✓ Checkpoint cargado (modo legacy)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2586\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DataParallel:\n\tsize mismatch for module.head.deconv_layers_1.pwconv.weight: copying a param with shape torch.Size([512, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for module.head.deconv_layers_1.pwconv.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.dwconv.weight: copying a param with shape torch.Size([512, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1, 3, 3]).\n\tsize mismatch for module.head.deconv_layers_2.dwconv.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.pwconv.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module.head.deconv_layers_2.pwconv.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.dwconv.weight: copying a param with shape torch.Size([512, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1, 3, 3]).\n\tsize mismatch for module.head.deconv_layers_3.dwconv.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.pwconv.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module.head.deconv_layers_3.pwconv.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.final_layer.weight: copying a param with shape torch.Size([1152, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 256, 1, 1])."],"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for DataParallel:\n\tsize mismatch for module.head.deconv_layers_1.pwconv.weight: copying a param with shape torch.Size([512, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).\n\tsize mismatch for module.head.deconv_layers_1.pwconv.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.dwconv.weight: copying a param with shape torch.Size([512, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1, 3, 3]).\n\tsize mismatch for module.head.deconv_layers_2.dwconv.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_2.pwconv.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module.head.deconv_layers_2.pwconv.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.dwconv.weight: copying a param with shape torch.Size([512, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1, 3, 3]).\n\tsize mismatch for module.head.deconv_layers_3.dwconv.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.norm.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.norm.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.norm.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.norm.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.deconv_layers_3.pwconv.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module.head.deconv_layers_3.pwconv.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module.head.final_layer.weight: copying a param with shape torch.Size([1152, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1152, 256, 1, 1]).","output_type":"error"}],"execution_count":25},{"cell_type":"markdown","source":"### Modelo M (Medium) - Opcional","metadata":{}},{"cell_type":"code","source":"# Si tienes el checkpoint del modelo M, ejecuta esto:\n# !python test.py --gpu 0 --epochs {CHECKPOINT_EPOCH} --variant M","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:43.280996Z","iopub.status.idle":"2025-10-14T16:47:43.281277Z","shell.execute_reply":"2025-10-14T16:47:43.281153Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📊 PASO 5: Verificar Resultados","metadata":{}},{"cell_type":"code","source":"# Ver resultados generados\n%cd ..\n!ls -lh output/result/\n\n# Leer log de resultados\nimport glob\nlog_files = glob.glob('output/log/*.log')\nif log_files:\n    latest_log = max(log_files, key=os.path.getctime)\n    print(f\"\\n📄 Últimas líneas del log ({os.path.basename(latest_log)}):\")\n    !tail -n 20 {latest_log}\nelse:\n    print(\"⚠️  No se encontraron logs\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:43.282247Z","iopub.status.idle":"2025-10-14T16:47:43.282557Z","shell.execute_reply":"2025-10-14T16:47:43.282399Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📈 PASO 6: Análisis de Resultados","metadata":{}},{"cell_type":"code","source":"import re\n\ndef extract_mpjpe_from_log(log_path):\n    \"\"\"Extrae el MPJPE del log\"\"\"\n    with open(log_path, 'r') as f:\n        content = f.read()\n    \n    # Buscar patrón de MPJPE\n    pattern = r'MPJPE.*?(\\d+\\.\\d+)'\n    matches = re.findall(pattern, content)\n    \n    if matches:\n        return float(matches[-1])  # Último valor\n    return None\n\n# Extraer resultados\nlog_files = glob.glob('output/log/*.log')\nif log_files:\n    latest_log = max(log_files, key=os.path.getctime)\n    mpjpe = extract_mpjpe_from_log(latest_log)\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"  📊 RESULTADOS FINALES\")\n    print(\"=\"*60)\n    \n    if mpjpe:\n        print(f\"\\n  MPJPE (Protocol 2): {mpjpe:.2f} mm\")\n        \n        # Comparar con paper\n        expected = {\n            'L': 42.3,\n            'M': 44.6\n        }\n        \n        # Determinar variante\n        for variant, expected_val in expected.items():\n            diff = abs(mpjpe - expected_val)\n            if diff < 5:\n                print(f\"\\n  Variante detectada: {variant}\")\n                print(f\"  Valor del paper: {expected_val:.2f} mm\")\n                print(f\"  Diferencia: {mpjpe - expected_val:+.2f} mm\")\n                \n                if diff < 2:\n                    print(\"  ✅ Resultado excelente (dentro de ±2mm)\")\n                elif diff < 5:\n                    print(\"  ✓ Resultado aceptable (dentro de ±5mm)\")\n                break\n    else:\n        print(\"\\n⚠️  No se pudo extraer MPJPE del log\")\n        print(\"Revisa el log manualmente en output/log/\")\n    \n    print(\"\\n\" + \"=\"*60)\nelse:\n    print(\"❌ No se encontraron logs de testing\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:43.283332Z","iopub.status.idle":"2025-10-14T16:47:43.283568Z","shell.execute_reply":"2025-10-14T16:47:43.283470Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 💾 PASO 7: Guardar Outputs\n\nKaggle guarda automáticamente todo en `/kaggle/working/`. Opcionalmente puedes copiar resultados específicos:","metadata":{}},{"cell_type":"code","source":"# Crear resumen de resultados\nimport json\nfrom datetime import datetime\n\nsummary = {\n    'timestamp': datetime.now().isoformat(),\n    'model': 'ConvNeXtPose-L',  # Cambiar según modelo testeado\n    'checkpoint_epoch': CHECKPOINT_EPOCH,\n    'dataset': 'Human3.6M Protocol 2',\n    'mpjpe_mm': mpjpe if 'mpjpe' in locals() else None,\n    'pytorch_version': torch.__version__,\n    'cuda_version': torch.version.cuda if torch.cuda.is_available() else None\n}\n\n# Guardar resumen\nwith open('output/result/test_summary.json', 'w') as f:\n    json.dump(summary, f, indent=2)\n\nprint(\"✓ Resumen guardado en output/result/test_summary.json\")\nprint(\"\\n📄 Contenido:\")\nprint(json.dumps(summary, indent=2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:47:43.284405Z","iopub.status.idle":"2025-10-14T16:47:43.284663Z","shell.execute_reply":"2025-10-14T16:47:43.284552Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🎉 Testing Completado!\n\nLos resultados están en:\n- **Logs**: `output/log/`\n- **Resultados**: `output/result/`\n- **Resumen JSON**: `output/result/test_summary.json`\n\nTodos los archivos en `/kaggle/working/ConvNeXtPose/output/` se guardarán automáticamente cuando hagas commit del notebook.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}