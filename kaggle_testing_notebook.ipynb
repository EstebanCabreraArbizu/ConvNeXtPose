{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17daf72a",
   "metadata": {},
   "source": [
    "# üéØ ConvNeXtPose Testing en Kaggle - Modelos L y M\n",
    "\n",
    "Este notebook eval√∫a los modelos ConvNeXtPose L y M en Human3.6M Protocol 2.\n",
    "\n",
    "**Datasets requeridos:**\n",
    "- Human3.6M Dataset (con S9_ACT2_i6, S11_ACT2_i6, annotations)\n",
    "- ConvNeXtPose Pre-trained Models (checkpoints .tar)\n",
    "\n",
    "**GPU recomendada:** T4 x2 o P100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee4c88",
   "metadata": {},
   "source": [
    "## üì¶ PASO 1: Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba1510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonar repositorio\n",
    "!git clone https://github.com/EstebanCabreraArbizu/ConvNeXtPose.git\n",
    "%cd ConvNeXtPose\n",
    "\n",
    "# Verificar versiones\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc19b2",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è PASO 2: Configurar Dataset Human3.6M\n",
    "\n",
    "**IMPORTANTE:** Solo enlazamos el contenido del dataset dentro de `data/Human36M/`.\n",
    "Los m√≥dulos Python originales (`dataset.py`, `Human36M.py`) permanecen intactos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Ajusta este path al nombre real de tu dataset en Kaggle\n",
    "KAGGLE_DATASET_PATH = '/kaggle/input/human36m-dataset'  # ‚Üê CAMBIAR SEG√öN TU DATASET\n",
    "\n",
    "# Verificar que el dataset existe\n",
    "import os\n",
    "if not os.path.exists(KAGGLE_DATASET_PATH):\n",
    "    print(f\"‚ùå Dataset no encontrado en {KAGGLE_DATASET_PATH}\")\n",
    "    print(\"\\nüìÇ Datasets disponibles:\")\n",
    "    !ls /kaggle/input/\n",
    "    raise FileNotFoundError(\"Verifica el nombre del dataset y actualiza KAGGLE_DATASET_PATH\")\n",
    "else:\n",
    "    print(f\"‚úì Dataset encontrado en {KAGGLE_DATASET_PATH}\")\n",
    "    print(\"\\nüìÇ Contenido:\")\n",
    "    !ls {KAGGLE_DATASET_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fc699",
   "metadata": {},
   "source": [
    "### (Opcional) Diagnosticar Estructura del Dataset\n",
    "\n",
    "Si tienes dudas sobre la estructura de tu dataset, ejecuta esta celda primero para ver c√≥mo est√°n organizadas las carpetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a35b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosticar estructura del dataset (√∫til para identificar carpetas anidadas)\n",
    "!python diagnose_kaggle_dataset.py {KAGGLE_DATASET_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d76eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar script de configuraci√≥n\n",
    "# IMPORTANTE: Esto enlaza el dataset DENTRO de data/Human36M/, NO reemplaza data/\n",
    "# El script detecta autom√°ticamente carpetas anidadas (ej: annotations (1)/annotations/)\n",
    "!python setup_kaggle_dataset.py --kaggle-input {KAGGLE_DATASET_PATH} --project-root /kaggle/working/ConvNeXtPose\n",
    "\n",
    "print(\"\\n‚úÖ Dataset enlazado en data/Human36M/\")\n",
    "print(\"‚úÖ M√≥dulos Python originales intactos en data/\")\n",
    "print(\"‚úÖ Carpetas anidadas detectadas autom√°ticamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdaddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que la estructura es correcta\n",
    "!python setup_kaggle_dataset.py --verify /kaggle/working/ConvNeXtPose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79560116",
   "metadata": {},
   "source": [
    "## üéØ PASO 3: Preparar Checkpoints\n",
    "\n",
    "Extraer los modelos pre-entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace898e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Si usas gdown, ajusta la ruta al directorio donde descargaste\n",
    "# Si usas dataset de Kaggle, usa: MODELS_DATASET_PATH = '/kaggle/input/convnextpose-models'\n",
    "MODELS_DATASET_PATH = '/kaggle/working/ConvNeXtPose/models_tar'  # ‚Üê CAMBIAR SEG√öN TU CASO\n",
    "\n",
    "# Verificar modelos disponibles\n",
    "if os.path.exists(MODELS_DATASET_PATH):\n",
    "    print(\"üì¶ Modelos disponibles:\")\n",
    "    !ls -lh {MODELS_DATASET_PATH}/*.tar\n",
    "else:\n",
    "    print(f\"‚ùå Dataset de modelos no encontrado: {MODELS_DATASET_PATH}\")\n",
    "    print(\"\\nüìÇ Rutas disponibles:\")\n",
    "    !ls -lh /kaggle/working/ConvNeXtPose/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import tarfile\n",
    "import torch\n",
    "\n",
    "# Crear directorio para modelos\n",
    "os.makedirs('output/model_dump', exist_ok=True)\n",
    "\n",
    "# Funci√≥n para extraer y convertir checkpoints\n",
    "def extract_checkpoint(tar_path, model_name, expected_epoch=None):\n",
    "    \"\"\"Extrae checkpoint desde .tar/.zip y lo convierte en archivo .pth v√°lido\n",
    "    \n",
    "    Los archivos .tar de ConvNeXtPose son ZIP con estructura de directorio en formato legacy.\n",
    "    Usamos una conversi√≥n simple: empaquetar el directorio como TAR que PyTorch puede leer.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(tar_path):\n",
    "        print(f\"‚ö†Ô∏è  Modelo {model_name} no encontrado en {tar_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üì¶ Extrayendo modelo {model_name} desde {tar_path}...\")\n",
    "    \n",
    "    # Verificar tama√±o del archivo\n",
    "    file_size = os.path.getsize(tar_path)\n",
    "    print(f\"   üìè Tama√±o del archivo: {file_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    # Leer primeros bytes para diagnosticar el formato\n",
    "    with open(tar_path, 'rb') as f:\n",
    "        header = f.read(512)\n",
    "        print(f\"   üîç Primeros bytes (hex): {header[:50].hex()}\")\n",
    "    \n",
    "    # Si el archivo es muy peque√±o o empieza con HTML, es un error de descarga\n",
    "    if file_size < 1000 or header.startswith(b'<!DOCTYPE') or header.startswith(b'<html'):\n",
    "        print(f\"   ‚ùå ERROR: El archivo parece ser HTML (error de descarga)\")\n",
    "        print(f\"   üí° Soluci√≥n: Revisa que el folder de Google Drive sea p√∫blico\")\n",
    "        return None\n",
    "    \n",
    "    # Extraer a directorio temporal\n",
    "    temp_dir = 'output/model_dump/temp_extract'\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    # Detectar formato: intentar ZIP primero, luego TAR\n",
    "    extracted = False\n",
    "    try:\n",
    "        with zipfile.ZipFile(tar_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "            files = zip_ref.namelist()\n",
    "            print(f\"   ‚úì Formato: ZIP - Extra√≠do: {len(files)} archivos\")\n",
    "            extracted = True\n",
    "    except zipfile.BadZipFile:\n",
    "        try:\n",
    "            with tarfile.open(tar_path, 'r') as tar_ref:\n",
    "                tar_ref.extractall(temp_dir)\n",
    "                files = tar_ref.getnames()\n",
    "                print(f\"   ‚úì Formato: TAR - Extra√≠do: {len(files)} archivos\")\n",
    "                extracted = True\n",
    "        except (tarfile.ReadError, Exception) as e:\n",
    "            print(f\"   ‚ùå ERROR: No se pudo extraer el archivo\")\n",
    "            print(f\"   üí° Formato no reconocido: {type(e).__name__}: {e}\")\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "            return None\n",
    "    \n",
    "    if not extracted:\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        return None\n",
    "    \n",
    "    # Buscar la carpeta del checkpoint (snapshot_XX.pth/ o archive/)\n",
    "    found_checkpoints = []\n",
    "    for item in os.listdir(temp_dir):\n",
    "        item_path = os.path.join(temp_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            # Verificar que tenga data.pkl (indicador de checkpoint PyTorch)\n",
    "            if os.path.exists(os.path.join(item_path, 'data.pkl')):\n",
    "                found_checkpoints.append((item, item_path))\n",
    "                print(f\"   ‚úì Checkpoint encontrado: {item}/\")\n",
    "    \n",
    "    if not found_checkpoints:\n",
    "        print(f\"   ‚ùå No se encontr√≥ estructura de checkpoint v√°lida\")\n",
    "        print(f\"   üìÇ Contenido extra√≠do:\")\n",
    "        for item in os.listdir(temp_dir)[:10]:\n",
    "            print(f\"      - {item}\")\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        return None\n",
    "    \n",
    "    # Convertir el checkpoint legacy a formato moderno\n",
    "    epoch = None\n",
    "    for ckpt_name, ckpt_path in found_checkpoints:\n",
    "        # Determinar el epoch desde el nombre\n",
    "        import re\n",
    "        match = re.search(r'snapshot_(\\d+)', ckpt_name)\n",
    "        if match:\n",
    "            epoch = match.group(1)\n",
    "            final_name = f'snapshot_{epoch}.pth'\n",
    "        else:\n",
    "            # Si no tiene snapshot_XX, usar archive/ con epoch esperado\n",
    "            if expected_epoch:\n",
    "                epoch = str(expected_epoch)\n",
    "                final_name = f'snapshot_{epoch}.pth'\n",
    "            else:\n",
    "                epoch = '0'\n",
    "                final_name = f'{model_name}_checkpoint.pth'\n",
    "        \n",
    "        dest_path = os.path.join('output/model_dump', final_name)\n",
    "        \n",
    "        print(f\"   üîÑ Convirtiendo formato legacy ‚Üí formato moderno...\")\n",
    "        \n",
    "        try:\n",
    "            # SOLUCI√ìN DEFINITIVA: Cargar manualmente el formato legacy y guardar como moderno\n",
    "            import pickle\n",
    "            import io\n",
    "            \n",
    "            # Cargar data.pkl\n",
    "            data_pkl_path = os.path.join(ckpt_path, 'data.pkl')\n",
    "            data_dir = os.path.join(ckpt_path, 'data')\n",
    "            \n",
    "            # Crear un unpickler personalizado que resuelve persistent IDs\n",
    "            class LegacyUnpickler(pickle.Unpickler):\n",
    "                def __init__(self, file, data_dir):\n",
    "                    super().__init__(file)\n",
    "                    self.data_dir = data_dir\n",
    "                    self.storage_cache = {}\n",
    "                \n",
    "                def persistent_load(self, pid):\n",
    "                    # pid es una tupla: ('storage', <type>, <key>, <location>, <size>)\n",
    "                    if isinstance(pid, tuple) and len(pid) >= 2 and pid[0] == 'storage':\n",
    "                        typename, key = pid[1:3]\n",
    "                        location = pid[3] if len(pid) > 3 else None\n",
    "                        \n",
    "                        # Cachear storages para evitar recargar\n",
    "                        if key in self.storage_cache:\n",
    "                            return self.storage_cache[key]\n",
    "                        \n",
    "                        # Leer el archivo de storage\n",
    "                        storage_file = os.path.join(self.data_dir, str(key))\n",
    "                        \n",
    "                        # Leer el contenido como raw binary\n",
    "                        with open(storage_file, 'rb') as f:\n",
    "                            raw_data = f.read()\n",
    "                            \n",
    "                            # Crear UntypedStorage desde el buffer\n",
    "                            untyped_storage = torch.UntypedStorage.from_buffer(raw_data, dtype=torch.uint8)\n",
    "                            \n",
    "                            # Mapear typename a dtype de PyTorch\n",
    "                            dtype_map = {\n",
    "                                'FloatStorage': torch.float32,\n",
    "                                'DoubleStorage': torch.float64,\n",
    "                                'HalfStorage': torch.float16,\n",
    "                                'LongStorage': torch.int64,\n",
    "                                'IntStorage': torch.int32,\n",
    "                                'ShortStorage': torch.int16,\n",
    "                                'CharStorage': torch.int8,\n",
    "                                'ByteStorage': torch.uint8,\n",
    "                                'BoolStorage': torch.bool,\n",
    "                            }\n",
    "                            \n",
    "                            # Obtener dtype desde typename\n",
    "                            # typename puede ser un objeto _LegacyStorageMeta, extraer el nombre\n",
    "                            type_str = str(typename).split('.')[-1].replace(\"'>\", \"\")\n",
    "                            dtype = dtype_map.get(type_str, torch.float32)\n",
    "                            \n",
    "                            # Crear TypedStorage desde UntypedStorage\n",
    "                            typed_storage = torch.storage.TypedStorage(\n",
    "                                wrap_storage=untyped_storage,\n",
    "                                dtype=dtype\n",
    "                            )\n",
    "                            \n",
    "                            self.storage_cache[key] = typed_storage\n",
    "                            return typed_storage\n",
    "                    \n",
    "                    raise pickle.UnpicklingError(f\"unsupported persistent id: {pid}\")\n",
    "            \n",
    "            # Cargar el checkpoint usando el unpickler personalizado\n",
    "            with open(data_pkl_path, 'rb') as f:\n",
    "                unpickler = LegacyUnpickler(f, data_dir)\n",
    "                checkpoint = unpickler.load()\n",
    "            \n",
    "            # Guardar en formato moderno\n",
    "            torch.save(checkpoint, dest_path)\n",
    "            \n",
    "            # Verificar tama√±o\n",
    "            size_mb = os.path.getsize(dest_path) / (1024 * 1024)\n",
    "            print(f\"   ‚úì Archivo creado: {final_name} ({size_mb:.1f} MB)\")\n",
    "            \n",
    "            # Verificar que se puede cargar\n",
    "            test_load = torch.load(dest_path, map_location='cpu', weights_only=False)\n",
    "            keys = list(test_load.keys())\n",
    "            print(f\"   ‚úì Verificaci√≥n exitosa - Keys: {keys}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå ERROR al convertir checkpoint: {type(e).__name__}\")\n",
    "            print(f\"      {str(e)[:200]}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "            return None\n",
    "    \n",
    "    # Limpiar temporal\n",
    "    shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "    print(f\"   ‚úì Conversi√≥n completada\")\n",
    "    \n",
    "    return epoch\n",
    "\n",
    "# Extraer modelo L (epoch 83 seg√∫n el paper)\n",
    "print(\"=\"*60)\n",
    "model_l_path = f'{MODELS_DATASET_PATH}/ConvNeXtPose_L.tar'\n",
    "epoch_l = extract_checkpoint(model_l_path, 'L', expected_epoch=83)\n",
    "\n",
    "print()\n",
    "\n",
    "# Extraer modelo M (epoch 70 seg√∫n el paper)\n",
    "model_m_path = f'{MODELS_DATASET_PATH}/ConvNeXtPose_M.tar'\n",
    "epoch_m = extract_checkpoint(model_m_path, 'M', expected_epoch=70)\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar checkpoints extra√≠dos\n",
    "print(\"\\nüìÇ Checkpoints disponibles:\")\n",
    "checkpoints = [f for f in os.listdir('output/model_dump') \n",
    "               if f.endswith('.pth') and os.path.isfile(os.path.join('output/model_dump', f))]\n",
    "\n",
    "if checkpoints:\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        ckpt_path = os.path.join('output/model_dump', ckpt)\n",
    "        size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n",
    "        print(f\"  ‚úì {ckpt} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        # Verificar contenido\n",
    "        try:\n",
    "            test_load = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "            keys = list(test_load.keys())\n",
    "            print(f\"    ‚Üí Keys: {keys}\")\n",
    "            if 'network' in test_load:\n",
    "                # Contar par√°metros\n",
    "                num_params = sum(p.numel() for p in test_load['network'].values() \n",
    "                                 if isinstance(p, torch.Tensor))\n",
    "                print(f\"    ‚Üí ‚úÖ Formato v√°lido ({num_params:,} par√°metros)\")\n",
    "            else:\n",
    "                print(f\"    ‚Üí ‚ö†Ô∏è  Falta key 'network'\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ‚Üí ‚ùå Error: {type(e).__name__}: {str(e)[:80]}\")\n",
    "\n",
    "# Mostrar informaci√≥n de epochs\n",
    "if epoch_l:\n",
    "    print(f\"\\nüí° Modelo L: Usa CHECKPOINT_EPOCH = {epoch_l}\")\n",
    "if epoch_m:\n",
    "    print(f\"üí° Modelo M: Usa CHECKPOINT_EPOCH = {epoch_m}\")\n",
    "\n",
    "if epoch_l or epoch_m:\n",
    "    print(\"\\n‚úÖ Los checkpoints est√°n listos para torch.load()\")\n",
    "    print(\"   Formato: PyTorch moderno (.pth)\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No se pudieron extraer los checkpoints\")\n",
    "    print(\"üí° Verifica que los archivos .tar se descargaron correctamente\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b098aaa5",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Nota sobre Extracci√≥n de Checkpoints\n",
    "\n",
    "Los archivos `.tar` de ConvNeXtPose son en realidad **archivos ZIP** con estructura anidada:\n",
    "```\n",
    "ConvNeXtPose_L.tar (archivo zip)\n",
    "‚îî‚îÄ‚îÄ snapshot_83.pth/        ‚Üê Directorio (formato legacy de PyTorch)\n",
    "    ‚îú‚îÄ‚îÄ data.pkl            ‚Üê Metadatos del modelo (epoch, network, etc.)\n",
    "    ‚îú‚îÄ‚îÄ version             ‚Üê Versi√≥n de PyTorch\n",
    "    ‚îî‚îÄ‚îÄ data/               ‚Üê Tensors del modelo\n",
    "        ‚îú‚îÄ‚îÄ 0, 1, 2...      ‚Üê Fragmentos binarios\n",
    "```\n",
    "\n",
    "**Problema:** `torch.load()` en PyTorch moderno **NO acepta directorios**, solo archivos.\n",
    "\n",
    "**Soluci√≥n:** La celda anterior:\n",
    "1. Extrae el contenido del ZIP\n",
    "2. Lee `data.pkl` del directorio\n",
    "3. Convierte y guarda como archivo `.pth` est√°ndar que `torch.load()` puede abrir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar checkpoints extra√≠dos y detectar epoch\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "\n",
    "print(\"üîç Verificaci√≥n de Checkpoints:\\n\")\n",
    "\n",
    "# Buscar ARCHIVOS .pth\n",
    "checkpoint_dir = 'output/model_dump'\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) \n",
    "                   if f.endswith('.pth') and os.path.isfile(os.path.join(checkpoint_dir, f))]\n",
    "else:\n",
    "    checkpoints = []\n",
    "\n",
    "if checkpoints:\n",
    "    print(\"‚úÖ Checkpoints encontrados:\\n\")\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        ckpt_path = os.path.join(checkpoint_dir, ckpt)\n",
    "        size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n",
    "        \n",
    "        # Extraer epoch\n",
    "        match = re.search(r'snapshot_(\\d+)', ckpt)\n",
    "        if match:\n",
    "            epoch = match.group(1)\n",
    "            print(f\"  ‚úì {ckpt} ({size_mb:.1f} MB)\")\n",
    "            print(f\"    ‚Üí Usa CHECKPOINT_EPOCH = {epoch}\")\n",
    "            \n",
    "            # Verificar contenido del checkpoint\n",
    "            try:\n",
    "                test_load = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "                keys = list(test_load.keys())\n",
    "                print(f\"    ‚Üí Keys: {keys}\")\n",
    "                \n",
    "                if 'network' in test_load:\n",
    "                    # Contar par√°metros del modelo\n",
    "                    num_params = sum(p.numel() for p in test_load['network'].values() \n",
    "                                     if isinstance(p, torch.Tensor))\n",
    "                    print(f\"    ‚Üí ‚úÖ Formato v√°lido ({num_params:,} par√°metros)\")\n",
    "                else:\n",
    "                    print(f\"    ‚Üí ‚ö†Ô∏è  Falta key 'network'\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"    ‚Üí ‚ùå Error al verificar: {type(e).__name__}: {str(e)[:50]}\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"‚ùå No se encontraron checkpoints v√°lidos\\n\")\n",
    "    \n",
    "    # Diagnosticar problema\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        all_items = os.listdir(checkpoint_dir)\n",
    "        if all_items:\n",
    "            print(\"üìÇ Contenido de output/model_dump/:\")\n",
    "            for item in all_items[:15]:\n",
    "                item_path = os.path.join(checkpoint_dir, item)\n",
    "                if os.path.isdir(item_path):\n",
    "                    print(f\"    üìÅ {item}/ (directorio - no v√°lido)\")\n",
    "                else:\n",
    "                    size_mb = os.path.getsize(item_path) / (1024 * 1024)\n",
    "                    print(f\"    üìÑ {item} ({size_mb:.1f} MB)\")\n",
    "            \n",
    "            print(\"\\nüí° Soluci√≥n: Re-ejecuta la celda anterior de extracci√≥n\")\n",
    "        else:\n",
    "            print(\"üí° Directorio vac√≠o - verifica MODELS_DATASET_PATH\")\n",
    "    else:\n",
    "        print(\"üí° Soluci√≥n: Verifica que MODELS_DATASET_PATH es correcto\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí° IMPORTANTE: Los checkpoints son archivos .pth modernos\")\n",
    "print(\"   Convertidos desde formato legacy a formato PyTorch est√°ndar\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177530d1",
   "metadata": {},
   "source": [
    "**‚ö†Ô∏è IMPORTANTE:** Ajusta el valor de `CHECKPOINT_EPOCH` en las siguientes celdas seg√∫n el epoch de tu checkpoint extra√≠do. En este caso detectamos `snapshot_83.pth`, as√≠ que usa `CHECKPOINT_EPOCH = 83`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25c20a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üö® SOLUCI√ìN AL ERROR: \"Found no NVIDIA driver\"\n",
    "\n",
    "**Causa:** El notebook NO tiene GPU activada en Kaggle.\n",
    "\n",
    "**Soluci√≥n r√°pida:**\n",
    "1. Ve al panel derecho de Kaggle\n",
    "2. **Settings** ‚Üí **Accelerator**\n",
    "3. Selecciona: **GPU T4 x2** (recomendado) o **GPU P100**\n",
    "4. Click **Save**\n",
    "5. Notebook se reiniciar√° autom√°ticamente\n",
    "6. Re-ejecuta desde el PASO 1\n",
    "\n",
    "**¬øPor qu√© se necesita GPU?**\n",
    "- Modelo ConvNeXtPose-L: ~35M par√°metros\n",
    "- Dataset: ~30,000 im√°genes\n",
    "- CPU: ~20 horas ‚ùå\n",
    "- GPU T4: ~15 minutos ‚úÖ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63761ce",
   "metadata": {},
   "source": [
    "## üöÄ PASO 4: Ejecutar Testing\n",
    "\n",
    "### Modelo L (Large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58509a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagn√≥stico: Verificar que todos los componentes est√°n listos\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"üîç Verificaci√≥n de Componentes:\\n\")\n",
    "\n",
    "# 1. Dataset - Verificar estructura DENTRO del proyecto\n",
    "project_root = '/kaggle/working/ConvNeXtPose'\n",
    "data_dir = os.path.join(project_root, 'data')\n",
    "h36m_path = os.path.join(data_dir, 'Human36M')\n",
    "\n",
    "print(f\"1. Dataset (estructura del proyecto):\")\n",
    "print(f\"   Project root: {project_root}\")\n",
    "print(f\"   data/ exists: {os.path.exists(data_dir)}\")\n",
    "print(f\"   data/dataset.py: {os.path.exists(os.path.join(data_dir, 'dataset.py'))}\")\n",
    "print(f\"   data/Human36M/ exists: {os.path.exists(h36m_path)}\")\n",
    "\n",
    "if os.path.exists(h36m_path):\n",
    "    print(f\"   - Human36M.py: {os.path.exists(os.path.join(h36m_path, 'Human36M.py'))}\")\n",
    "    print(f\"   - annotations: {os.path.exists(os.path.join(h36m_path, 'annotations'))}\")\n",
    "    print(f\"   - images/S9: {os.path.exists(os.path.join(h36m_path, 'images', 'S9'))}\")\n",
    "    print(f\"   - images/S11: {os.path.exists(os.path.join(h36m_path, 'images', 'S11'))}\")\n",
    "\n",
    "# 2. Checkpoints\n",
    "checkpoint_dir = os.path.join(project_root, 'output/model_dump')\n",
    "print(f\"\\n2. Checkpoints: {checkpoint_dir}\")\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith('snapshot_')]\n",
    "    if checkpoints:\n",
    "        print(f\"   Disponibles: {', '.join(checkpoints)}\")\n",
    "        # Extraer epoch del checkpoint\n",
    "        import re\n",
    "        for ckpt in checkpoints:\n",
    "            match = re.search(r'snapshot_(\\d+)', ckpt)\n",
    "            if match:\n",
    "                epoch = match.group(1)\n",
    "                print(f\"   üí° Usa CHECKPOINT_EPOCH = {epoch} en la siguiente celda\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No se encontraron checkpoints\")\n",
    "else:\n",
    "    print(\"   ‚ùå Directorio no existe\")\n",
    "\n",
    "# 3. Estructura del proyecto\n",
    "print(f\"\\n3. Estructura del proyecto:\")\n",
    "critical_files = ['main/config.py', 'common/base.py', 'data/dataset.py', 'data/Human36M/Human36M.py']\n",
    "for file_path in critical_files:\n",
    "    full_path = os.path.join(project_root, file_path)\n",
    "    exists = os.path.exists(full_path)\n",
    "    status = \"‚úì\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {file_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all(os.path.exists(os.path.join(project_root, f)) for f in critical_files):\n",
    "    print(\"‚úÖ Todos los checks pasaron - Listo para testing\")\n",
    "else:\n",
    "    print(\"‚ùå Algunos archivos faltan - Revisa la configuraci√≥n\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c873e6",
   "metadata": {},
   "source": [
    "### Ejecutar Testing desde Python\n",
    "\n",
    "**Estructura correcta:**\n",
    "- ‚úÖ M√≥dulos Python originales en `data/` (dataset.py, Human36M.py)\n",
    "- ‚úÖ Dataset de Kaggle enlazado en `data/Human36M/` (images, annotations)\n",
    "- ‚úÖ `config.py` configura autom√°ticamente los paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be90e5",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è IMPORTANTE: Verificar GPU Antes de Testing\n",
    "\n",
    "**El modelo REQUIERE GPU para correr en tiempo razonable.**\n",
    "\n",
    "- ‚úÖ **Con GPU T4 x2**: ~10-20 minutos\n",
    "- ‚ùå **Con CPU**: ~10-20 HORAS (no recomendado)\n",
    "\n",
    "**C√≥mo activar GPU en Kaggle:**\n",
    "1. Panel derecho ‚Üí **Settings**\n",
    "2. **Accelerator** ‚Üí Selecciona **GPU T4 x2** o **GPU P100**\n",
    "3. Click **Save**\n",
    "4. El notebook se reiniciar√° con GPU habilitada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b310d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar disponibilidad de GPU\n",
    "import torch\n",
    "\n",
    "print(\"üîç Verificando hardware disponible...\\n\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memoria: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"\\nüí° Tiempo estimado: 10-20 minutos\")\n",
    "    USE_GPU = True\n",
    "else:\n",
    "    print(\"‚ùå GPU NO disponible - usando CPU\")\n",
    "    print(\"\\n‚ö†Ô∏è  ADVERTENCIA: El testing en CPU puede tomar HORAS\")\n",
    "    print(\"   Se recomienda activar GPU T4 x2 en Kaggle\")\n",
    "    print(\"\\n¬øContinuar de todas formas? (no recomendado)\")\n",
    "    USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6224a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing con estructura correcta del proyecto\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. Cambiar al directorio main (donde est√° config.py)\n",
    "os.chdir('/kaggle/working/ConvNeXtPose/main')\n",
    "\n",
    "# 2. Importar config PRIMERO - esto configura autom√°ticamente los paths\n",
    "from config import cfg\n",
    "\n",
    "# 3. Cargar variante ANTES de importar otros m√≥dulos\n",
    "VARIANT = 'S'  # ‚úÖ Usando modelo Small (disponible y convertido)\n",
    "# NOTA: Los archivos descargados como 'L' y 'M' contienen realmente modelo S\n",
    "# dims=[48, 96, 192, 384] confirmado por an√°lisis de arquitectura\n",
    "CHECKPOINT_EPOCH = 83  # ‚Üê AJUSTAR seg√∫n tu checkpoint\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  Testing ConvNeXtPose-{VARIANT}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "cfg.load_variant_config(VARIANT)\n",
    "cfg.set_args('0')  # GPU 0\n",
    "\n",
    "# 4. AHORA importar los dem√°s m√≥dulos (config ya configur√≥ sys.path)\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from base import Tester\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configurar CUDA solo si est√° disponible\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = False\n",
    "    cudnn.enabled = True\n",
    "    print(\"‚úÖ CUDA habilitado\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Ejecutando en CPU (ser√° muy lento)\")\n",
    "\n",
    "# 5. Crear tester y ejecutar\n",
    "tester = Tester()\n",
    "tester._make_batch_generator()\n",
    "tester._make_model(CHECKPOINT_EPOCH)\n",
    "\n",
    "print(f\"\\nüöÄ Ejecutando testing en epoch {CHECKPOINT_EPOCH}...\\n\")\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for itr, input_img in enumerate(tqdm(tester.batch_generator)):\n",
    "        coord_out = tester.model(input_img)\n",
    "        \n",
    "        if cfg.flip_test:\n",
    "            from utils.pose_utils import flip\n",
    "            flipped_input_img = flip(input_img, dims=3)\n",
    "            flipped_coord_out = tester.model(flipped_input_img)\n",
    "            flipped_coord_out[:, :, 0] = cfg.output_shape[1] - flipped_coord_out[:, :, 0] - 1\n",
    "            for pair in tester.flip_pairs:\n",
    "                flipped_coord_out[:, pair[0], :], flipped_coord_out[:, pair[1], :] = \\\n",
    "                    flipped_coord_out[:, pair[1], :].clone(), flipped_coord_out[:, pair[0], :].clone()\n",
    "            coord_out = (coord_out + flipped_coord_out)/2.\n",
    "        \n",
    "        coord_out = coord_out.cpu().numpy()\n",
    "        preds.append(coord_out)\n",
    "\n",
    "# Evaluar\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "print(f\"\\nüìä Evaluando {len(preds)} predicciones...\\n\")\n",
    "tester._evaluate(preds, cfg.result_dir)\n",
    "\n",
    "print(f\"\\n‚úÖ Testing completado!\")\n",
    "print(f\"üìÇ Resultados guardados en: {cfg.result_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7ffa5",
   "metadata": {},
   "source": [
    "### Modelo M (Medium) - Opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8944d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si tienes el checkpoint del modelo M, ejecuta esto:\n",
    "# !python test.py --gpu 0 --epochs {CHECKPOINT_EPOCH} --variant M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df8cdae",
   "metadata": {},
   "source": [
    "## üìä PASO 5: Verificar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver resultados generados\n",
    "%cd ..\n",
    "!ls -lh output/result/\n",
    "\n",
    "# Leer log de resultados\n",
    "import glob\n",
    "log_files = glob.glob('output/log/*.log')\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    print(f\"\\nüìÑ √öltimas l√≠neas del log ({os.path.basename(latest_log)}):\")\n",
    "    !tail -n 20 {latest_log}\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No se encontraron logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8e2af",
   "metadata": {},
   "source": [
    "## üìà PASO 6: An√°lisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_mpjpe_from_log(log_path):\n",
    "    \"\"\"Extrae el MPJPE del log\"\"\"\n",
    "    with open(log_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Buscar patr√≥n de MPJPE\n",
    "    pattern = r'MPJPE.*?(\\d+\\.\\d+)'\n",
    "    matches = re.findall(pattern, content)\n",
    "    \n",
    "    if matches:\n",
    "        return float(matches[-1])  # √öltimo valor\n",
    "    return None\n",
    "\n",
    "# Extraer resultados\n",
    "log_files = glob.glob('output/log/*.log')\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    mpjpe = extract_mpjpe_from_log(latest_log)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  üìä RESULTADOS FINALES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if mpjpe:\n",
    "        print(f\"\\n  MPJPE (Protocol 2): {mpjpe:.2f} mm\")\n",
    "        \n",
    "        # Comparar con paper\n",
    "        expected = {\n",
    "            'L': 42.3,\n",
    "            'M': 44.6\n",
    "        }\n",
    "        \n",
    "        # Determinar variante\n",
    "        for variant, expected_val in expected.items():\n",
    "            diff = abs(mpjpe - expected_val)\n",
    "            if diff < 5:\n",
    "                print(f\"\\n  Variante detectada: {variant}\")\n",
    "                print(f\"  Valor del paper: {expected_val:.2f} mm\")\n",
    "                print(f\"  Diferencia: {mpjpe - expected_val:+.2f} mm\")\n",
    "                \n",
    "                if diff < 2:\n",
    "                    print(\"  ‚úÖ Resultado excelente (dentro de ¬±2mm)\")\n",
    "                elif diff < 5:\n",
    "                    print(\"  ‚úì Resultado aceptable (dentro de ¬±5mm)\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No se pudo extraer MPJPE del log\")\n",
    "        print(\"Revisa el log manualmente en output/log/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"‚ùå No se encontraron logs de testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e80fd2",
   "metadata": {},
   "source": [
    "## üíæ PASO 7: Guardar Outputs\n",
    "\n",
    "Kaggle guarda autom√°ticamente todo en `/kaggle/working/`. Opcionalmente puedes copiar resultados espec√≠ficos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear resumen de resultados\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model': 'ConvNeXtPose-S',  # ‚úÖ Modelo Small confirmado\n",
    "    'checkpoint_epoch': CHECKPOINT_EPOCH,\n",
    "    'dataset': 'Human3.6M Protocol 2',\n",
    "    'mpjpe_mm': mpjpe if 'mpjpe' in locals() else None,\n",
    "    'pytorch_version': torch.__version__,\n",
    "    'cuda_version': torch.version.cuda if torch.cuda.is_available() else None\n",
    "}\n",
    "\n",
    "# Guardar resumen\n",
    "with open('output/result/test_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"‚úì Resumen guardado en output/result/test_summary.json\")\n",
    "print(\"\\nüìÑ Contenido:\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f63b45",
   "metadata": {},
   "source": [
    "## üéâ Testing Completado!\n",
    "\n",
    "Los resultados est√°n en:\n",
    "- **Logs**: `output/log/`\n",
    "- **Resultados**: `output/result/`\n",
    "- **Resumen JSON**: `output/result/test_summary.json`\n",
    "\n",
    "Todos los archivos en `/kaggle/working/ConvNeXtPose/output/` se guardar√°n autom√°ticamente cuando hagas commit del notebook."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
