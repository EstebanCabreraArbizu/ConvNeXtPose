{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17daf72a",
   "metadata": {},
   "source": [
    "# üéØ ConvNeXtPose Testing en Kaggle - Modelos L y M\n",
    "\n",
    "Este notebook eval√∫a los modelos ConvNeXtPose L y M en Human3.6M Protocol 2.\n",
    "\n",
    "**Datasets requeridos:**\n",
    "- Human3.6M Dataset (con S9_ACT2_i6, S11_ACT2_i6, annotations)\n",
    "- ConvNeXtPose Pre-trained Models (checkpoints .tar)\n",
    "\n",
    "**GPU recomendada:** T4 x2 o P100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee4c88",
   "metadata": {},
   "source": [
    "## üì¶ PASO 1: Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba1510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clonar repositorio\n",
    "!git clone https://github.com/EstebanCabreraArbizu/ConvNeXtPose.git\n",
    "%cd ConvNeXtPose\n",
    "\n",
    "# Verificar versiones\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc19b2",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è PASO 2: Configurar Dataset Human3.6M\n",
    "\n",
    "**IMPORTANTE:** Solo enlazamos el contenido del dataset dentro de `data/Human36M/`.\n",
    "Los m√≥dulos Python originales (`dataset.py`, `Human36M.py`) permanecen intactos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Ajusta este path al nombre real de tu dataset en Kaggle\n",
    "KAGGLE_DATASET_PATH = '/kaggle/input/human36m-dataset'  # ‚Üê CAMBIAR SEG√öN TU DATASET\n",
    "\n",
    "# Verificar que el dataset existe\n",
    "import os\n",
    "if not os.path.exists(KAGGLE_DATASET_PATH):\n",
    "    print(f\"‚ùå Dataset no encontrado en {KAGGLE_DATASET_PATH}\")\n",
    "    print(\"\\nüìÇ Datasets disponibles:\")\n",
    "    !ls /kaggle/input/\n",
    "    raise FileNotFoundError(\"Verifica el nombre del dataset y actualiza KAGGLE_DATASET_PATH\")\n",
    "else:\n",
    "    print(f\"‚úì Dataset encontrado en {KAGGLE_DATASET_PATH}\")\n",
    "    print(\"\\nüìÇ Contenido:\")\n",
    "    !ls {KAGGLE_DATASET_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d76eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar script de configuraci√≥n\n",
    "# IMPORTANTE: Esto enlaza el dataset DENTRO de data/Human36M/, NO reemplaza data/\n",
    "!python setup_kaggle_dataset.py --kaggle-input {KAGGLE_DATASET_PATH} --project-root /kaggle/working/ConvNeXtPose\n",
    "\n",
    "print(\"\\n‚úÖ Dataset enlazado en data/Human36M/\")\n",
    "print(\"‚úÖ M√≥dulos Python originales intactos en data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdaddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que la estructura es correcta\n",
    "!python setup_kaggle_dataset.py --verify /kaggle/working/ConvNeXtPose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79560116",
   "metadata": {},
   "source": [
    "## üéØ PASO 3: Preparar Checkpoints\n",
    "\n",
    "Extraer los modelos pre-entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace898e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Ajusta seg√∫n el nombre de tu dataset de modelos\n",
    "MODELS_DATASET_PATH = '/kaggle/input/convnextpose-models'  # ‚Üê CAMBIAR SEG√öN TU DATASET\n",
    "\n",
    "# Verificar modelos disponibles\n",
    "if os.path.exists(MODELS_DATASET_PATH):\n",
    "    print(\"üì¶ Modelos disponibles:\")\n",
    "    !ls -lh {MODELS_DATASET_PATH}/models_tar/\n",
    "else:\n",
    "    print(f\"‚ùå Dataset de modelos no encontrado: {MODELS_DATASET_PATH}\")\n",
    "    print(\"\\nüìÇ Datasets disponibles:\")\n",
    "    !ls /kaggle/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import zipfile\n",
    "# Crear directorio para modelos\n",
    "os.makedirs('output/model_dump', exist_ok=True)\n",
    "\n",
    "#Extraer modelos preentrenados con zipfile (no son realmente archivos tar)\n",
    "\n",
    "# Extraer modelo L\n",
    "model_l_path = f'{MODELS_DATASET_PATH}/models_tar/ConvNeXtPose_L.tar'\n",
    "if os.path.exists(model_l_path):\n",
    "    print(f\"üì¶ Extrayendo modelo L desde {model_l_path}...\")\n",
    "    with zipfile.ZipFile(model_l_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('output/model_dump')\n",
    "    print(f\"‚úì Modelo L extra√≠do: {zip_ref.namelist()}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Modelo L no encontrado en {model_l_path}\")\n",
    "\n",
    "# Extraer modelo M (opcional)\n",
    "model_m_path = f'{MODELS_DATASET_PATH}/models_tar/ConvNeXtPose_M.tar'\n",
    "if os.path.exists(model_m_path):\n",
    "    print(f\"üì¶ Extrayendo modelo M desde {model_m_path}...\")\n",
    "    with zipfile.ZipFile(model_m_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('output/model_dump')\n",
    "    print(f\"‚úì Modelo M extra√≠do: {zip_ref.namelist()}\")\n",
    "\n",
    "# Verificar checkpoints extra√≠dos\n",
    "print(\"\\nüìÇ Checkpoints disponibles:\")\n",
    "!ls -lh output/model_dump/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar el nombre del checkpoint y renombrar si es necesario\n",
    "import glob\n",
    "\n",
    "checkpoints = glob.glob('output/model_dump/snapshot_*.pth*')\n",
    "if checkpoints:\n",
    "    for ckpt in checkpoints:\n",
    "        print(f\"‚úì Checkpoint encontrado: {os.path.basename(ckpt)}\")\n",
    "else:\n",
    "    print(\"‚ùå No se encontraron checkpoints\")\n",
    "    print(\"Verifica que la extracci√≥n fue exitosa\")\n",
    "\n",
    "# Si necesitas renombrar (ej: snapshot_68.pth -> snapshot_70.pth):\n",
    "# os.rename('output/model_dump/snapshot_68.pth', 'output/model_dump/snapshot_70.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177530d1",
   "metadata": {},
   "source": [
    "**‚ö†Ô∏è IMPORTANTE:** Ajusta el valor de `CHECKPOINT_EPOCH` en las siguientes celdas seg√∫n el epoch de tu checkpoint extra√≠do. En este caso detectamos `snapshot_83.pth`, as√≠ que usa `CHECKPOINT_EPOCH = 83`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63761ce",
   "metadata": {},
   "source": [
    "## üöÄ PASO 4: Ejecutar Testing\n",
    "\n",
    "### Modelo L (Large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58509a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagn√≥stico: Verificar que todos los componentes est√°n listos\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"üîç Verificaci√≥n de Componentes:\\n\")\n",
    "\n",
    "# 1. Dataset - Verificar estructura DENTRO del proyecto\n",
    "project_root = '/kaggle/working/ConvNeXtPose'\n",
    "data_dir = os.path.join(project_root, 'data')\n",
    "h36m_path = os.path.join(data_dir, 'Human36M')\n",
    "\n",
    "print(f\"1. Dataset (estructura del proyecto):\")\n",
    "print(f\"   Project root: {project_root}\")\n",
    "print(f\"   data/ exists: {os.path.exists(data_dir)}\")\n",
    "print(f\"   data/dataset.py: {os.path.exists(os.path.join(data_dir, 'dataset.py'))}\")\n",
    "print(f\"   data/Human36M/ exists: {os.path.exists(h36m_path)}\")\n",
    "\n",
    "if os.path.exists(h36m_path):\n",
    "    print(f\"   - Human36M.py: {os.path.exists(os.path.join(h36m_path, 'Human36M.py'))}\")\n",
    "    print(f\"   - annotations: {os.path.exists(os.path.join(h36m_path, 'annotations'))}\")\n",
    "    print(f\"   - images/S9: {os.path.exists(os.path.join(h36m_path, 'images', 'S9'))}\")\n",
    "    print(f\"   - images/S11: {os.path.exists(os.path.join(h36m_path, 'images', 'S11'))}\")\n",
    "\n",
    "# 2. Checkpoints\n",
    "checkpoint_dir = os.path.join(project_root, 'output/model_dump')\n",
    "print(f\"\\n2. Checkpoints: {checkpoint_dir}\")\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith('snapshot_')]\n",
    "    if checkpoints:\n",
    "        print(f\"   Disponibles: {', '.join(checkpoints)}\")\n",
    "        # Extraer epoch del checkpoint\n",
    "        import re\n",
    "        for ckpt in checkpoints:\n",
    "            match = re.search(r'snapshot_(\\d+)', ckpt)\n",
    "            if match:\n",
    "                epoch = match.group(1)\n",
    "                print(f\"   üí° Usa CHECKPOINT_EPOCH = {epoch} en la siguiente celda\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No se encontraron checkpoints\")\n",
    "else:\n",
    "    print(\"   ‚ùå Directorio no existe\")\n",
    "\n",
    "# 3. Estructura del proyecto\n",
    "print(f\"\\n3. Estructura del proyecto:\")\n",
    "critical_files = ['main/config.py', 'common/base.py', 'data/dataset.py', 'data/Human36M/Human36M.py']\n",
    "for file_path in critical_files:\n",
    "    full_path = os.path.join(project_root, file_path)\n",
    "    exists = os.path.exists(full_path)\n",
    "    status = \"‚úì\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {file_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all(os.path.exists(os.path.join(project_root, f)) for f in critical_files):\n",
    "    print(\"‚úÖ Todos los checks pasaron - Listo para testing\")\n",
    "else:\n",
    "    print(\"‚ùå Algunos archivos faltan - Revisa la configuraci√≥n\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c873e6",
   "metadata": {},
   "source": [
    "### Ejecutar Testing desde Python\n",
    "\n",
    "**Estructura correcta:**\n",
    "- ‚úÖ M√≥dulos Python originales en `data/` (dataset.py, Human36M.py)\n",
    "- ‚úÖ Dataset de Kaggle enlazado en `data/Human36M/` (images, annotations)\n",
    "- ‚úÖ `config.py` configura autom√°ticamente los paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6224a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing con estructura correcta del proyecto\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. Cambiar al directorio main (donde est√° config.py)\n",
    "os.chdir('/kaggle/working/ConvNeXtPose/main')\n",
    "\n",
    "# 2. Importar config PRIMERO - esto configura autom√°ticamente los paths\n",
    "from config import cfg\n",
    "\n",
    "# 3. Cargar variante ANTES de importar otros m√≥dulos\n",
    "VARIANT = 'L'  # Cambiar a 'M' para modelo Medium\n",
    "CHECKPOINT_EPOCH = 83  # ‚Üê AJUSTAR seg√∫n tu checkpoint\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  Testing ConvNeXtPose-{VARIANT}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "cfg.load_variant_config(VARIANT)\n",
    "cfg.set_args('0')  # GPU 0\n",
    "\n",
    "# 4. AHORA importar los dem√°s m√≥dulos (config ya configur√≥ sys.path)\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from base import Tester\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False\n",
    "cudnn.enabled = True\n",
    "\n",
    "# 5. Crear tester y ejecutar\n",
    "tester = Tester()\n",
    "tester._make_batch_generator()\n",
    "tester._make_model(CHECKPOINT_EPOCH)\n",
    "\n",
    "print(f\"\\nüöÄ Ejecutando testing en epoch {CHECKPOINT_EPOCH}...\\n\")\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for itr, input_img in enumerate(tqdm(tester.batch_generator)):\n",
    "        coord_out = tester.model(input_img)\n",
    "        \n",
    "        if cfg.flip_test:\n",
    "            from utils.pose_utils import flip\n",
    "            flipped_input_img = flip(input_img, dims=3)\n",
    "            flipped_coord_out = tester.model(flipped_input_img)\n",
    "            flipped_coord_out[:, :, 0] = cfg.output_shape[1] - flipped_coord_out[:, :, 0] - 1\n",
    "            for pair in tester.flip_pairs:\n",
    "                flipped_coord_out[:, pair[0], :], flipped_coord_out[:, pair[1], :] = \\\n",
    "                    flipped_coord_out[:, pair[1], :].clone(), flipped_coord_out[:, pair[0], :].clone()\n",
    "            coord_out = (coord_out + flipped_coord_out)/2.\n",
    "        \n",
    "        coord_out = coord_out.cpu().numpy()\n",
    "        preds.append(coord_out)\n",
    "\n",
    "# Evaluar\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "print(f\"\\nüìä Evaluando {len(preds)} predicciones...\\n\")\n",
    "tester._evaluate(preds, cfg.result_dir)\n",
    "\n",
    "print(f\"\\n‚úÖ Testing completado!\")\n",
    "print(f\"üìÇ Resultados guardados en: {cfg.result_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7ffa5",
   "metadata": {},
   "source": [
    "### Modelo M (Medium) - Opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8944d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si tienes el checkpoint del modelo M, ejecuta esto:\n",
    "# !python test.py --gpu 0 --epochs {CHECKPOINT_EPOCH} --variant M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df8cdae",
   "metadata": {},
   "source": [
    "## üìä PASO 5: Verificar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200f20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver resultados generados\n",
    "%cd ..\n",
    "!ls -lh output/result/\n",
    "\n",
    "# Leer log de resultados\n",
    "import glob\n",
    "log_files = glob.glob('output/log/*.log')\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    print(f\"\\nüìÑ √öltimas l√≠neas del log ({os.path.basename(latest_log)}):\")\n",
    "    !tail -n 20 {latest_log}\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No se encontraron logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8e2af",
   "metadata": {},
   "source": [
    "## üìà PASO 6: An√°lisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_mpjpe_from_log(log_path):\n",
    "    \"\"\"Extrae el MPJPE del log\"\"\"\n",
    "    with open(log_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Buscar patr√≥n de MPJPE\n",
    "    pattern = r'MPJPE.*?(\\d+\\.\\d+)'\n",
    "    matches = re.findall(pattern, content)\n",
    "    \n",
    "    if matches:\n",
    "        return float(matches[-1])  # √öltimo valor\n",
    "    return None\n",
    "\n",
    "# Extraer resultados\n",
    "log_files = glob.glob('output/log/*.log')\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    mpjpe = extract_mpjpe_from_log(latest_log)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  üìä RESULTADOS FINALES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if mpjpe:\n",
    "        print(f\"\\n  MPJPE (Protocol 2): {mpjpe:.2f} mm\")\n",
    "        \n",
    "        # Comparar con paper\n",
    "        expected = {\n",
    "            'L': 42.3,\n",
    "            'M': 44.6\n",
    "        }\n",
    "        \n",
    "        # Determinar variante\n",
    "        for variant, expected_val in expected.items():\n",
    "            diff = abs(mpjpe - expected_val)\n",
    "            if diff < 5:\n",
    "                print(f\"\\n  Variante detectada: {variant}\")\n",
    "                print(f\"  Valor del paper: {expected_val:.2f} mm\")\n",
    "                print(f\"  Diferencia: {mpjpe - expected_val:+.2f} mm\")\n",
    "                \n",
    "                if diff < 2:\n",
    "                    print(\"  ‚úÖ Resultado excelente (dentro de ¬±2mm)\")\n",
    "                elif diff < 5:\n",
    "                    print(\"  ‚úì Resultado aceptable (dentro de ¬±5mm)\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No se pudo extraer MPJPE del log\")\n",
    "        print(\"Revisa el log manualmente en output/log/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"‚ùå No se encontraron logs de testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e80fd2",
   "metadata": {},
   "source": [
    "## üíæ PASO 7: Guardar Outputs\n",
    "\n",
    "Kaggle guarda autom√°ticamente todo en `/kaggle/working/`. Opcionalmente puedes copiar resultados espec√≠ficos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear resumen de resultados\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model': 'ConvNeXtPose-L',  # Cambiar seg√∫n modelo testeado\n",
    "    'checkpoint_epoch': CHECKPOINT_EPOCH,\n",
    "    'dataset': 'Human3.6M Protocol 2',\n",
    "    'mpjpe_mm': mpjpe if 'mpjpe' in locals() else None,\n",
    "    'pytorch_version': torch.__version__,\n",
    "    'cuda_version': torch.version.cuda if torch.cuda.is_available() else None\n",
    "}\n",
    "\n",
    "# Guardar resumen\n",
    "with open('output/result/test_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"‚úì Resumen guardado en output/result/test_summary.json\")\n",
    "print(\"\\nüìÑ Contenido:\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f63b45",
   "metadata": {},
   "source": [
    "## üéâ Testing Completado!\n",
    "\n",
    "Los resultados est√°n en:\n",
    "- **Logs**: `output/log/`\n",
    "- **Resultados**: `output/result/`\n",
    "- **Resumen JSON**: `output/result/test_summary.json`\n",
    "\n",
    "Todos los archivos en `/kaggle/working/ConvNeXtPose/output/` se guardar√°n autom√°ticamente cuando hagas commit del notebook."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
