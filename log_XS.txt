10-14 14:24:20 Creating dataset...
10-14 14:24:20 Creating dataset...
10-14 14:24:20 Creating dataset...
10-14 14:24:20 Creating dataset...

============================================================
  Testing ConvNeXtPose-XS
============================================================

‚úì Configuraci√≥n cargada para variante: XS
  - Backbone: depths=[3, 3, 9, 3], dims=[48, 96, 192, 384]
  - HeadNet: 2-UP (2 capas de upsampling)
>>> Using GPU: 0
‚úÖ CUDA habilitado
Load data of H36M Protocol 2
creating index...
index created!
Get bounding box and root from groundtruth
10-14 14:24:33 Load checkpoint from /kaggle/working/ConvNeXtPose/main/../output/model_dump/snapshot_83.pth
10-14 14:24:33 Load checkpoint from /kaggle/working/ConvNeXtPose/main/../output/model_dump/snapshot_83.pth
10-14 14:24:33 Load checkpoint from /kaggle/working/ConvNeXtPose/main/../output/model_dump/snapshot_83.pth
10-14 14:24:33 Load checkpoint from /kaggle/working/ConvNeXtPose/main/../output/model_dump/snapshot_83.pth
10-14 14:24:33 Creating graph...
10-14 14:24:33 Creating graph...
10-14 14:24:33 Creating graph...
10-14 14:24:33 Creating graph...
üìê Arquitectura: ConvNeXtPose-XS
   Backbone: 384 canales de salida
   HeadNet: 2-UP (2 capas de upsampling)
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-28-cbfa3a4e605b> in <cell line: 44>()
     42 tester = Tester()
     43 tester._make_batch_generator()
---> 44 tester._make_model(CHECKPOINT_EPOCH)
     45 
     46 print(f"\nüöÄ Ejecutando testing en epoch {CHECKPOINT_EPOCH}...\n")

/kaggle/working/ConvNeXtPose/main/../common/base.py in _make_model(self, test_epoch)
    237         else:
    238             # Para XS/S, usar carga est√°ndar
--> 239             model.load_state_dict(state_dict)
    240             self.logger.info("‚úì Checkpoint cargado (modo est√°ndar)")
    241 

/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in load_state_dict(self, state_dict, strict, assign)
   2582 
   2583         if len(error_msgs) > 0:
-> 2584             raise RuntimeError(
   2585                 "Error(s) in loading state_dict for {}:\n\t{}".format(
   2586                     self.__class__.__name__, "\n\t".join(error_msgs)

RuntimeError: Error(s) in loading state_dict for DataParallel:
	Missing key(s) in state_dict: "module.head.deconv_layers.0.dwconv.weight", "module.head.deconv_layers.0.dwconv.bias", "module.head.deconv_layers.0.norm.weight", "module.head.deconv_layers.0.norm.bias", "module.head.deconv_layers.0.norm.running_mean", "module.head.deconv_layers.0.norm.running_var", "module.head.deconv_layers.0.pwconv.weight", "module.head.deconv_layers.0.pwconv.bias", "module.head.deconv_layers.1.dwconv.weight", "module.head.deconv_layers.1.dwconv.bias", "module.head.deconv_layers.1.norm.weight", "module.head.deconv_layers.1.norm.bias", "module.head.deconv_layers.1.norm.running_mean", "module.head.deconv_layers.1.norm.running_var", "module.head.deconv_layers.1.pwconv.weight", "module.head.deconv_layers.1.pwconv.bias". 
	Unexpected key(s) in state_dict: "module.head.deconv_layers_1.0.weight", "module.head.deconv_layers_1.0.bias", "module.head.deconv_layers_1.1.weight", "module.head.deconv_layers_1.1.bias", "module.head.deconv_layers_1.1.running_mean", "module.head.deconv_layers_1.1.running_var", "module.head.deconv_layers_1.1.num_batches_tracked", "module.head.deconv_layers_1.2.weight", "module.head.deconv_layers_1.2.bias", "module.head.deconv_layers_2.0.weight", "module.head.deconv_layers_2.0.bias", "module.head.deconv_layers_2.1.weight", "module.head.deconv_layers_2.1.bias", "module.head.deconv_layers_2.1.running_mean", "module.head.deconv_layers_2.1.running_var", "module.head.deconv_layers_2.1.num_batches_tracked", "module.head.deconv_layers_2.2.weight", "module.head.deconv_layers_2.2.bias", "module.head.deconv_layers_3.0.weight", "module.head.deconv_layers_3.0.bias", "module.head.deconv_layers_3.1.weight", "module.head.deconv_layers_3.1.bias", "module.head.deconv_layers_3.1.running_mean", "module.head.deconv_layers_3.1.running_var", "module.head.deconv_layers_3.1.num_batches_tracked", "module.head.deconv_layers_3.2.weight", "module.head.deconv_layers_3.2.bias". 
	size mismatch for module.head.final_layer.weight: copying a param with shape torch.Size([1152, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 256, 1, 1]).
	size mismatch for module.head.final_layer.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([576]).