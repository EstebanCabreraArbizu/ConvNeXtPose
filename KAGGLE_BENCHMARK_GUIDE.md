# üöÄ Gu√≠a Completa: Benchmark de ConvNeXtPose en Kaggle

**Actualizado:** 17 de Octubre 2025  
**Notebook:** `convnextpose (5).ipynb`

---

## üìã Resumen

Este notebook ejecuta un benchmark automatizado de **todos los modelos ConvNeXtPose** (XS, S, M, L) en Kaggle con:

‚úÖ Configuraciones **verificadas desde checkpoints reales**  
‚úÖ Extracci√≥n autom√°tica de archivos `.tar` (formato legacy ‚Üí moderno)  
‚úÖ Mapeo correcto de keys para modelos M y L  
‚úÖ Comparaci√≥n autom√°tica con resultados del paper  
‚úÖ Gr√°ficos y reportes exportables  

---

## üéØ Configuraciones Verificadas

### An√°lisis de Checkpoints Reales:

Todos los valores han sido **extra√≠dos directamente de los checkpoints** pre-entrenados:

| Modelo | Params | Backbone | Head Kernels | Head Channels | MPJPE Esperado |
|--------|--------|----------|--------------|---------------|----------------|
| **XS** | 3.53M | Atto (7√ó7) | `[3,3,3]` | `[128,128,128]` | 56.61 mm |
| **S** | 7.45M | Femto-L (7√ó7) | `[3,3,3]` | `[256,256,256]` | 51.80 mm |
| **M** | 7.60M | Femto-L (7√ó7) | `[3,3,3]` | `[256,256,256]` | 51.05 mm |
| **L** | 8.39M | Femto-L (7√ó7) | `[3,3,3]` | `[512,512,512]` | 49.75 mm |

**Fuente:** Documentaci√≥n completa en `DIMENSIONES_KERNELS_VERIFICADAS.md`

---

## üîß Configuraci√≥n del Upsampling

### ‚úÖ Todos los Modelos Usan "Legacy Mode"

Los checkpoints pre-entrenados fueron guardados con **Legacy mode**, donde:

```python
cfg.head_cfg = None           # NO especificar head_cfg
cfg.depth = valor_por_modelo  # Controla canales del head
cfg.depth_dim = 64            # Profundidad de predicci√≥n 3D
```

### üìä Valores de `cfg.depth` por Modelo:

```python
# XS
cfg.depth = 128  # ‚Üí head channels [128, 128, 128]

# S
cfg.depth = 256  # ‚Üí head channels [256, 256, 256]

# M
cfg.depth = 256  # ‚Üí head channels [256, 256, 256]

# L
cfg.depth = 512  # ‚Üí head channels [512, 512, 512]
```

**Nota:** Aunque los modelos M y L tienen los mismos canales (256 y 512), difieren en el n√∫mero de capas con upsampling real:
- **M:** 3 capas con upsampling
- **L:** 3 capas con upsampling pero configuraci√≥n diferente internamente

---

## üóÇÔ∏è Extracci√≥n de Checkpoints

### Formato de Archivos `.tar`

Los checkpoints de ConvNeXtPose tienen un formato especial:

```
ConvNeXtPose_L.tar (archivo ZIP disfrazado)
‚îî‚îÄ‚îÄ snapshot_83.pth/          ‚Üê Directorio con formato legacy
    ‚îú‚îÄ‚îÄ data.pkl              ‚Üê Metadatos del checkpoint
    ‚îú‚îÄ‚îÄ version               ‚Üê Versi√≥n de PyTorch
    ‚îî‚îÄ‚îÄ data/                 ‚Üê Pesos del modelo
        ‚îú‚îÄ‚îÄ 0                 ‚Üê Storage files (binarios)
        ‚îú‚îÄ‚îÄ 1
        ‚îî‚îÄ‚îÄ ...
```

### Proceso de Conversi√≥n Autom√°tica:

El notebook incluye una funci√≥n `extract_checkpoint()` que:

1. ‚úÖ Detecta formato (ZIP o TAR real)
2. ‚úÖ Extrae contenido a directorio temporal
3. ‚úÖ Carga formato legacy con `LegacyUnpickler` personalizado
4. ‚úÖ Convierte a formato PyTorch moderno (`.pth`)
5. ‚úÖ Guarda en `output/model_dump/snapshot_XX.pth`
6. ‚úÖ Verifica integridad del checkpoint

**Resultado:** Archivos `.pth` est√°ndar compatibles con `torch.load()`

---

## üîë Mapeo de Keys Legacy ‚Üí Moderno

### Problema:

Los modelos M y L usan un formato de naming diferente a XS y S:

```python
# Formato XS, S (moderno):
'module.head.deconv_layers_1.dwconv.weight'
'module.head.deconv_layers_1.norm.bias'
'module.head.deconv_layers_1.pwconv.weight'

# Formato M, L (legacy):
'module.head.deconv_layers_1.0.weight'    # dwconv
'module.head.deconv_layers_1.1.bias'      # norm
'module.head.deconv_layers_1.2.weight'    # pwconv
```

### Soluci√≥n:

El notebook incluye la funci√≥n `map_legacy_head_keys()`:

```python
def map_legacy_head_keys(state_dict):
    """Mapea keys del formato legacy (M, L) al formato moderno (XS, S)"""
    new_state = OrderedDict()
    for k, v in state_dict.items():
        if k.startswith('module.head.deconv_layers_'):
            suffix = k.split('.', 3)[-1]
            
            # Mapeo: .0 ‚Üí .dwconv, .1 ‚Üí .norm, .2 ‚Üí .pwconv
            if suffix.startswith('0.'):
                new_k = k.replace('.0.', '.dwconv.')
            elif suffix.startswith('1.'):
                new_k = k.replace('.1.', '.norm.')
            elif suffix.startswith('2.'):
                new_k = k.replace('.2.', '.pwconv.')
            else:
                new_k = k
            
            new_state[new_k] = v
        else:
            new_state[k] = v
    
    return new_state
```

Este mapeo se aplica **autom√°ticamente** al cargar los checkpoints de M y L.

---

## üìù Uso del Notebook

### 1Ô∏è‚É£ **Setup Inicial**

```python
# Celda 1: Clonar repositorio
!git clone https://github.com/EstebanCabreraArbizu/ConvNeXtPose.git
%cd ConvNeXtPose

# Verificar GPU
import torch
print(f"CUDA: {torch.cuda.is_available()}")
print(f"GPU: {torch.cuda.get_device_name(0)}")
```

### 2Ô∏è‚É£ **Configurar Dataset Human3.6M**

```python
# Celda 2: Enlazar dataset de Kaggle
KAGGLE_DATASET_PATH = '/kaggle/input/tu-dataset-human36m'

!python setup_kaggle_dataset.py --kaggle-input {KAGGLE_DATASET_PATH} \
                                 --project-root /kaggle/working/ConvNeXtPose
```

### 3Ô∏è‚É£ **Descargar y Extraer Checkpoints**

```python
# Celda 3: Descargar desde Google Drive
import gdown

folder_id = "12H7zkLvmJtrkCmAUAPkQ6788WAnO60gI"
gdown.download_folder(id=folder_id, output="models_tar", quiet=False)

# Celda 4: Extraer y convertir (autom√°tico)
# La funci√≥n extract_checkpoint() maneja todo el proceso
```

### 4Ô∏è‚É£ **Ejecutar Benchmark**

```python
# Celda 5: Benchmark automatizado de todos los modelos
# El script test_model() ejecuta secuencialmente:
# - XS (epoch detectado autom√°ticamente)
# - S (epoch detectado autom√°ticamente)
# - M (epoch detectado autom√°ticamente)
# - L (epoch detectado autom√°ticamente)

# Tiempo estimado: 40-80 minutos para los 4 modelos (GPU T4 x2)
```

### 5Ô∏è‚É£ **Analizar Resultados**

```python
# Celda 6: Generar gr√°ficos y an√°lisis
# Crea autom√°ticamente:
# - benchmark_results.json (datos estructurados)
# - BENCHMARK_REPORT.md (reporte completo)
# - benchmark_comparison.png (gr√°ficos)
```

---

## üìä Resultados Esperados

### Comparaci√≥n con el Paper:

El benchmark compara autom√°ticamente los resultados obtenidos con los del paper:

| Modelo | MPJPE Paper | Rango Aceptable | Clasificaci√≥n |
|--------|-------------|-----------------|---------------|
| XS | 56.61 mm | 55.6 - 57.6 mm | ¬±1mm Excelente |
| S | 51.80 mm | 50.8 - 52.8 mm | ¬±1mm Excelente |
| M | 51.05 mm | 50.0 - 52.0 mm | ¬±1mm Excelente |
| L | 49.75 mm | 48.8 - 50.8 mm | ¬±1mm Excelente |

**Criterios de Evaluaci√≥n:**
- ‚úÖ **Excelente:** Diferencia < 1mm
- ‚úì‚úì **Muy bueno:** Diferencia < 2mm
- ‚úì **Aceptable:** Diferencia < 5mm
- ‚ö†Ô∏è **Revisar:** Diferencia ‚â• 5mm

---

## üõ†Ô∏è Troubleshooting

### Problema: "Checkpoint no encontrado"

**Causa:** Extracci√≥n incompleta o path incorrecto

**Soluci√≥n:**
```python
# Verificar checkpoints extra√≠dos
!ls -lh output/model_dump/

# Re-ejecutar extracci√≥n si es necesario
```

### Problema: "Size mismatch en head.deconv_layers"

**Causa:** Configuraci√≥n incorrecta de `cfg.depth`

**Soluci√≥n:**
```python
# Verificar que usas Legacy mode:
cfg.head_cfg = None  # ‚Üê IMPORTANTE
cfg.depth = valor_correcto  # Ver tabla arriba
```

### Problema: "Keys no coinciden (modelos M, L)"

**Causa:** Formato legacy no mapeado

**Soluci√≥n:** El notebook aplica `map_legacy_head_keys()` autom√°ticamente. Si persiste:
```python
# Verificar que el mapeo se est√° aplicando
state_dict = map_legacy_head_keys(checkpoint['network'])
model.load_state_dict(state_dict)
```

### Problema: "Testing muy lento"

**Causa:** Ejecutando en CPU en lugar de GPU

**Soluci√≥n:**
1. Settings ‚Üí Accelerator ‚Üí **GPU T4 x2**
2. Reiniciar notebook
3. Verificar con `torch.cuda.is_available()`

---

## üìÅ Estructura de Archivos Generados

Despu√©s de ejecutar el benchmark:

```
/kaggle/working/ConvNeXtPose/
‚îú‚îÄ‚îÄ output/
‚îÇ   ‚îú‚îÄ‚îÄ model_dump/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ snapshot_XX.pth  (XS)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ snapshot_YY.pth  (S)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ snapshot_ZZ.pth  (M)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ snapshot_WW.pth  (L)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ result/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ benchmark_results.json       ‚Üê Resultados estructurados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BENCHMARK_REPORT.md          ‚Üê Reporte completo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ benchmark_comparison.png     ‚Üê Gr√°ficos comparativos
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ log/
‚îÇ       ‚îú‚îÄ‚îÄ test_XS.log
‚îÇ       ‚îú‚îÄ‚îÄ test_S.log
‚îÇ       ‚îú‚îÄ‚îÄ test_M.log
‚îÇ       ‚îî‚îÄ‚îÄ test_L.log
```

---

## üíæ Guardar y Exportar Resultados

### Opci√≥n 1: Commit del Notebook

Kaggle guarda autom√°ticamente todo en `/kaggle/working/` al hacer commit.

### Opci√≥n 2: Descargar Output

```python
# En la √∫ltima celda del notebook:
!zip -r benchmark_results.zip output/result/
!zip -r benchmark_logs.zip output/log/

# Descargar desde el panel de Output del notebook
```

### Opci√≥n 3: Copiar a Dataset

```python
# Crear un nuevo dataset de Kaggle con los resultados
!kaggle datasets init -p output/result/
# Editar dataset-metadata.json
!kaggle datasets create -p output/result/
```

---

## üî¨ Validaci√≥n de Configuraciones

Para verificar que las configuraciones son correctas:

```python
# Script de verificaci√≥n r√°pida
import torch
from main.config import cfg
from main.model import get_pose_net

def verify_model_config(model_name, variant, backbone_cfg, depth):
    """Verifica que la configuraci√≥n carga correctamente"""
    cfg.head_cfg = None
    cfg.variant = variant
    cfg.backbone_cfg = backbone_cfg
    cfg.depth = depth
    cfg.depth_dim = 64
    
    # Crear modelo
    model = get_pose_net(cfg, is_train=False, joint_num=17)
    
    # Contar par√°metros
    total_params = sum(p.numel() for p in model.parameters())
    
    print(f"{model_name}: {total_params/1e6:.2f}M par√°metros")
    
    return model

# Verificar todos los modelos
verify_model_config('XS', 'Atto', ([2,2,6,2],[40,80,160,320]), 128)
verify_model_config('S', 'Femto-L', ([3,3,9,3],[48,96,192,384]), 256)
verify_model_config('M', 'Femto-L', ([3,3,9,3],[48,96,192,384]), 256)
verify_model_config('L', 'Femto-L', ([3,3,9,3],[48,96,192,384]), 512)
```

**Par√°metros esperados:**
- XS: ~3.53M
- S: ~7.45M
- M: ~7.60M
- L: ~8.39M

---

## üìö Documentaci√≥n Adicional

- **An√°lisis de Kernels:** `DIMENSIONES_KERNELS_VERIFICADAS.md`
- **Gu√≠a Completa:** `GUIA_COMPLETA_ACTUALIZADA.md`
- **Paper Original:** ConvNeXtPose (IEEE Access 2023)
- **Repositorio:** https://github.com/EstebanCabreraArbizu/ConvNeXtPose

---

## ‚úÖ Checklist de Ejecuci√≥n

Antes de ejecutar el benchmark, verifica:

- [ ] GPU activada (T4 x2 o P100)
- [ ] Dataset Human3.6M enlazado correctamente
- [ ] Checkpoints descargados y extra√≠dos
- [ ] Configuraciones verificadas (Legacy mode)
- [ ] Espacio suficiente en disco (~5GB)

Durante la ejecuci√≥n:

- [ ] Monitor GPU usage (`nvidia-smi`)
- [ ] Verificar logs en tiempo real
- [ ] Guardar resultados parciales

Despu√©s de completar:

- [ ] Revisar BENCHMARK_REPORT.md
- [ ] Comparar gr√°ficos generados
- [ ] Exportar resultados
- [ ] Documentar hallazgos

---

## üéØ Conclusiones

Este notebook proporciona:

‚úÖ **Configuraciones 100% verificadas** desde checkpoints reales  
‚úÖ **Extracci√≥n autom√°tica** de archivos `.tar` legacy  
‚úÖ **Mapeo correcto** de keys para todos los modelos  
‚úÖ **Benchmark completo** de los 4 modelos  
‚úÖ **An√°lisis comparativo** autom√°tico con el paper  
‚úÖ **Resultados exportables** en m√∫ltiples formatos  

**Tiempo total:** ~1-2 horas (incluyendo descarga y extracci√≥n)  
**Costo:** Gratis en Kaggle con GPU T4 x2

---

**¬øPreguntas o problemas?**  
Consulta la documentaci√≥n completa o abre un issue en el repositorio.

**¬°Buena suerte con tu benchmark!** üöÄ
