# ðŸ“š DocumentaciÃ³n: Testing ConvNeXtPose Modelos L y M

## Ãndice de DocumentaciÃ³n

Esta es la documentaciÃ³n completa para testear los modelos **L (Large)** y **M (Medium)** de ConvNeXtPose en el dataset Human3.6M usando el Protocolo 2.

---

## ðŸ“– GuÃ­as Disponibles

### 1. ðŸš€ RESUMEN_EJECUTIVO.md
**Para**: Comenzar rÃ¡pidamente  
**Tiempo de lectura**: 5 minutos  
**Contenido**:
- TL;DR con pasos principales
- Comandos de una lÃ­nea
- Diferencias clave vs configuraciÃ³n actual
- Tips importantes

ðŸ‘‰ **Usa esto si**: Necesitas comenzar YA y tienes experiencia previa

---

### 2. âœ… CHECKLIST_TESTING.md
**Para**: Seguimiento paso a paso interactivo  
**Tiempo de lectura**: 10 minutos  
**Contenido**:
- 10 fases con checkboxes
- Comandos especÃ­ficos para cada paso
- VerificaciÃ³n de Ã©xito
- Troubleshooting rÃ¡pido

ðŸ‘‰ **Usa esto si**: Prefieres una lista de tareas clara y organizada

---

### 3. ðŸ“˜ GUIA_TESTING_MODELOS_L_M.md
**Para**: GuÃ­a completa y detallada  
**Tiempo de lectura**: 30 minutos  
**Contenido**:
- 13 pasos detallados con explicaciones
- Scripts de ejemplo completos
- Troubleshooting extensivo
- AnÃ¡lisis avanzado y benchmarking
- Configuraciones arquitectÃ³nicas detalladas

ðŸ‘‰ **Usa esto si**: Quieres entender TODO el proceso en profundidad

---

## ðŸ› ï¸ Scripts Implementados

### 1. main/config_variants.py
**PropÃ³sito**: Definir configuraciones de arquitectura  
**Funciones principales**:
- `get_model_config(variant)`: Obtiene (depths, dims) para una variante
- `print_model_info(variant)`: Muestra informaciÃ³n detallada
- `compare_variants()`: Tabla comparativa de todas las variantes
- `get_recommended_batch_size()`: Recomienda batch size segÃºn GPU

**Ejemplo de uso**:
```python
from config_variants import get_model_config, print_model_info

# Obtener configuraciÃ³n
depths, dims = get_model_config('M')

# Ver info
print_model_info('M')
```

---

### 2. main/test_variants.py
**PropÃ³sito**: Testing de modelos con soporte para variantes  
**Argumentos principales**:
- `--variant`: Variante del modelo (XS, S, M, L)
- `--epoch`: NÃºmero de epoch del checkpoint
- `--gpu`: ID de GPU a usar
- `--protocol`: Protocolo de evaluaciÃ³n (1 o 2)
- `--flip_test`: Habilitar flip augmentation
- `--use_gt_bbox`: Usar GT bounding box

**Ejemplo de uso**:
```bash
python test_variants.py --variant M --gpu 0 --epoch 70 --protocol 2 --flip_test
```

---

### 3. main/compare_variants.py
**PropÃ³sito**: Comparar resultados entre variantes  
**Argumentos principales**:
- `--variants`: Variantes a comparar
- `--epoch`: Epoch a analizar
- `--plot`: Generar grÃ¡ficos
- `--save_report`: Guardar reporte markdown

**Ejemplo de uso**:
```bash
python compare_variants.py --variants M L --epoch 70 --plot --save_report
```

---

### 4. quick_start.sh
**PropÃ³sito**: Script bash interactivo para setup y testing  
**Funciones**:
- VerificaciÃ³n automÃ¡tica de entorno
- DetecciÃ³n de GPU y CUDA
- VerificaciÃ³n de estructura de datos
- MenÃº interactivo de comandos
- EjecuciÃ³n guiada

**Ejemplo de uso**:
```bash
bash quick_start.sh
```

---

## ðŸ—ºï¸ Flujo de Trabajo Recomendado

### Para Principiantes
```
1. RESUMEN_EJECUTIVO.md (entender el objetivo)
   â†“
2. bash quick_start.sh (verificar entorno)
   â†“
3. CHECKLIST_TESTING.md (seguir paso a paso)
   â†“
4. Ejecutar testing con test_variants.py
   â†“
5. Comparar con compare_variants.py
```

### Para Usuarios Avanzados
```
1. RESUMEN_EJECUTIVO.md (comandos rÃ¡pidos)
   â†“
2. test_variants.py directo
   â†“
3. compare_variants.py con --plot --save_report
   â†“
4. GUIA_TESTING_MODELOS_L_M.md (troubleshooting si es necesario)
```

### Para InvestigaciÃ³n Profunda
```
1. GUIA_TESTING_MODELOS_L_M.md (leer completa)
   â†“
2. Entender configuraciones en config_variants.py
   â†“
3. Experimentar con diferentes configuraciones
   â†“
4. Benchmark avanzado (Paso 12 de la guÃ­a)
   â†“
5. AnÃ¡lisis comparativo detallado
```

---

## ðŸŽ¯ Comandos Esenciales

### Setup Inicial
```bash
# 1. Navegar al directorio
cd /home/user/convnextpose_esteban/ConvNeXtPose

# 2. Verificar entorno
bash quick_start.sh

# 3. O manual: instalar dependencias
pip install torch torchvision timm pycocotools opencv-python tqdm numpy matplotlib
```

### Testing
```bash
# Modelo M
cd main
python test_variants.py --variant M --gpu 0 --epoch 70 --protocol 2 --flip_test --use_gt_bbox

# Modelo L
python test_variants.py --variant L --gpu 0 --epoch 70 --protocol 2 --flip_test --use_gt_bbox
```

### ComparaciÃ³n
```bash
cd main
python compare_variants.py --variants M L --epoch 70 --protocol 2 --plot --save_report
```

---

## ðŸ“Š Configuraciones de Modelos

### Resumen RÃ¡pido

| Variante | Depths        | Dims                    | Params | GFLOPs | MPJPE (mm) |
|----------|---------------|-------------------------|--------|--------|------------|
| XS       | [3,3,9,3]     | [48,96,192,384]        | 22M    | 4.5    | ~52        |
| S        | [3,3,27,3]    | [96,192,384,768]       | 50M    | 8.7    | ~48        |
| **M**    | [3,3,27,3]    | [128,256,512,1024]     | 89M    | 15.4   | **44.6**   |
| **L**    | [3,3,27,3]    | [192,384,768,1536]     | 198M   | 34.4   | **42.3**   |

### Diferencias Clave M vs L

**Modelo M (Medium)**:
- Depths: `[3, 3, 27, 3]`
- Dims: `[128, 256, 512, 1024]`
- Balance Ã³ptimo precisiÃ³n/velocidad
- Recomendado para prototipado

**Modelo L (Large)**:
- Depths: `[3, 3, 27, 3]`
- Dims: `[192, 384, 768, 1536]`
- MÃ¡xima precisiÃ³n
- Recomendado para resultados finales

---

## ðŸ” Estructura de Archivos

### Archivos de DocumentaciÃ³n
```
ConvNeXtPose/
â”œâ”€â”€ README_TESTING.md              # â† Este archivo (Ã­ndice)
â”œâ”€â”€ RESUMEN_EJECUTIVO.md           # Vista rÃ¡pida
â”œâ”€â”€ CHECKLIST_TESTING.md           # Checklist paso a paso
â”œâ”€â”€ GUIA_TESTING_MODELOS_L_M.md    # GuÃ­a completa
â””â”€â”€ quick_start.sh                 # Script bash interactivo
```

### Scripts de Testing
```
ConvNeXtPose/main/
â”œâ”€â”€ config_variants.py             # Configuraciones de variantes
â”œâ”€â”€ test_variants.py               # Testing adaptado
â””â”€â”€ compare_variants.py            # ComparaciÃ³n de resultados
```

### Archivos de Entrada
```
ConvNeXtPose/
â”œâ”€â”€ data/Human36M/                 # Dataset
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ annotations/
â”‚   â””â”€â”€ bbox_root/
â””â”€â”€ output/model_dump/             # Checkpoints
    â””â”€â”€ snapshot_70.pth.tar
```

### Archivos de Salida
```
ConvNeXtPose/output/
â”œâ”€â”€ result/
â”‚   â”œâ”€â”€ bbox_root_pose_human36m_output.json  # Predicciones
â”‚   â”œâ”€â”€ results_M_epoch70.json               # MÃ©tricas M
â”‚   â”œâ”€â”€ results_L_epoch70.json               # MÃ©tricas L
â”‚   â”œâ”€â”€ comparison_plot.png                  # GrÃ¡fico comparativo
â”‚   â””â”€â”€ comparison_report.md                 # Reporte
â””â”€â”€ log/                                      # Logs de ejecuciÃ³n
```

---

## âš™ï¸ ConfiguraciÃ³n del Protocolo 2

### Diferencias Protocol 1 vs 2

**Protocol 1 (PA-MPJPE)**:
- Training: S1, S5, S6, S7, S8, S9
- Testing: **S11**
- MÃ©trica: PA-MPJPE (con alineaciÃ³n Procrustes)
- MÃ¡s fÃ¡cil (~2-3mm mejor)

**Protocol 2 (MPJPE)** â† **Usamos este**:
- Training: S1, S5, S6, S7, S8
- Testing: **S9, S11**
- MÃ©trica: MPJPE (sin alineaciÃ³n)
- MÃ¡s estricto (posiciÃ³n absoluta)

### Verificar Protocolo

```bash
grep "self.protocol" data/Human36M/Human36M.py
# Debe mostrar: self.protocol = 2
```

Si muestra `self.protocol = 1`, cambiar a 2:
```python
# data/Human36M/Human36M.py lÃ­nea ~30
self.protocol = 2
```

---

## ðŸŽ“ Resultados Esperados

### Protocol 2 (MPJPE)

**Modelo M**:
- Total: **44.6 mm**
- Rango aceptable: 43-46 mm
- Mejor acciÃ³n: Directions (~39.8 mm)
- Peor acciÃ³n: Greeting (~46.9 mm)

**Modelo L**:
- Total: **42.3 mm**
- Rango aceptable: 41-44 mm
- Mejor acciÃ³n: Directions (~37.9 mm)
- Peor acciÃ³n: Greeting (~44.5 mm)

**Mejora L vs M**: ~2.3 mm (~5.2%)

---

## ðŸ› Troubleshooting RÃ¡pido

### Problema: Out of Memory
**SoluciÃ³n**: Reducir batch size
```bash
python test_variants.py --variant L --gpu 0 --epoch 70 --batch_size 8
```

### Problema: Modelo no carga
**SoluciÃ³n**: Verificar nombre del checkpoint
```bash
# Debe ser: snapshot_70.pth.tar
ls -la output/model_dump/
mv output/model_dump/OLD_NAME.pth output/model_dump/snapshot_70.pth.tar
```

### Problema: Dataset no encontrado
**SoluciÃ³n**: Verificar estructura
```bash
ls data/Human36M/images/ | wc -l  # Debe ser > 0
ls data/Human36M/annotations/*.json
```

### Problema: Resultados muy diferentes al paper
**Causas posibles**:
1. Protocolo incorrecto (verificar que sea 2)
2. Checkpoint no corresponde a la variante
3. ConfiguraciÃ³n de bbox incorrecta
4. Datos incompletos o corruptos

---

## ðŸ“ž PrÃ³ximos Pasos

### 1. PreparaciÃ³n
- [ ] Leer RESUMEN_EJECUTIVO.md
- [ ] Ejecutar `bash quick_start.sh`
- [ ] Verificar que todo estÃ¡ listo

### 2. Testing
- [ ] Testear Modelo M
- [ ] Testear Modelo L
- [ ] Verificar resultados

### 3. AnÃ¡lisis
- [ ] Comparar M vs L
- [ ] Generar grÃ¡ficos
- [ ] Crear reporte

### 4. ValidaciÃ³n
- [ ] Verificar que MPJPE estÃ¡ en rango esperado
- [ ] Confirmar que L > M en precisiÃ³n
- [ ] Documentar hallazgos

---

## ðŸŒŸ Recursos Adicionales

### Paper Original
- **TÃ­tulo**: ConvNeXtPose: A Fast Accurate Method for 3D Human Pose Estimation
- **Journal**: IEEE Access 2023
- **Link**: https://ieeexplore.ieee.org/document/10288440

### Repositorio Oficial
- **GitHub**: https://github.com/medialab-ku/ConvNeXtPose
- **Modelos**: https://drive.google.com/drive/folders/12H7zkLvmJtrkCmAUAPkQ6788WAnO60gI

### Dataset Human3.6M
- **Website**: http://vision.imar.ro/human3.6m/
- **DescripciÃ³n**: Dataset de pose 3D mÃ¡s grande
- **Sujetos**: 11 actores, 15 acciones

---

## ðŸ“§ Soporte

Si tienes problemas:

1. **Primero**: Consulta la secciÃ³n de troubleshooting en cada guÃ­a
2. **Segundo**: Ejecuta `bash quick_start.sh` para diagnÃ³stico
3. **Tercero**: Revisa logs en `output/log/`
4. **Cuarto**: Verifica que seguiste todos los pasos del checklist

---

## âœ… Checklist de Inicio RÃ¡pido

Antes de empezar, verifica:

- [ ] Python 3.8+ instalado
- [ ] PyTorch con CUDA funcionando
- [ ] GPU con â‰¥8GB VRAM (o â‰¥4GB para M solo)
- [ ] Dataset Human3.6M descargado
- [ ] Modelos pre-entrenados descargados
- [ ] Scripts de testing creados (config_variants.py, test_variants.py, compare_variants.py)
- [ ] Protocolo configurado a 2

Si todos estÃ¡n âœ…, estÃ¡s listo para comenzar:

```bash
bash quick_start.sh
```

---

**Ãšltima actualizaciÃ³n**: Octubre 2025  
**VersiÃ³n**: 1.0  
**Mantenedor**: Testing adaptado para modelos L y M

---

## ðŸš€ Â¡Comienza Ahora!

### OpciÃ³n 1: Guiado (Recomendado)
```bash
bash quick_start.sh
```

### OpciÃ³n 2: Manual RÃ¡pido
```bash
cd main
python test_variants.py --variant M --gpu 0 --epoch 70 --protocol 2 --flip_test
python test_variants.py --variant L --gpu 0 --epoch 70 --protocol 2 --flip_test
python compare_variants.py --variants M L --epoch 70 --plot --save_report
```

### OpciÃ³n 3: Explorar DocumentaciÃ³n
1. Lee `RESUMEN_EJECUTIVO.md` para vista general
2. Sigue `CHECKLIST_TESTING.md` paso a paso
3. Consulta `GUIA_TESTING_MODELOS_L_M.md` para detalles

---

**Â¡Ã‰xito en tu testing!** ðŸŽ‰
