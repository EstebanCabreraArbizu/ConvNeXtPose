# üö® Hallazgo Cr√≠tico: Diferencias en depth_dim entre Modelos

**Fecha:** 19 de Octubre 2025  
**Estado:** ‚úÖ RESUELTO

---

## üîç Problema Detectado

Al ejecutar benchmarks, los modelos **XS y S fallaban al cargar checkpoints** con este error:

```
RuntimeError: size mismatch for module.head.final_layer.weight: 
  copying a param with shape torch.Size([576, 128, 1, 1]) from checkpoint, 
  the shape in current model is torch.Size([1152, 128, 1, 1])
```

Mientras que **M y L cargaban correctamente**.

---

## üéØ Root Cause

### Diferencia en `cfg.depth_dim` por Modelo

Los checkpoints pre-entrenados **NO usan el mismo `depth_dim`** para todos los modelos:

| Modelo | depth_dim | final_layer canales | Checkpoint size |
|--------|-----------|---------------------|-----------------|
| **XS** | **32** | 18 √ó 32 = **576** | `snapshot_68.pth` |
| **S**  | **32** | 18 √ó 32 = **576** | `snapshot_67.pth` |
| **M**  | **64** | 18 √ó 64 = **1152** | `snapshot_70.pth` |
| **L**  | **64** | 18 √ó 64 = **1152** | `snapshot_83.pth` |

### ¬øPor Qu√© Fallaba el C√≥digo?

El archivo `main/config.py` ten√≠a **hardcoded `depth_dim = 64`** para todos:

```python
# config.py (ANTES)
depth_dim = 64  # ‚Üê Aplicaba a TODOS los modelos
```

Esto causaba que:
1. XS/S: c√≥digo creaba `final_layer` con 1152 canales, pero checkpoint ten√≠a 576 ‚Üí **ERROR**
2. M/L: c√≥digo creaba 1152 canales, checkpoint ten√≠a 1152 ‚Üí **OK**

---

## ‚úÖ Soluci√≥n

### Configurar `depth_dim` por Modelo

```python
MODEL_CONFIGS = {
    'XS': {
        'variant': 'Atto',
        'backbone_cfg': ([2,2,6,2], [40,80,160,320]),
        'depth': 128,
        'depth_dim': 32,  # ‚ö†Ô∏è CR√çTICO: 32, no 64
        'expected_mpjpe': 56.61
    },
    'S': {
        'variant': 'Femto-L',
        'backbone_cfg': ([3,3,9,3], [48,96,192,384]),
        'depth': 256,
        'depth_dim': 32,  # ‚ö†Ô∏è CR√çTICO: 32, no 64
        'expected_mpjpe': 51.80
    },
    'M': {
        'variant': 'Femto-L',
        'backbone_cfg': ([3,3,9,3], [48,96,192,384]),
        'depth': 256,
        'depth_dim': 64,  # OK: 64
        'expected_mpjpe': 51.05
    },
    'L': {
        'variant': 'Femto-L',
        'backbone_cfg': ([3,3,9,3], [48,96,192,384]),
        'depth': 512,
        'depth_dim': 64,  # OK: 64
        'expected_mpjpe': 49.75
    }
}
```

### Aplicar en el C√≥digo

```python
# Antes de crear el modelo
cfg.depth_dim = config['depth_dim']  # ‚Üê Configurar seg√∫n modelo
cfg.set_args('0')

# Ahora HeadNet crear√° final_layer con tama√±o correcto:
# XS/S: joint_num √ó 32 = 576 canales
# M/L: joint_num √ó 64 = 1152 canales
```

---

## üß™ Verificaci√≥n

### Estado de Validaci√≥n de Checkpoints

```
======================================================================
 üî¨ VALIDACI√ìN PROFUNDA DE CHECKPOINTS CONVERTIDOS
======================================================================

XS: ‚úÖ OK (sin problemas)
S:  ‚úÖ OK (sin problemas)
M:  ‚ö†Ô∏è WARNINGS (formato legacy, no cr√≠tico)
L:  ‚ö†Ô∏è WARNINGS (formato legacy, no cr√≠tico)
```

Los warnings de M/L son **solo sobre formato de keys legacy** (`.0/.1/.2`), que se resuelven con `map_legacy_head_keys()`. **No son cr√≠ticos**.

### Benchmark Esperado Despu√©s del Fix

Con `depth_dim` configurado correctamente, **todos los modelos deber√≠an cargar** y mostrar:

```
| Modelo | Params | MPJPE (mm) | Esperado (mm) | Diff (mm) | Estado |
|--------|--------|------------|---------------|-----------|--------|
| XS     | 3.53M  | ~56.61     | 56.61         | ~0        | ‚úÖ      |
| S      | 7.45M  | ~51.80     | 51.80         | ~0        | ‚úÖ      |
| M      | 7.60M  | ~51.05     | 51.05         | ~0        | ‚úÖ      |
| L      | 8.39M  | ~49.75     | 49.75         | ~0        | ‚úÖ      |
```

---

## üìù Lecciones Aprendidas

### 1. ‚ö†Ô∏è No Asumir Configuraci√≥n Uniforme

Aunque los modelos XS/S/M/L comparten arquitectura base (3 deconv layers, kernels 3x3), **tienen configuraciones internas diferentes**:
- `depth_dim` var√≠a (32 vs 64)
- `depth` (canales head) var√≠a (128/256/512)
- Naming de keys var√≠a (moderno vs legacy)

### 2. üîç Validar Checkpoints Antes de Benchmark

La celda de validaci√≥n profunda fue crucial para detectar que:
- Los checkpoints estaban **correctos**
- El problema estaba en la **configuraci√≥n del c√≥digo**
- Los warnings de M/L eran **inofensivos**

### 3. üß© Entender la Arquitectura del Head

```python
class HeadNet:
    def __init__(self, joint_num, in_channel, head_cfg=None):
        # ...
        self.final_layer = nn.Conv2d(
            in_channels=self.final_channels,  # depth (128/256/512)
            out_channels=joint_num * cfg.depth_dim,  # ‚Üê AQU√ç estaba el problema
            kernel_size=1
        )
```

`final_layer` produce heatmaps 3D con resoluci√≥n:
- Espacial: `output_shape[0] √ó output_shape[1]` (32√ó32)
- Profundidad: `cfg.depth_dim` (32 o 64 bins)
- Articulaciones: `joint_num` (18)

---

## üöÄ Pr√≥ximos Pasos

1. **Ejecutar benchmark con fix aplicado** en el notebook de Kaggle
2. **Verificar que XS/S cargan correctamente** sin RuntimeError
3. **Comparar MPJPE obtenido vs esperado** para todos los modelos
4. **Documentar resultados finales** en `BENCHMARK_REPORT.md`

---

## üìö Referencias

- **Issue Original:** RuntimeError en XS/S al cargar checkpoints
- **Archivos Modificados:** `convnextpose (5).ipynb` (celda de benchmark)
- **Validaci√≥n:** Celda de validaci√≥n profunda confirma integridad de checkpoints
- **Paper:** ConvNeXtPose (IEEE Access 2023)

---

**Autor:** GitHub Copilot  
**Colaborador:** Esteban Cabrera Arbizu
