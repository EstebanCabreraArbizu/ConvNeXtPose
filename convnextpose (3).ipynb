{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎯 ConvNeXtPose Testing en Kaggle - Modelo XS\n",
    "\n",
    "Este notebook evalúa el modelo ConvNeXtPose XS en Human3.6M Protocol 2.\n",
    "\n",
    "**⚠️ IMPORTANTE:** Los checkpoints descargados etiquetados como \"L\", \"M\", y \"S\" contienen TODOS la arquitectura **XS**:\n",
    "- dims = `[48, 96, 192, 384]`\n",
    "- depths = `[3, 3, 9, 3]`\n",
    "\n",
    "Ver `CHECKPOINT_ARCHITECTURE_ANALYSIS.md` para análisis completo.\n",
    "\n",
    "**Datasets requeridos:**\n",
    "- Human3.6M Dataset (con S9_ACT2_16, S11_ACT2_16, annotations)\n",
    "- ConvNeXtPose Pre-trained Models (checkpoints .tar)\n",
    "\n",
    "**GPU recomendada:** T4 x2 o P100\n",
    "\n",
    "**Resultados esperados (XS):**\n",
    "- MPJPE (Protocol 2): ~52.0 mm\n",
    "- PA-MPJPE (Protocol 1): ~36.5 mm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 PASO 1: Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:01.076350Z",
     "iopub.status.busy": "2025-10-14T13:09:01.075988Z",
     "iopub.status.idle": "2025-10-14T13:09:01.192919Z",
     "shell.execute_reply": "2025-10-14T13:09:01.191852Z",
     "shell.execute_reply.started": "2025-10-14T13:09:01.076305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:01.194721Z",
     "iopub.status.busy": "2025-10-14T13:09:01.194418Z",
     "iopub.status.idle": "2025-10-14T13:09:01.198544Z",
     "shell.execute_reply": "2025-10-14T13:09:01.197567Z",
     "shell.execute_reply.started": "2025-10-14T13:09:01.194691Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!rm -r ConvNeXtPose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:01.200474Z",
     "iopub.status.busy": "2025-10-14T13:09:01.200169Z",
     "iopub.status.idle": "2025-10-14T13:09:17.597159Z",
     "shell.execute_reply": "2025-10-14T13:09:17.596397Z",
     "shell.execute_reply.started": "2025-10-14T13:09:01.200452Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ConvNeXtPose'...\n",
      "remote: Enumerating objects: 1166, done.\u001b[K\n",
      "remote: Counting objects: 100% (288/288), done.\u001b[K\n",
      "remote: Compressing objects: 100% (225/225), done.\u001b[K\n",
      "remote: Total 1166 (delta 103), reused 222 (delta 62), pack-reused 878 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1166/1166), 318.73 MiB | 40.05 MiB/s, done.\n",
      "Resolving deltas: 100% (341/341), done.\n",
      "Updating files: 100% (207/207), done.\n",
      "/kaggle/working/ConvNeXtPose\n",
      "PyTorch: 2.5.1+cu121\n",
      "CUDA disponible: True\n",
      "GPU: Tesla T4\n",
      "Memoria GPU: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "# Clonar repositorio\n",
    "!git clone https://github.com/EstebanCabreraArbizu/ConvNeXtPose.git\n",
    "%cd ConvNeXtPose\n",
    "!git fetch origin\n",
    "\n",
    "# Verificar versiones\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🗂️ PASO 2: Configurar Dataset Human3.6M\n",
    "\n",
    "Usamos enlaces simbólicos para evitar copiar ~30GB de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:17.598891Z",
     "iopub.status.busy": "2025-10-14T13:09:17.598573Z",
     "iopub.status.idle": "2025-10-14T13:09:17.721633Z",
     "shell.execute_reply": "2025-10-14T13:09:17.720586Z",
     "shell.execute_reply.started": "2025-10-14T13:09:17.598872Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ConvNeXtPose\n"
     ]
    }
   ],
   "source": [
    "!pwd ConvNeXtPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:17.723001Z",
     "iopub.status.busy": "2025-10-14T13:09:17.722755Z",
     "iopub.status.idle": "2025-10-14T13:09:17.854934Z",
     "shell.execute_reply": "2025-10-14T13:09:17.853856Z",
     "shell.execute_reply.started": "2025-10-14T13:09:17.722979Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset encontrado en /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net\n",
      "\n",
      "📂 Contenido:\n",
      "'annotations (1)'   S11_ACT2_16   S9_ACT2_16\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANTE: Ajusta este path al nombre real de tu dataset en Kaggle\n",
    "KAGGLE_DATASET_PATH = '/kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net'  # ← CAMBIAR SEGÚN TU DATASET\n",
    "\n",
    "# Verificar que el dataset existe\n",
    "import os\n",
    "if not os.path.exists(KAGGLE_DATASET_PATH):\n",
    "    print(f\"❌ Dataset no encontrado en {KAGGLE_DATASET_PATH}\")\n",
    "    print(\"\\n📂 Datasets disponibles:\")\n",
    "    !ls /kaggle/input/\n",
    "    raise FileNotFoundError(\"Verifica el nombre del dataset y actualiza KAGGLE_DATASET_PATH\")\n",
    "else:\n",
    "    print(f\"✓ Dataset encontrado en {KAGGLE_DATASET_PATH}\")\n",
    "    print(\"\\n📂 Contenido:\")\n",
    "    !ls {KAGGLE_DATASET_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Opcional) Diagnosticar Estructura del Dataset\n",
    "\n",
    "Si tienes dudas sobre la estructura de tu dataset, ejecuta esta celda primero para ver cómo están organizadas las carpetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:17.856240Z",
     "iopub.status.busy": "2025-10-14T13:09:17.855965Z",
     "iopub.status.idle": "2025-10-14T13:09:17.859726Z",
     "shell.execute_reply": "2025-10-14T13:09:17.858790Z",
     "shell.execute_reply.started": "2025-10-14T13:09:17.856203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Diagnosticar estructura del dataset (útil para identificar carpetas anidadas)\n",
    "# !python diagnose_kaggle_dataset.py {KAGGLE_DATASET_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:17.860997Z",
     "iopub.status.busy": "2025-10-14T13:09:17.860710Z",
     "iopub.status.idle": "2025-10-14T13:09:18.107296Z",
     "shell.execute_reply": "2025-10-14T13:09:18.106454Z",
     "shell.execute_reply.started": "2025-10-14T13:09:17.860968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Configuración de Dataset Human3.6M para ConvNeXtPose\n",
      "======================================================================\n",
      "📂 Dataset Kaggle:     /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net\n",
      "📂 Proyecto ConvNeXt:  /kaggle/working/ConvNeXtPose\n",
      "\n",
      "✓ Directorio del proyecto encontrado: /kaggle/working/ConvNeXtPose/data/Human36M\n",
      "✓ Manteniendo módulos Python originales en /kaggle/working/ConvNeXtPose/data\n",
      "\n",
      "📁 [1/3] Configurando annotations...\n",
      "  ✓ Encontrado: annotations (1)/annotations\n",
      "    (21 archivos JSON detectados)\n",
      "  ✓ Creado: annotations -> /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net/annotations (1)/annotations\n",
      "\n",
      "👥 [2/3] Configurando sujetos S9 y S11...\n",
      "  ✓ Creado: S9 -> /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net/S9_ACT2_16\n",
      "  ✓ Creado: S11 -> /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net/S11_ACT2_16\n",
      "\n",
      "📦 [3/3] Configurando bbox_root...\n",
      "  ⚠️  No se encontró bbox_root (opcional)\n",
      "\n",
      "======================================================================\n",
      "  ✅ Configuración Completada\n",
      "======================================================================\n",
      "\n",
      "📂 Estructura creada en: /kaggle/working/ConvNeXtPose/data/Human36M\n",
      "\n",
      "Contenido:\n",
      "  📁 __pycache__/\n",
      "  🔗 annotations -> annotations\n",
      "  📁 bbox_root/\n",
      "  📁 bbox_root/Subject 9,11 (trained on subject 1,5,6,7,8)/\n",
      "  📁 images/\n",
      "  🔗 images/S11 -> S11_ACT2_16\n",
      "  🔗 images/S9 -> S9_ACT2_16\n",
      "\n",
      "======================================================================\n",
      "  ✅ LISTO - NO necesitas configurar CONVNEXPOSE_DATA_DIR\n",
      "======================================================================\n",
      "\n",
      "✅ Los módulos Python originales están intactos en:\n",
      "   /kaggle/working/ConvNeXtPose/data/dataset.py\n",
      "   /kaggle/working/ConvNeXtPose/data/Human36M/Human36M.py\n",
      "\n",
      "✅ El dataset de Kaggle está enlazado en:\n",
      "   /kaggle/working/ConvNeXtPose/data/Human36M/images\n",
      "   /kaggle/working/ConvNeXtPose/data/Human36M/annotations\n",
      "   /kaggle/working/ConvNeXtPose/data/Human36M/bbox_root (si existe)\n",
      "\n",
      "🚀 Puedes ejecutar el testing directamente:\n",
      "   %cd /kaggle/working/ConvNeXtPose/main\n",
      "   !python test.py --gpu 0 --epochs 70 --variant L\n",
      "\n",
      "\n",
      "🎉 Setup completado exitosamente!\n",
      "\n",
      "💡 Tip: Ejecuta con --verify para verificar la estructura:\n",
      "   !python setup_kaggle_dataset.py --verify /kaggle/working/ConvNeXtPose\n",
      "\n",
      "✅ Dataset enlazado en data/Human36M/\n",
      "✅ Módulos Python originales intactos en data/\n",
      "✅ Carpetas anidadas detectadas automáticamente\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar script de configuración\n",
    "# IMPORTANTE: Esto enlaza el dataset DENTRO de data/Human36M/, NO reemplaza data/\n",
    "# El script detecta automáticamente carpetas anidadas (ej: annotations (1)/annotations/)\n",
    "!python setup_kaggle_dataset.py --kaggle-input {KAGGLE_DATASET_PATH} --project-root /kaggle/working/ConvNeXtPose\n",
    "\n",
    "print(\"\\n✅ Dataset enlazado en data/Human36M/\")\n",
    "print(\"✅ Módulos Python originales intactos en data/\")\n",
    "print(\"✅ Carpetas anidadas detectadas automáticamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:18.108494Z",
     "iopub.status.busy": "2025-10-14T13:09:18.108262Z",
     "iopub.status.idle": "2025-10-14T13:09:18.326006Z",
     "shell.execute_reply": "2025-10-14T13:09:18.324873Z",
     "shell.execute_reply.started": "2025-10-14T13:09:18.108474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  🔍 Verificación de Estructura\n",
      "======================================================================\n",
      "  ✓ data/dataset.py\n",
      "  ✓ data/Human36M/Human36M.py\n",
      "  ✓ data/Human36M/annotations\n",
      "  ✓ data/Human36M/images\n",
      "  ✓ data/Human36M/images/S9\n",
      "  ✓ data/Human36M/images/S11\n",
      "  ✓ data/Human36M/bbox_root (optional)\n",
      "\n",
      "  ✅ Estructura verificada correctamente\n",
      "  ✅ Módulos Python intactos en data/\n",
      "  ✅ Dataset enlazado en data/Human36M/\n"
     ]
    }
   ],
   "source": [
    "# Verificar que la estructura es correcta\n",
    "!python setup_kaggle_dataset.py --verify /kaggle/working/ConvNeXtPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:18.329365Z",
     "iopub.status.busy": "2025-10-14T13:09:18.329090Z",
     "iopub.status.idle": "2025-10-14T13:09:18.537978Z",
     "shell.execute_reply": "2025-10-14T13:09:18.536919Z",
     "shell.execute_reply.started": "2025-10-14T13:09:18.329338Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  🔍 VERIFICACIÓN RÁPIDA - Estructura del Proyecto\n",
      "======================================================================\n",
      "\n",
      "📄 Módulos Python originales:\n",
      "  ✓ data/dataset.py\n",
      "  ✓ data/multiple_datasets.py\n",
      "  ✓ data/Human36M/Human36M.py\n",
      "  ✓ common/base.py\n",
      "  ✓ main/config.py\n",
      "\n",
      "📂 Dataset de Kaggle (enlaces):\n",
      "  ✓ data/Human36M/images/S9\n",
      "  ✓ data/Human36M/images/S11\n",
      "  ✓ data/Human36M/annotations\n",
      "  ✓ data/Human36M/bbox_root\n",
      "\n",
      "======================================================================\n",
      "✅ ESTRUCTURA CORRECTA - Listo para testing\n",
      "\n",
      "🚀 Siguiente paso:\n",
      "   %cd /kaggle/working/ConvNeXtPose/main\n",
      "   !python test.py --gpu 0 --epochs 83 --variant L\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar que la estructura es correcta\n",
    "!python verify_kaggle_structure.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 PASO 3: Preparar Checkpoints\n",
    "\n",
    "Extraer los modelos pre-entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:18.540716Z",
     "iopub.status.busy": "2025-10-14T13:09:18.540485Z",
     "iopub.status.idle": "2025-10-14T13:09:18.664481Z",
     "shell.execute_reply": "2025-10-14T13:09:18.663587Z",
     "shell.execute_reply.started": "2025-10-14T13:09:18.540696Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCHITECTURE_ADAPTATION_COMPLETE.md  KAGGLE_TESTING_GUIDE.md\n",
      "assets\t\t\t\t     kaggle_testing_notebook.ipynb\n",
      "AUTHOR_CONTACT_GUIDE.md\t\t     LICENSE\n",
      "CHECKLIST_TESTING.md\t\t     list_google_drive_contents.py\n",
      "CHECKPOINT_EXTRACTION_FIX.md\t     log2.txt\n",
      "CHECKPOINT_INVESTIGATION_REPORT.md   log.txt\n",
      "CHECKPOINT_MISLABELING_ISSUE.md      main\n",
      "common\t\t\t\t     NESTED_FOLDERS_SOLUTION.md\n",
      "CORRECCION_CONFIG_S.md\t\t     output\n",
      "data\t\t\t\t     PASOS_TESTING.md\n",
      "demo\t\t\t\t     PLAN_ACCION_INMEDIATO.md\n",
      "diagnose_kaggle_dataset.py\t     quick_start.sh\n",
      "EMAIL_TEMPLATE_AUTHORS.md\t     README.md\n",
      "ESTADO_PROYECTO.md\t\t     README_TESTING.md\n",
      "EXPLICACION_DIMS_INCORRECTOS.md      requirements.txt\n",
      "exports\t\t\t\t     RESUMEN_EJECUTIVO.md\n",
      "GITHUB_ISSUE_TEMPLATE.md\t     RESUMEN_RETESTING.md\n",
      "GUIA_TESTING_MODELOS_L_M.md\t     setup_kaggle_dataset.py\n",
      "identify_model_variant.py\t     tool\n",
      "KAGGLE_DATASET_FIX.md\t\t     UBUNTU_QUICKSTART.md\n",
      "KAGGLE_EXECUTION_GUIDE.md\t     ubuntu_quickstart.sh\n",
      "KAGGLE_QUICK_SOLUTION.md\t     verify_kaggle_structure.py\n",
      "KAGGLE_QUICKSTART.md\t\t     vis\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:18.665549Z",
     "iopub.status.busy": "2025-10-14T13:09:18.665297Z",
     "iopub.status.idle": "2025-10-14T13:09:22.944974Z",
     "shell.execute_reply": "2025-10-14T13:09:22.943903Z",
     "shell.execute_reply.started": "2025-10-14T13:09:18.665528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:22.946262Z",
     "iopub.status.busy": "2025-10-14T13:09:22.945999Z",
     "iopub.status.idle": "2025-10-14T13:10:15.430648Z",
     "shell.execute_reply": "2025-10-14T13:10:15.429886Z",
     "shell.execute_reply.started": "2025-10-14T13:09:22.946241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1eIaMqTYG-30CuPULs9LzSfeouAzYYHQW ConvNeXtPose_L.tar\n",
      "Processing file 1X_H-6S4xrQjW9GhJ3yWB-AXqUHddvkOI ConvNeXtPose_M.tar\n",
      "Processing file 1OriQPQ3uRY8MWPHP9KnwPaKawzrontqH ConvNeXtPose_S.tar\n",
      "Processing file 165D0rU2GImmRe7u7DNe6eKJG8voBIcGh ConvNeXtPose_XS.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1eIaMqTYG-30CuPULs9LzSfeouAzYYHQW\n",
      "To: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_L.tar\n",
      "100%|██████████| 101M/101M [00:02<00:00, 45.4MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1X_H-6S4xrQjW9GhJ3yWB-AXqUHddvkOI\n",
      "To: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_M.tar\n",
      "100%|██████████| 91.3M/91.3M [00:00<00:00, 136MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OriQPQ3uRY8MWPHP9KnwPaKawzrontqH\n",
      "To: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_S.tar\n",
      "100%|██████████| 89.6M/89.6M [00:00<00:00, 89.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=165D0rU2GImmRe7u7DNe6eKJG8voBIcGh\n",
      "To: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_XS.tar\n",
      "100%|██████████| 42.5M/42.5M [00:00<00:00, 153MB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_tar/ConvNeXtPose_L.tar',\n",
       " 'models_tar/ConvNeXtPose_M.tar',\n",
       " 'models_tar/ConvNeXtPose_S.tar',\n",
       " 'models_tar/ConvNeXtPose_XS.tar']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "folder_id = \"12H7zkLvmJtrkCmAUAPkQ6788WAnO60gI\"\n",
    "output = \"models_tar\"\n",
    "\n",
    "gdown.download_folder(id=folder_id, output=output, quiet=False, use_cookies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:15.431633Z",
     "iopub.status.busy": "2025-10-14T13:10:15.431280Z",
     "iopub.status.idle": "2025-10-14T13:10:15.554873Z",
     "shell.execute_reply": "2025-10-14T13:10:15.554094Z",
     "shell.execute_reply.started": "2025-10-14T13:10:15.431612Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCHITECTURE_ADAPTATION_COMPLETE.md  kaggle_testing_notebook.ipynb\n",
      "assets\t\t\t\t     LICENSE\n",
      "AUTHOR_CONTACT_GUIDE.md\t\t     list_google_drive_contents.py\n",
      "CHECKLIST_TESTING.md\t\t     log2.txt\n",
      "CHECKPOINT_EXTRACTION_FIX.md\t     log.txt\n",
      "CHECKPOINT_INVESTIGATION_REPORT.md   main\n",
      "CHECKPOINT_MISLABELING_ISSUE.md      models_tar\n",
      "common\t\t\t\t     NESTED_FOLDERS_SOLUTION.md\n",
      "CORRECCION_CONFIG_S.md\t\t     output\n",
      "data\t\t\t\t     PASOS_TESTING.md\n",
      "demo\t\t\t\t     PLAN_ACCION_INMEDIATO.md\n",
      "diagnose_kaggle_dataset.py\t     quick_start.sh\n",
      "EMAIL_TEMPLATE_AUTHORS.md\t     README.md\n",
      "ESTADO_PROYECTO.md\t\t     README_TESTING.md\n",
      "EXPLICACION_DIMS_INCORRECTOS.md      requirements.txt\n",
      "exports\t\t\t\t     RESUMEN_EJECUTIVO.md\n",
      "GITHUB_ISSUE_TEMPLATE.md\t     RESUMEN_RETESTING.md\n",
      "GUIA_TESTING_MODELOS_L_M.md\t     setup_kaggle_dataset.py\n",
      "identify_model_variant.py\t     tool\n",
      "KAGGLE_DATASET_FIX.md\t\t     UBUNTU_QUICKSTART.md\n",
      "KAGGLE_EXECUTION_GUIDE.md\t     ubuntu_quickstart.sh\n",
      "KAGGLE_QUICK_SOLUTION.md\t     verify_kaggle_structure.py\n",
      "KAGGLE_QUICKSTART.md\t\t     vis\n",
      "KAGGLE_TESTING_GUIDE.md\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:15.556241Z",
     "iopub.status.busy": "2025-10-14T13:10:15.555925Z",
     "iopub.status.idle": "2025-10-14T13:10:15.677921Z",
     "shell.execute_reply": "2025-10-14T13:10:15.677131Z",
     "shell.execute_reply.started": "2025-10-14T13:10:15.556209Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'src': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:15.679251Z",
     "iopub.status.busy": "2025-10-14T13:10:15.678934Z",
     "iopub.status.idle": "2025-10-14T13:10:15.800238Z",
     "shell.execute_reply": "2025-10-14T13:10:15.799451Z",
     "shell.execute_reply.started": "2025-10-14T13:10:15.679218Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ConvNeXtPose\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:15.801407Z",
     "iopub.status.busy": "2025-10-14T13:10:15.801180Z",
     "iopub.status.idle": "2025-10-14T13:10:15.924046Z",
     "shell.execute_reply": "2025-10-14T13:10:15.923030Z",
     "shell.execute_reply.started": "2025-10-14T13:10:15.801387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 310M\n",
      "-rw-r--r-- 1 root root 97M Oct  4  2023 ConvNeXtPose_L.tar\n",
      "-rw-r--r-- 1 root root 88M Oct  4  2023 ConvNeXtPose_M.tar\n",
      "-rw-r--r-- 1 root root 86M Oct  4  2023 ConvNeXtPose_S.tar\n",
      "-rw-r--r-- 1 root root 41M Oct  4  2023 ConvNeXtPose_XS.tar\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /kaggle/working/ConvNeXtPose/models_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:15.925534Z",
     "iopub.status.busy": "2025-10-14T13:10:15.925198Z",
     "iopub.status.idle": "2025-10-14T13:10:16.048823Z",
     "shell.execute_reply": "2025-10-14T13:10:16.048039Z",
     "shell.execute_reply.started": "2025-10-14T13:10:15.925503Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Modelos disponibles:\n",
      "total 310M\n",
      "-rw-r--r-- 1 root root 97M Oct  4  2023 ConvNeXtPose_L.tar\n",
      "-rw-r--r-- 1 root root 88M Oct  4  2023 ConvNeXtPose_M.tar\n",
      "-rw-r--r-- 1 root root 86M Oct  4  2023 ConvNeXtPose_S.tar\n",
      "-rw-r--r-- 1 root root 41M Oct  4  2023 ConvNeXtPose_XS.tar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# IMPORTANTE: Ajusta según el nombre de tu dataset de modelos\n",
    "MODELS_DATASET_PATH = '/kaggle/working/ConvNeXtPose/models_tar'\n",
    "# Verificar modelos disponibles\n",
    "if os.path.exists(MODELS_DATASET_PATH):\n",
    "    print(\"📦 Modelos disponibles:\")\n",
    "    !ls -lh {MODELS_DATASET_PATH}\n",
    "else:\n",
    "    print(f\"❌ Dataset de modelos no encontrado: {MODELS_DATASET_PATH}\")\n",
    "    print(\"\\n📂 Datasets disponibles:\")\n",
    "    !ls /kaggle/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:16.050370Z",
     "iopub.status.busy": "2025-10-14T13:10:16.050036Z",
     "iopub.status.idle": "2025-10-14T13:10:17.426976Z",
     "shell.execute_reply": "2025-10-14T13:10:17.425992Z",
     "shell.execute_reply.started": "2025-10-14T13:10:16.050336Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "📦 Extrayendo modelo L desde /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_L.tar...\n",
      "   📏 Tamaño del archivo: 96.19 MB\n",
      "   🔍 Primeros bytes (hex): 504b03040000080800000000000000000000000000000000000018000a00736e617073686f745f38332e7074682f64617461\n",
      "   ✓ Formato: ZIP - Extraído: 808 archivos\n",
      "   ✓ Checkpoint encontrado: snapshot_83.pth/\n",
      "   🔄 Convirtiendo formato legacy → formato moderno...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-2ab6ed486f7e>:162: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  typed_storage = torch.storage.TypedStorage(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Archivo creado: snapshot_83.pth (96.2 MB)\n",
      "   ✓ Verificación exitosa - Keys: ['epoch', 'network', 'optimizer']\n",
      "   ✓ Conversión completada\n",
      "\n",
      "📦 Extrayendo modelo M desde /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_M.tar...\n",
      "   📏 Tamaño del archivo: 87.10 MB\n",
      "   🔍 Primeros bytes (hex): 504b03040000080800000000000000000000000000000000000010001200617263686976652f646174612e706b6c46420e00\n",
      "   ✓ Formato: ZIP - Extraído: 808 archivos\n",
      "   ✓ Checkpoint encontrado: archive/\n",
      "   🔄 Convirtiendo formato legacy → formato moderno...\n",
      "   ✓ Archivo creado: snapshot_70.pth (87.1 MB)\n",
      "   ✓ Verificación exitosa - Keys: ['epoch', 'network', 'optimizer']\n",
      "   ✓ Conversión completada\n",
      "============================================================\n",
      "\n",
      "📂 Checkpoints disponibles:\n",
      "  ✓ snapshot_70.pth (87.1 MB)\n",
      "    → Keys: ['epoch', 'network', 'optimizer']\n",
      "    → ✅ Formato válido (7,596,986 parámetros)\n",
      "  ✓ snapshot_83.pth (96.2 MB)\n",
      "    → Keys: ['epoch', 'network', 'optimizer']\n",
      "    → ✅ Formato válido (8,391,354 parámetros)\n",
      "\n",
      "💡 Modelo L: Usa CHECKPOINT_EPOCH = 83\n",
      "💡 Modelo M: Usa CHECKPOINT_EPOCH = 70\n",
      "\n",
      "✅ Los checkpoints están listos para torch.load()\n",
      "   Formato: PyTorch moderno (.pth)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import tarfile\n",
    "import torch\n",
    "\n",
    "# Crear directorio para modelos\n",
    "os.makedirs('output/model_dump', exist_ok=True)\n",
    "\n",
    "# Función para extraer y convertir checkpoints\n",
    "def extract_checkpoint(tar_path, model_name, expected_epoch=None):\n",
    "    \"\"\"Extrae checkpoint desde .tar/.zip y lo convierte en archivo .pth válido\n",
    "    \n",
    "    Los archivos .tar de ConvNeXtPose son ZIP con estructura de directorio en formato legacy.\n",
    "    Usamos una conversión simple: empaquetar el directorio como TAR que PyTorch puede leer.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(tar_path):\n",
    "        print(f\"⚠️  Modelo {model_name} no encontrado en {tar_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📦 Extrayendo modelo {model_name} desde {tar_path}...\")\n",
    "    \n",
    "    # Verificar tamaño del archivo\n",
    "    file_size = os.path.getsize(tar_path)\n",
    "    print(f\"   📏 Tamaño del archivo: {file_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    # Leer primeros bytes para diagnosticar el formato\n",
    "    with open(tar_path, 'rb') as f:\n",
    "        header = f.read(512)\n",
    "        print(f\"   🔍 Primeros bytes (hex): {header[:50].hex()}\")\n",
    "    \n",
    "    # Si el archivo es muy pequeño o empieza con HTML, es un error de descarga\n",
    "    if file_size < 1000 or header.startswith(b'<!DOCTYPE') or header.startswith(b'<html'):\n",
    "        print(f\"   ❌ ERROR: El archivo parece ser HTML (error de descarga)\")\n",
    "        print(f\"   💡 Solución: Revisa que el folder de Google Drive sea público\")\n",
    "        return None\n",
    "    \n",
    "    # Extraer a directorio temporal\n",
    "    temp_dir = 'output/model_dump/temp_extract'\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    # Detectar formato: intentar ZIP primero, luego TAR\n",
    "    extracted = False\n",
    "    try:\n",
    "        with zipfile.ZipFile(tar_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "            files = zip_ref.namelist()\n",
    "            print(f\"   ✓ Formato: ZIP - Extraído: {len(files)} archivos\")\n",
    "            extracted = True\n",
    "    except zipfile.BadZipFile:\n",
    "        try:\n",
    "            with tarfile.open(tar_path, 'r') as tar_ref:\n",
    "                tar_ref.extractall(temp_dir)\n",
    "                files = tar_ref.getnames()\n",
    "                print(f\"   ✓ Formato: TAR - Extraído: {len(files)} archivos\")\n",
    "                extracted = True\n",
    "        except (tarfile.ReadError, Exception) as e:\n",
    "            print(f\"   ❌ ERROR: No se pudo extraer el archivo\")\n",
    "            print(f\"   💡 Formato no reconocido: {type(e).__name__}: {e}\")\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "            return None\n",
    "    \n",
    "    if not extracted:\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        return None\n",
    "    \n",
    "    # Buscar la carpeta del checkpoint (snapshot_XX.pth/ o archive/)\n",
    "    found_checkpoints = []\n",
    "    for item in os.listdir(temp_dir):\n",
    "        item_path = os.path.join(temp_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            # Verificar que tenga data.pkl (indicador de checkpoint PyTorch)\n",
    "            if os.path.exists(os.path.join(item_path, 'data.pkl')):\n",
    "                found_checkpoints.append((item, item_path))\n",
    "                print(f\"   ✓ Checkpoint encontrado: {item}/\")\n",
    "    \n",
    "    if not found_checkpoints:\n",
    "        print(f\"   ❌ No se encontró estructura de checkpoint válida\")\n",
    "        print(f\"   📂 Contenido extraído:\")\n",
    "        for item in os.listdir(temp_dir)[:10]:\n",
    "            print(f\"      - {item}\")\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        return None\n",
    "    \n",
    "    # Convertir el checkpoint legacy a formato moderno\n",
    "    epoch = None\n",
    "    for ckpt_name, ckpt_path in found_checkpoints:\n",
    "        # Determinar el epoch desde el nombre\n",
    "        import re\n",
    "        match = re.search(r'snapshot_(\\d+)', ckpt_name)\n",
    "        if match:\n",
    "            epoch = match.group(1)\n",
    "            final_name = f'snapshot_{epoch}.pth'\n",
    "        else:\n",
    "            # Si no tiene snapshot_XX, usar archive/ con epoch esperado\n",
    "            if expected_epoch:\n",
    "                epoch = str(expected_epoch)\n",
    "                final_name = f'snapshot_{epoch}.pth'\n",
    "            else:\n",
    "                epoch = '0'\n",
    "                final_name = f'{model_name}_checkpoint.pth'\n",
    "        \n",
    "        dest_path = os.path.join('output/model_dump', final_name)\n",
    "        \n",
    "        print(f\"   🔄 Convirtiendo formato legacy → formato moderno...\")\n",
    "        \n",
    "        try:\n",
    "            # SOLUCIÓN DEFINITIVA: Cargar manualmente el formato legacy y guardar como moderno\n",
    "            import pickle\n",
    "            import io\n",
    "            \n",
    "            # Cargar data.pkl\n",
    "            data_pkl_path = os.path.join(ckpt_path, 'data.pkl')\n",
    "            data_dir = os.path.join(ckpt_path, 'data')\n",
    "            \n",
    "            # Crear un unpickler personalizado que resuelve persistent IDs\n",
    "            class LegacyUnpickler(pickle.Unpickler):\n",
    "                def __init__(self, file, data_dir):\n",
    "                    super().__init__(file)\n",
    "                    self.data_dir = data_dir\n",
    "                    self.storage_cache = {}\n",
    "                \n",
    "                def persistent_load(self, pid):\n",
    "                    # pid es una tupla: ('storage', <type>, <key>, <location>, <size>)\n",
    "                    if isinstance(pid, tuple) and len(pid) >= 2 and pid[0] == 'storage':\n",
    "                        typename, key = pid[1:3]\n",
    "                        location = pid[3] if len(pid) > 3 else None\n",
    "                        \n",
    "                        # Cachear storages para evitar recargar\n",
    "                        if key in self.storage_cache:\n",
    "                            return self.storage_cache[key]\n",
    "                        \n",
    "                        # Leer el archivo de storage\n",
    "                        storage_file = os.path.join(self.data_dir, str(key))\n",
    "                        \n",
    "                        # Leer el contenido como raw binary\n",
    "                        with open(storage_file, 'rb') as f:\n",
    "                            raw_data = f.read()\n",
    "                            \n",
    "                            # Crear UntypedStorage desde el buffer\n",
    "                            untyped_storage = torch.UntypedStorage.from_buffer(raw_data, dtype=torch.uint8)\n",
    "                            \n",
    "                            # Mapear typename a dtype de PyTorch\n",
    "                            dtype_map = {\n",
    "                                'FloatStorage': torch.float32,\n",
    "                                'DoubleStorage': torch.float64,\n",
    "                                'HalfStorage': torch.float16,\n",
    "                                'LongStorage': torch.int64,\n",
    "                                'IntStorage': torch.int32,\n",
    "                                'ShortStorage': torch.int16,\n",
    "                                'CharStorage': torch.int8,\n",
    "                                'ByteStorage': torch.uint8,\n",
    "                                'BoolStorage': torch.bool,\n",
    "                            }\n",
    "                            \n",
    "                            # Obtener dtype desde typename\n",
    "                            # typename puede ser un objeto _LegacyStorageMeta, extraer el nombre\n",
    "                            type_str = str(typename).split('.')[-1].replace(\"'>\", \"\")\n",
    "                            dtype = dtype_map.get(type_str, torch.float32)\n",
    "                            \n",
    "                            # Crear TypedStorage desde UntypedStorage\n",
    "                            typed_storage = torch.storage.TypedStorage(\n",
    "                                wrap_storage=untyped_storage,\n",
    "                                dtype=dtype\n",
    "                            )\n",
    "                            \n",
    "                            self.storage_cache[key] = typed_storage\n",
    "                            return typed_storage\n",
    "                    \n",
    "                    raise pickle.UnpicklingError(f\"unsupported persistent id: {pid}\")\n",
    "            \n",
    "            # Cargar el checkpoint usando el unpickler personalizado\n",
    "            with open(data_pkl_path, 'rb') as f:\n",
    "                unpickler = LegacyUnpickler(f, data_dir)\n",
    "                checkpoint = unpickler.load()\n",
    "            \n",
    "            # Guardar en formato moderno\n",
    "            torch.save(checkpoint, dest_path)\n",
    "            \n",
    "            # Verificar tamaño\n",
    "            size_mb = os.path.getsize(dest_path) / (1024 * 1024)\n",
    "            print(f\"   ✓ Archivo creado: {final_name} ({size_mb:.1f} MB)\")\n",
    "            \n",
    "            # Verificar que se puede cargar\n",
    "            test_load = torch.load(dest_path, map_location='cpu', weights_only=False)\n",
    "            keys = list(test_load.keys())\n",
    "            print(f\"   ✓ Verificación exitosa - Keys: {keys}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ ERROR al convertir checkpoint: {type(e).__name__}\")\n",
    "            print(f\"      {str(e)[:200]}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "            return None\n",
    "    \n",
    "    # Limpiar temporal\n",
    "    shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "    print(f\"   ✓ Conversión completada\")\n",
    "    \n",
    "    return epoch\n",
    "\n",
    "# Extraer modelo L (epoch 83 según el paper)\n",
    "print(\"=\"*60)\n",
    "model_l_path = f'{MODELS_DATASET_PATH}/ConvNeXtPose_L.tar'\n",
    "epoch_l = extract_checkpoint(model_l_path, 'L', expected_epoch=83)\n",
    "\n",
    "print()\n",
    "\n",
    "# Extraer modelo M (epoch 70 según el paper)\n",
    "model_m_path = f'{MODELS_DATASET_PATH}/ConvNeXtPose_M.tar'\n",
    "epoch_m = extract_checkpoint(model_m_path, 'M', expected_epoch=70)\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar checkpoints extraídos\n",
    "print(\"\\n📂 Checkpoints disponibles:\")\n",
    "checkpoints = [f for f in os.listdir('output/model_dump') \n",
    "               if f.endswith('.pth') and os.path.isfile(os.path.join('output/model_dump', f))]\n",
    "\n",
    "if checkpoints:\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        ckpt_path = os.path.join('output/model_dump', ckpt)\n",
    "        size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n",
    "        print(f\"  ✓ {ckpt} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        # Verificar contenido\n",
    "        try:\n",
    "            test_load = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "            keys = list(test_load.keys())\n",
    "            print(f\"    → Keys: {keys}\")\n",
    "            if 'network' in test_load:\n",
    "                # Contar parámetros\n",
    "                num_params = sum(p.numel() for p in test_load['network'].values() \n",
    "                                 if isinstance(p, torch.Tensor))\n",
    "                print(f\"    → ✅ Formato válido ({num_params:,} parámetros)\")\n",
    "            else:\n",
    "                print(f\"    → ⚠️  Falta key 'network'\")\n",
    "        except Exception as e:\n",
    "            print(f\"    → ❌ Error: {type(e).__name__}: {str(e)[:80]}\")\n",
    "\n",
    "# Mostrar información de epochs\n",
    "if epoch_l:\n",
    "    print(f\"\\n💡 Modelo L: Usa CHECKPOINT_EPOCH = {epoch_l}\")\n",
    "if epoch_m:\n",
    "    print(f\"💡 Modelo M: Usa CHECKPOINT_EPOCH = {epoch_m}\")\n",
    "\n",
    "if epoch_l or epoch_m:\n",
    "    print(\"\\n✅ Los checkpoints están listos para torch.load()\")\n",
    "    print(\"   Formato: PyTorch moderno (.pth)\")\n",
    "else:\n",
    "    print(\"\\n❌ No se pudieron extraer los checkpoints\")\n",
    "    print(\"💡 Verifica que los archivos .tar se descargaron correctamente\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ Nota sobre Extracción de Checkpoints\n",
    "\n",
    "Los archivos `.tar` de ConvNeXtPose son en realidad **archivos ZIP** con estructura anidada:\n",
    "```\n",
    "ConvNeXtPose_L.tar (archivo zip)\n",
    "└── snapshot_83.pth/        ← Directorio\n",
    "    ├── data.pkl\n",
    "    ├── version\n",
    "    └── data/               ← Carpeta con el checkpoint real\n",
    "        └── 0, 1, 2...      ← Archivos binarios\n",
    "```\n",
    "\n",
    "La siguiente celda extrae y reorganiza correctamente el archivo `.pth` real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:17.428421Z",
     "iopub.status.busy": "2025-10-14T13:10:17.428061Z",
     "iopub.status.idle": "2025-10-14T13:10:17.554586Z",
     "shell.execute_reply": "2025-10-14T13:10:17.553596Z",
     "shell.execute_reply.started": "2025-10-14T13:10:17.428386Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ConvNeXtPose\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:17.556076Z",
     "iopub.status.busy": "2025-10-14T13:10:17.555795Z",
     "iopub.status.idle": "2025-10-14T13:10:17.732607Z",
     "shell.execute_reply": "2025-10-14T13:10:17.731790Z",
     "shell.execute_reply.started": "2025-10-14T13:10:17.556053Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Verificación de Checkpoints:\n",
      "\n",
      "✅ Checkpoints encontrados:\n",
      "\n",
      "  ✓ snapshot_70.pth (87.1 MB)\n",
      "    → Usa CHECKPOINT_EPOCH = 70\n",
      "    → Keys: ['epoch', 'network', 'optimizer']\n",
      "    → ✅ Formato válido (7,596,986 parámetros)\n",
      "\n",
      "  ✓ snapshot_83.pth (96.2 MB)\n",
      "    → Usa CHECKPOINT_EPOCH = 83\n",
      "    → Keys: ['epoch', 'network', 'optimizer']\n",
      "    → ✅ Formato válido (8,391,354 parámetros)\n",
      "\n",
      "\n",
      "============================================================\n",
      "💡 IMPORTANTE: Los checkpoints son archivos .pth modernos\n",
      "   Convertidos desde formato legacy a formato PyTorch estándar\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verificar checkpoints extraídos y detectar epoch\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "\n",
    "print(\"🔍 Verificación de Checkpoints:\\n\")\n",
    "\n",
    "# Buscar ARCHIVOS .pth\n",
    "checkpoint_dir = 'output/model_dump'\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) \n",
    "                   if f.endswith('.pth') and os.path.isfile(os.path.join(checkpoint_dir, f))]\n",
    "else:\n",
    "    checkpoints = []\n",
    "\n",
    "if checkpoints:\n",
    "    print(\"✅ Checkpoints encontrados:\\n\")\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        ckpt_path = os.path.join(checkpoint_dir, ckpt)\n",
    "        size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n",
    "        \n",
    "        # Extraer epoch\n",
    "        match = re.search(r'snapshot_(\\d+)', ckpt)\n",
    "        if match:\n",
    "            epoch = match.group(1)\n",
    "            print(f\"  ✓ {ckpt} ({size_mb:.1f} MB)\")\n",
    "            print(f\"    → Usa CHECKPOINT_EPOCH = {epoch}\")\n",
    "            \n",
    "            # Verificar contenido del checkpoint\n",
    "            try:\n",
    "                test_load = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "                keys = list(test_load.keys())\n",
    "                print(f\"    → Keys: {keys}\")\n",
    "                \n",
    "                if 'network' in test_load:\n",
    "                    # Contar parámetros del modelo\n",
    "                    num_params = sum(p.numel() for p in test_load['network'].values() \n",
    "                                     if isinstance(p, torch.Tensor))\n",
    "                    print(f\"    → ✅ Formato válido ({num_params:,} parámetros)\")\n",
    "                else:\n",
    "                    print(f\"    → ⚠️  Falta key 'network'\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"    → ❌ Error al verificar: {type(e).__name__}: {str(e)[:50]}\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"❌ No se encontraron checkpoints válidos\\n\")\n",
    "    \n",
    "    # Diagnosticar problema\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        all_items = os.listdir(checkpoint_dir)\n",
    "        if all_items:\n",
    "            print(\"📂 Contenido de output/model_dump/:\")\n",
    "            for item in all_items[:15]:\n",
    "                item_path = os.path.join(checkpoint_dir, item)\n",
    "                if os.path.isdir(item_path):\n",
    "                    print(f\"    📁 {item}/ (directorio - no válido)\")\n",
    "                else:\n",
    "                    size_mb = os.path.getsize(item_path) / (1024 * 1024)\n",
    "                    print(f\"    📄 {item} ({size_mb:.1f} MB)\")\n",
    "            \n",
    "            print(\"\\n💡 Solución: Re-ejecuta la celda anterior de extracción\")\n",
    "        else:\n",
    "            print(\"💡 Directorio vacío - verifica MODELS_DATASET_PATH\")\n",
    "    else:\n",
    "        print(\"💡 Solución: Verifica que MODELS_DATASET_PATH es correcto\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"💡 IMPORTANTE: Los checkpoints son archivos .pth modernos\")\n",
    "print(\"   Convertidos desde formato legacy a formato PyTorch estándar\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**⚠️ IMPORTANTE:** Ajusta el valor de `CHECKPOINT_EPOCH` en las siguientes celdas según el epoch de tu checkpoint extraído. En este caso detectamos `snapshot_83.pth`, así que usa `CHECKPOINT_EPOCH = 83`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 PASO 4: Ejecutar Testing\n",
    "\n",
    "### Modelo XS (Extra Small)\n",
    "\n",
    "**⚠️ NOTA CRÍTICA:** Todos los checkpoints descargados (L.tar, M.tar, S.tar) contienen arquitectura XS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:17.733645Z",
     "iopub.status.busy": "2025-10-14T13:10:17.733442Z",
     "iopub.status.idle": "2025-10-14T13:10:17.751756Z",
     "shell.execute_reply": "2025-10-14T13:10:17.751008Z",
     "shell.execute_reply.started": "2025-10-14T13:10:17.733627Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Verificación de Componentes:\n",
      "\n",
      "1. Dataset (estructura del proyecto):\n",
      "   Project root: /kaggle/working/ConvNeXtPose\n",
      "   data/ exists: True\n",
      "   data/dataset.py: True\n",
      "   data/Human36M/ exists: True\n",
      "   - Human36M.py: True\n",
      "   - annotations: True\n",
      "   - images/S9: True\n",
      "   - images/S11: True\n",
      "\n",
      "2. Checkpoints: /kaggle/working/ConvNeXtPose/output/model_dump\n",
      "   Disponibles: snapshot_70.pth, snapshot_83.pth\n",
      "   💡 Usa CHECKPOINT_EPOCH = 70 en la siguiente celda\n",
      "   💡 Usa CHECKPOINT_EPOCH = 83 en la siguiente celda\n",
      "\n",
      "3. Estructura del proyecto:\n",
      "   ✓ main/config.py\n",
      "   ✓ common/base.py\n",
      "   ✓ data/dataset.py\n",
      "   ✓ data/Human36M/Human36M.py\n",
      "\n",
      "============================================================\n",
      "✅ Todos los checks pasaron - Listo para testing\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Diagnóstico: Verificar que todos los componentes están listos\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"🔍 Verificación de Componentes:\\n\")\n",
    "\n",
    "# 1. Dataset - Verificar estructura DENTRO del proyecto\n",
    "project_root = '/kaggle/working/ConvNeXtPose'\n",
    "data_dir = os.path.join(project_root, 'data')\n",
    "h36m_path = os.path.join(data_dir, 'Human36M')\n",
    "\n",
    "print(f\"1. Dataset (estructura del proyecto):\")\n",
    "print(f\"   Project root: {project_root}\")\n",
    "print(f\"   data/ exists: {os.path.exists(data_dir)}\")\n",
    "print(f\"   data/dataset.py: {os.path.exists(os.path.join(data_dir, 'dataset.py'))}\")\n",
    "print(f\"   data/Human36M/ exists: {os.path.exists(h36m_path)}\")\n",
    "\n",
    "if os.path.exists(h36m_path):\n",
    "    print(f\"   - Human36M.py: {os.path.exists(os.path.join(h36m_path, 'Human36M.py'))}\")\n",
    "    print(f\"   - annotations: {os.path.exists(os.path.join(h36m_path, 'annotations'))}\")\n",
    "    print(f\"   - images/S9: {os.path.exists(os.path.join(h36m_path, 'images', 'S9'))}\")\n",
    "    print(f\"   - images/S11: {os.path.exists(os.path.join(h36m_path, 'images', 'S11'))}\")\n",
    "\n",
    "# 2. Checkpoints\n",
    "checkpoint_dir = os.path.join(project_root, 'output/model_dump')\n",
    "print(f\"\\n2. Checkpoints: {checkpoint_dir}\")\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith('snapshot_')]\n",
    "    if checkpoints:\n",
    "        print(f\"   Disponibles: {', '.join(checkpoints)}\")\n",
    "        # Extraer epoch del checkpoint\n",
    "        import re\n",
    "        for ckpt in checkpoints:\n",
    "            match = re.search(r'snapshot_(\\d+)', ckpt)\n",
    "            if match:\n",
    "                epoch = match.group(1)\n",
    "                print(f\"   💡 Usa CHECKPOINT_EPOCH = {epoch} en la siguiente celda\")\n",
    "    else:\n",
    "        print(\"   ⚠️  No se encontraron checkpoints\")\n",
    "else:\n",
    "    print(\"   ❌ Directorio no existe\")\n",
    "\n",
    "# 3. Estructura del proyecto\n",
    "print(f\"\\n3. Estructura del proyecto:\")\n",
    "critical_files = ['main/config.py', 'common/base.py', 'data/dataset.py', 'data/Human36M/Human36M.py']\n",
    "for file_path in critical_files:\n",
    "    full_path = os.path.join(project_root, file_path)\n",
    "    exists = os.path.exists(full_path)\n",
    "    status = \"✓\" if exists else \"❌\"\n",
    "    print(f\"   {status} {file_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all(os.path.exists(os.path.join(project_root, f)) for f in critical_files):\n",
    "    print(\"✅ Todos los checks pasaron - Listo para testing\")\n",
    "else:\n",
    "    print(\"❌ Algunos archivos faltan - Revisa la configuración\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar Testing desde Python\n",
    "\n",
    "**Estructura correcta:**\n",
    "- ✅ Módulos Python originales en `data/` (dataset.py, Human36M.py)\n",
    "- ✅ Dataset de Kaggle enlazado en `data/Human36M/` (images, annotations)\n",
    "- ✅ `config.py` configura automáticamente los paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️ IMPORTANTE: Verificar GPU Antes de Testing\n",
    "\n",
    "**El modelo REQUIERE GPU para correr en tiempo razonable.**\n",
    "\n",
    "- ✅ **Con GPU T4 x2**: ~10-20 minutos\n",
    "- ❌ **Con CPU**: ~10-20 HORAS (no recomendado)\n",
    "\n",
    "**Cómo activar GPU en Kaggle:**\n",
    "1. Panel derecho → **Settings**\n",
    "2. **Accelerator** → Selecciona **GPU T4 x2** o **GPU P100**\n",
    "3. Click **Save**\n",
    "4. El notebook se reiniciará con GPU habilitada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:17.752776Z",
     "iopub.status.busy": "2025-10-14T13:10:17.752599Z",
     "iopub.status.idle": "2025-10-14T13:10:17.757975Z",
     "shell.execute_reply": "2025-10-14T13:10:17.757092Z",
     "shell.execute_reply.started": "2025-10-14T13:10:17.752760Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Verificando hardware disponible...\n",
      "\n",
      "✅ GPU disponible: Tesla T4\n",
      "   Memoria: 15.8 GB\n",
      "\n",
      "💡 Tiempo estimado: 10-20 minutos\n"
     ]
    }
   ],
   "source": [
    "# Verificar disponibilidad de GPU\n",
    "import torch\n",
    "\n",
    "print(\"🔍 Verificando hardware disponible...\\n\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✅ GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memoria: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"\\n💡 Tiempo estimado: 10-20 minutos\")\n",
    "    USE_GPU = True\n",
    "else:\n",
    "    print(\"❌ GPU NO disponible - usando CPU\")\n",
    "    print(\"\\n⚠️  ADVERTENCIA: El testing en CPU puede tomar HORAS\")\n",
    "    print(\"   Se recomienda activar GPU T4 x2 en Kaggle\")\n",
    "    print(\"\\n¿Continuar de todas formas? (no recomendado)\")\n",
    "    USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:17.759110Z",
     "iopub.status.busy": "2025-10-14T13:10:17.758902Z",
     "iopub.status.idle": "2025-10-14T13:10:45.079598Z",
     "shell.execute_reply": "2025-10-14T13:10:45.077104Z",
     "shell.execute_reply.started": "2025-10-14T13:10:17.759092Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Testing ConvNeXtPose-L\n",
      "============================================================\n",
      "\n",
      "✓ Configuración cargada para variante: L\n",
      "  - Backbone: depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536]\n",
      "  - HeadNet: 3-UP (3 capas de upsampling)\n",
      ">>> Using GPU: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "\u001b[92m10-14 13:10:24\u001b[0m Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CUDA habilitado\n",
      "Load data of H36M Protocol 2\n",
      "creating index...\n",
      "index created!\n",
      "Get bounding box and root from groundtruth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\u001b[92m10-14 13:10:41\u001b[0m Load checkpoint from /kaggle/working/ConvNeXtPose/main/../output/model_dump/snapshot_83.pth\n",
      "\u001b[92m10-14 13:10:41\u001b[0m Creating graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📐 Arquitectura: ConvNeXtPose-L\n",
      "   Backbone: 1536 canales de salida\n",
      "   HeadNet: 3-UP (3 capas de upsampling)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ConvNeXtPose/main/../common/base.py:205: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(model_path)\n",
      "\u001b[92m10-14 13:10:44\u001b[0m Aplicando checkpoint remapping para variante L...\n",
      "\u001b[92m10-14 13:10:44\u001b[0m \u001b[93mWRN: Detectadas claves incompatibles, aplicando remapping...\u001b[0m\n",
      "\u001b[92m10-14 13:10:44\u001b[0m \u001b[91mERR: ❌ Error cargando checkpoint remapeado: Error(s) in loading state_dict for ConvNeXtPose:\n",
      "\tsize mismatch for backbone.downsample_layers.0.0.weight: copying a param with shape torch.Size([48, 3, 4, 4]) from checkpoint, the shape in current model is torch.Size([192, 3, 4, 4]).\n",
      "\tsize mismatch for backbone.downsample_layers.0.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.0.1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.0.1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.0.1.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.0.1.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.0.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.0.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.0.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.1.weight: copying a param with shape torch.Size([96, 48, 2, 2]) from checkpoint, the shape in current model is torch.Size([384, 192, 2, 2]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.0.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.0.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.0.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.1.weight: copying a param with shape torch.Size([192, 96, 2, 2]) from checkpoint, the shape in current model is torch.Size([768, 384, 2, 2]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.0.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.0.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.0.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.0.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.1.weight: copying a param with shape torch.Size([384, 192, 2, 2]) from checkpoint, the shape in current model is torch.Size([1536, 768, 2, 2]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.0.0.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.0.0.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.0.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.0.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.0.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.0.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.0.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.0.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.0.0.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.0.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.0.1.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.1.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.0.1.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.1.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.0.2.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.2.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.0.2.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.2.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.1.0.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.1.0.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.0.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.0.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.0.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.0.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.0.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.0.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.1.0.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.0.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.1.1.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.1.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.1.1.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.1.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.1.2.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.2.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.1.2.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.2.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.2.0.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.0.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.0.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.0.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.0.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.0.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.0.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.0.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.0.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.0.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.1.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.1.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.1.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.1.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.2.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.2.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.2.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.2.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.3.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.3.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.3.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.3.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.4.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.4.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.4.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.4.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.5.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.5.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.5.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.5.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.6.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.6.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.6.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.6.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.7.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.7.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.7.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.7.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.8.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.8.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.8.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.8.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.3.0.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.3.0.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.0.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.0.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.0.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.0.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.0.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.0.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "\tsize mismatch for backbone.stages.3.0.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.0.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.3.1.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.1.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "\tsize mismatch for backbone.stages.3.1.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.1.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.3.2.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.2.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "\tsize mismatch for backbone.stages.3.2.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.2.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for head.final_layer.weight: copying a param with shape torch.Size([1152, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 256, 1, 1]).\n",
      "\tsize mismatch for head.final_layer.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([576]).\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ConvNeXtPose:\n\tsize mismatch for backbone.downsample_layers.0.0.weight: copying a param with shape torch.Size([48, 3, 4, 4]) from checkpoint, the shape in current model is torch.Size([192, 3, 4, 4]).\n\tsize mismatch for backbone.downsample_layers.0.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.1.weight: copying a param with shape torch.Size([96, 48, 2, 2]) from checkpoint, the shape in current model is torch.Size([384, 192, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.1.1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.1.weight: copying a param with shape torch.Size([192, 96, 2, 2]) from checkpoint, the shape in current model is torch.Size([768, 384, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.2.1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.1.weight: copying a param with shape torch.Size([384, 192, 2, 2]) from checkpoint, the shape in current model is torch.Size([1536, 768, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.3.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.0.0.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.0.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.0.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.0.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.0.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.1.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.1.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.1.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.1.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.2.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.2.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.2.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.2.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.1.0.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.0.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.0.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.0.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.0.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.1.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.1.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.1.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.1.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.2.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.2.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.2.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.2.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.2.0.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.0.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.0.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.0.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.0.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.1.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.1.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.1.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.1.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.2.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.2.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.2.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.2.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.3.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.3.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.3.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.3.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.4.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.4.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.4.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.4.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.5.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.5.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.5.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.5.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.6.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.6.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.6.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.6.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.7.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.7.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.7.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.7.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.8.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.8.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.8.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.8.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.3.0.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.0.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.0.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.0.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.0.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.1.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.1.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.1.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.1.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.2.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.2.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.2.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.2.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for head.final_layer.weight: copying a param with shape torch.Size([1152, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 256, 1, 1]).\n\tsize mismatch for head.final_layer.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([576]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/kaggle/working/ConvNeXtPose/main/../common/base.py\u001b[0m in \u001b[0;36m_make_model\u001b[0;34m(self, test_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✓ Checkpoint cargado sin necesidad de remapping\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DataParallel:\n\tMissing key(s) in state_dict: \"module.backbone.stages.2.9.dwconv.weight\", \"module.backbone.stages.2.9.dwconv.bias\", \"module.backbone.stages.2.9.norm.weight\", \"module.backbone.stages.2.9.norm.bias\", \"module.backbone.stages.2.9.norm.running_mean\", \"module.backbone.stages.2.9.norm.running_var\", \"module.backbone.stages.2.9.pwconv1.weight\", \"module.backbone.stages.2.9.pwconv1.bias\", \"module.backbone.stages.2.9.pwconv2.weight\", \"module.backbone.stages.2.9.pwconv2.bias\", \"module.backbone.stages.2.10.dwconv.weight\", \"module.backbone.stages.2.10.dwconv.bias\", \"module.backbone.stages.2.10.norm.weight\", \"module.backbone.stages.2.10.norm.bias\", \"module.backbone.stages.2.10.norm.running_mean\", \"module.backbone.stages.2.10.norm.running_var\", \"module.backbone.stages.2.10.pwconv1.weight\", \"module.backbone.stages.2.10.pwconv1.bias\", \"module.backbone.stages.2.10.pwconv2.weight\", \"module.backbone.stages.2.10.pwconv2.bias\", \"module.backbone.stages.2.11.dwconv.weight\", \"module.backbone.stages.2.11.dwconv.bias\", \"module.backbone.stages.2.11.norm.weight\", \"module.backbone.stages.2.11.norm.bias\", \"module.backbone.stages.2.11.norm.running_mean\", \"module.backbone.stages.2.11.norm.running_var\", \"module.backbone.stages.2.11.pwconv1.weight\", \"module.backbone.stages.2.11.pwconv1.bias\", \"module.backbone.stages.2.11.pwconv2.weight\", \"module.backbone.stages.2.11.pwconv2.bias\", \"module.backbone.stages.2.12.dwconv.weight\", \"module.backbone.stages.2.12.dwconv.bias\", \"module.backbone.stages.2.12.norm.weight\", \"module.backbone.stages.2.12.norm.bias\", \"module.backbone.stages.2.12.norm.running_mean\", \"module.backbone.stages.2.12.norm.running_var\", \"module.backbone.stages.2.12.pwconv1.weight\", \"module.backbone.stages.2.12.pwconv1.bias\", \"module.backbone.stages.2.12.pwconv2.weight\", \"module.backbone.stages.2.12.pwconv2.bias\", \"module.backbone.stages.2.13.dwconv.weight\", \"module.backbone.stages.2.13.dwconv.bias\", \"module.backbone.stages.2.13.norm.weight\", \"module.backbone.stages.2.13.norm.bias\", \"module.backbone.stages.2.13.norm.running_mean\", \"module.backbone.stages.2.13.norm.running_var\", \"module.backbone.stages.2.13.pwconv1.weight\", \"module.backbone.stages.2.13.pwconv1.bias\", \"module.backbone.stages.2.13.pwconv2.weight\", \"module.backbone.stages.2.13.pwconv2.bias\", \"module.backbone.stages.2.14.dwconv.weight\", \"module.backbone.stages.2.14.dwconv.bias\", \"module.backbone.stages.2.14.norm.weight\", \"module.backbone.stages.2.14.norm.bias\", \"module.backbone.stages.2.14.norm.running_mean\", \"module.backbone.stages.2.14.norm.running_var\", \"module.backbone.stages.2.14.pwconv1.weight\", \"module.backbone.stages.2.14.pwconv1.bias\", \"module.backbone.stages.2.14.pwconv2.weight\", \"module.backbone.stages.2.14.pwconv2.bias\", \"module.backbone.stages.2.15.dwconv.weight\", \"module.backbone.stages.2.15.dwconv.bias\", \"module.backbone.stages.2.15.norm.weight\", \"module.backbone.stages.2.15.norm.bias\", \"module.backbone.stages.2.15.norm.running_mean\", \"module.backbone.stages.2.15.norm.running_var\", \"module.backbone.stages.2.15.pwconv1.weight\", \"module.backbone.stages.2.15.pwconv1.bias\", \"module.backbone.stages.2.15.pwconv2.weight\", \"module.backbone.stages.2.15.pwconv2.bias\", \"module.backbone.stages.2.16.dwconv.weight\", \"module.backbone.stages.2.16.dwconv.bias\", \"module.backbone.stages.2.16.norm.weight\", \"module.backbone.stages.2.16.norm.bias\", \"module.backbone.stages.2.16.norm.running_mean\", \"module.backbone.stages.2.16.norm.running_var\", \"module.backbone.stages.2.16.pwconv1.weight\", \"module.backbone.stages.2.16.pwconv1.bias\", \"module.backbone.stages.2.16.pwconv2.weight\", \"module.backbone.stages.2.16.pwconv2.bias\", \"module.backbone.stages.2.17.dwconv.weight\", \"module.backbone.stages.2.17.dwconv.bias\", \"module.backbone.stages.2.17.norm.weight\", \"module.backbone.stages.2.17.norm.bias\", \"module.backbone.stages.2.17.norm.running_mean\", \"module.backbone.stages.2.17.norm.running_var\", \"module.backbone.stages.2.17.pwconv1.weight\", \"module.backbone.stages.2.17.pwconv1.bias\", \"module.backbone.stages.2.17.pwconv2.weight\", \"module.backbone.stages.2.17.pwconv2.bias\", \"module.backbone.stages.2.18.dwconv.weight\", \"module.backbone.stages.2.18.dwconv.bias\", \"module.backbone.stages.2.18.norm.weight\", \"module.backbone.stages.2.18.norm.bias\", \"module.backbone.stages.2.18.norm.running_mean\", \"module.backbone.stages.2.18.norm.running_var\", \"module.backbone.stages.2.18.pwconv1.weight\", \"module.backbone.stages.2.18.pwconv1.bias\", \"module.backbone.stages.2.18.pwconv2.weight\", \"module.backbone.stages.2.18.pwconv2.bias\", \"module.backbone.stages.2.19.dwconv.weight\", \"module.backbone.stages.2.19.dwconv.bias\", \"module.backbone.stages.2.19.norm.weight\", \"module.backbone.stages.2.19.norm.bias\", \"module.backbone.stages.2.19.norm.running_mean\", \"module.backbone.stages.2.19.norm.running_var\", \"module.backbone.stages.2.19.pwconv1.weight\", \"module.backbone.stages.2.19.pwconv1.bias\", \"module.backbone.stages.2.19.pwconv2.weight\", \"module.backbone.stages.2.19.pwconv2.bias\", \"module.backbone.stages.2.20.dwconv.weight\", \"module.backbone.stages.2.20.dwconv.bias\", \"module.backbone.stages.2.20.norm.weight\", \"module.backbone.stages.2.20.norm.bias\", \"module.backbone.stages.2.20.norm.running_mean\", \"module.backbone.stages.2.20.norm.running_var\", \"module.backbone.stages.2.20.pwconv1.weight\", \"module.backbone.stages.2.20.pwconv1.bias\", \"module.backbone.stages.2.20.pwconv2.weight\", \"module.backbone.stages.2.20.pwconv2.bias\", \"module.backbone.stages.2.21.dwconv.weight\", \"module.backbone.stages.2.21.dwconv.bias\", \"module.backbone.stages.2.21.norm.weight\", \"module.backbone.stages.2.21.norm.bias\", \"module.backbone.stages.2.21.norm.running_mean\", \"module.backbone.stages.2.21.norm.running_var\", \"module.backbone.stages.2.21.pwconv1.weight\", \"module.backbone.stages.2.21.pwconv1.bias\", \"module.backbone.stages.2.21.pwconv2.weight\", \"module.backbone.stages.2.21.pwconv2.bias\", \"module.backbone.stages.2.22.dwconv.weight\", \"module.backbone.stages.2.22.dwconv.bias\", \"module.backbone.stages.2.22.norm.weight\", \"module.backbone.stages.2.22.norm.bias\", \"module.backbone.stages.2.22.norm.running_mean\", \"module.backbone.stages.2.22.norm.running_var\", \"module.backbone.stages.2.22.pwconv1.weight\", \"module.backbone.stages.2.22.pwconv1.bias\", \"module.backbone.stages.2.22.pwconv2.weight\", \"module.backbone.stages.2.22.pwconv2.bias\", \"module.backbone.stages.2.23.dwconv.weight\", \"module.backbone.stages.2.23.dwconv.bias\", \"module.backbone.stages.2.23.norm.weight\", \"module.backbone.stages.2.23.norm.bias\", \"module.backbone.stages.2.23.norm.running_mean\", \"module.backbone.stages.2.23.norm.running_var\", \"module.backbone.stages.2.23.pwconv1.weight\", \"module.backbone.stages.2.23.pwconv1.bias\", \"module.backbone.stages.2.23.pwconv2.weight\", \"module.backbone.stages.2.23.pwconv2.bias\", \"module.backbone.stages.2.24.dwconv.weight\", \"module.backbone.stages.2.24.dwconv.bias\", \"module.backbone.stages.2.24.norm.weight\", \"module.backbone.stages.2.24.norm.bias\", \"module.backbone.stages.2.24.norm.running_mean\", \"module.backbone.stages.2.24.norm.running_var\", \"module.backbone.stages.2.24.pwconv1.weight\", \"module.backbone.stages.2.24.pwconv1.bias\", \"module.backbone.stages.2.24.pwconv2.weight\", \"module.backbone.stages.2.24.pwconv2.bias\", \"module.backbone.stages.2.25.dwconv.weight\", \"module.backbone.stages.2.25.dwconv.bias\", \"module.backbone.stages.2.25.norm.weight\", \"module.backbone.stages.2.25.norm.bias\", \"module.backbone.stages.2.25.norm.running_mean\", \"module.backbone.stages.2.25.norm.running_var\", \"module.backbone.stages.2.25.pwconv1.weight\", \"module.backbone.stages.2.25.pwconv1.bias\", \"module.backbone.stages.2.25.pwconv2.weight\", \"module.backbone.stages.2.25.pwconv2.bias\", \"module.backbone.stages.2.26.dwconv.weight\", \"module.backbone.stages.2.26.dwconv.bias\", \"module.backbone.stages.2.26.norm.weight\", \"module.backbone.stages.2.26.norm.bias\", \"module.backbone.stages.2.26.norm.running_mean\", \"module.backbone.stages.2.26.norm.running_var\", \"module.backbone.stages.2.26.pwconv1.weight\", \"module.backbone.stages.2.26.pwconv1.bias\", \"module.backbone.stages.2.26.pwconv2.weight\", \"module.backbone.stages.2.26.pwconv2.bias\", \"module.head.deconv_layers.0.dwconv.weight\", \"module.head.deconv_layers.0.dwconv.bias\", \"module.head.deconv_layers.0.norm.weight\", \"module.head.deconv_layers.0.norm.bias\", \"module.head.deconv_layers.0.norm.running_mean\", \"module.head.deconv_layers.0.norm.running_var\", \"module.head.deconv_layers.0.pwconv.weight\", \"module.head.deconv_layers.0.pwconv.bias\", \"module.head.deconv_layers.1.dwconv.weight\", \"module.head.deconv_layers.1.dwconv.bias\", \"module.head.deconv_layers.1.norm.weight\", \"module.head.deconv_layers.1.norm.bias\", \"module.head.deconv_layers.1.norm.running_mean\", \"module.head.deconv_layers.1.norm.running_var\", \"module.head.deconv_layers.1.pwconv.weight\", \"module.head.deconv_layers.1.pwconv.bias\", \"module.head.deconv_layers.2.dwconv.weight\", \"module.head.deconv_layers.2.dwconv.bias\", \"module.head.deconv_layers.2.norm.weight\", \"module.head.deconv_layers.2.norm.bias\", \"module.head.deconv_layers.2.norm.running_mean\", \"module.head.deconv_layers.2.norm.running_var\", \"module.head.deconv_layers.2.pwconv.weight\", \"module.head.deconv_layers.2.pwconv.bias\". \n\tUnexpected key(s) in state_dict: \"module.head.deconv_layers_1.0.weight\", \"module.head.deconv_layers_1.0.bias\", \"module.head.deconv_layers_1.1.weight\", \"module.head.deconv_layers_1.1.bias\", \"module.head.deconv_layers_1.1.running_mean\", \"module.head.deconv_layers_1.1.running_var\", \"module.head.deconv_layers_1.1.num_batches_tracked\", \"module.head.deconv_layers_1.2.weight\", \"module.head.deconv_layers_1.2.bias\", \"module.head.deconv_layers_2.0.weight\", \"module.head.deconv_layers_2.0.bias\", \"module.head.deconv_layers_2.1.weight\", \"module.head.deconv_layers_2.1.bias\", \"module.head.deconv_layers_2.1.running_mean\", \"module.head.deconv_layers_2.1.running_var\", \"module.head.deconv_layers_2.1.num_batches_tracked\", \"module.head.deconv_layers_2.2.weight\", \"module.head.deconv_layers_2.2.bias\", \"module.head.deconv_layers_3.0.weight\", \"module.head.deconv_layers_3.0.bias\", \"module.head.deconv_layers_3.1.weight\", \"module.head.deconv_layers_3.1.bias\", \"module.head.deconv_layers_3.1.running_mean\", \"module.head.deconv_layers_3.1.running_var\", \"module.head.deconv_layers_3.1.num_batches_tracked\", \"module.head.deconv_layers_3.2.weight\", \"module.head.deconv_layers_3.2.bias\". \n\tsize mismatch for module.backbone.downsample_layers.0.0.weight: copying a param with shape torch.Size([48, 3, 4, 4]) from checkpoint, the shape in current model is torch.Size([192, 3, 4, 4]).\n\tsize mismatch for module.backbone.downsample_layers.0.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.0.1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.0.1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.0.1.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.0.1.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.1.0.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.1.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.1.0.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.1.0.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.1.1.weight: copying a param with shape torch.Size([96, 48, 2, 2]) from checkpoint, the shape in current model is torch.Size([384, 192, 2, 2]).\n\tsize mismatch for module.backbone.downsample_layers.1.1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.downsample_layers.2.0.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.downsample_layers.2.0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.downsample_layers.2.0.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.downsample_layers.2.0.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.downsample_layers.2.1.weight: copying a param with shape torch.Size([192, 96, 2, 2]) from checkpoint, the shape in current model is torch.Size([768, 384, 2, 2]).\n\tsize mismatch for module.backbone.downsample_layers.2.1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.downsample_layers.3.0.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.downsample_layers.3.0.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.downsample_layers.3.0.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.downsample_layers.3.0.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.downsample_layers.3.1.weight: copying a param with shape torch.Size([384, 192, 2, 2]) from checkpoint, the shape in current model is torch.Size([1536, 768, 2, 2]).\n\tsize mismatch for module.backbone.downsample_layers.3.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.0.0.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.0.0.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.0.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.0.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.0.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.0.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.0.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.0.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.0.0.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.0.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.0.1.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.1.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.0.1.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.1.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.0.2.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.2.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.0.2.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.2.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.1.0.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.1.0.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.0.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.0.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.0.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.0.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.0.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.0.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.1.0.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.0.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.1.1.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.1.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.1.1.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.1.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.1.2.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.2.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.1.2.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.2.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.2.0.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.0.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.0.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.0.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.0.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.0.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.0.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.0.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.0.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.0.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.1.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.1.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.1.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.1.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.2.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.2.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.2.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.2.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.3.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.3.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.3.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.3.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.4.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.4.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.4.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.4.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.5.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.5.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.5.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.5.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.6.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.6.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.6.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.6.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.7.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.7.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.7.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.7.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.8.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.8.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.8.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.8.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.3.0.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.3.0.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.0.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.0.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.0.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.0.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.0.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.0.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for module.backbone.stages.3.0.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.0.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.3.1.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.1.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for module.backbone.stages.3.1.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.1.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.3.2.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.2.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for module.backbone.stages.3.2.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.2.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.head.final_layer.weight: copying a param with shape torch.Size([1152, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 256, 1, 1]).\n\tsize mismatch for module.head.final_layer.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([576]).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-955a9c30cf2f>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mtester\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_batch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHECKPOINT_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🚀 Ejecutando testing en epoch {CHECKPOINT_EPOCH}...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/ConvNeXtPose/main/../common/base.py\u001b[0m in \u001b[0;36m_make_model\u001b[0;34m(self, test_epoch)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Intentar carga con state dict remapeado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremapped_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✓ Checkpoint remapeado cargado exitosamente (strict=False)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2586\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ConvNeXtPose:\n\tsize mismatch for backbone.downsample_layers.0.0.weight: copying a param with shape torch.Size([48, 3, 4, 4]) from checkpoint, the shape in current model is torch.Size([192, 3, 4, 4]).\n\tsize mismatch for backbone.downsample_layers.0.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.1.weight: copying a param with shape torch.Size([96, 48, 2, 2]) from checkpoint, the shape in current model is torch.Size([384, 192, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.1.1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.1.weight: copying a param with shape torch.Size([192, 96, 2, 2]) from checkpoint, the shape in current model is torch.Size([768, 384, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.2.1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.1.weight: copying a param with shape torch.Size([384, 192, 2, 2]) from checkpoint, the shape in current model is torch.Size([1536, 768, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.3.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.0.0.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.0.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.0.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.0.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.0.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.1.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.1.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.1.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.1.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.2.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.2.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.2.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.2.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.1.0.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.0.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.0.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.0.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.0.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.1.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.1.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.1.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.1.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.2.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.2.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.2.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.2.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.2.0.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.0.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.0.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.0.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.0.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.1.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.1.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.1.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.1.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.2.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.2.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.2.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.2.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.3.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.3.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.3.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.3.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.4.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.4.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.4.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.4.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.5.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.5.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.5.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.5.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.6.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.6.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.6.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.6.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.7.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.7.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.7.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.7.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.8.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.8.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.8.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.8.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.3.0.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.0.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.0.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.0.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.0.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.1.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.1.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.1.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.1.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.2.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.2.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.2.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.2.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for head.final_layer.weight: copying a param with shape torch.Size([1152, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 256, 1, 1]).\n\tsize mismatch for head.final_layer.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([576])."
     ]
    }
   ],
   "source": [
    "# Testing con estructura correcta del proyecto\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. Cambiar al directorio main (donde está config.py)\n",
    "os.chdir('/kaggle/working/ConvNeXtPose/main')\n",
    "\n",
    "# 2. Importar config PRIMERO - esto configura automáticamente los paths\n",
    "from config import cfg\n",
    "\n",
    "# 3. Cargar variante ANTES de importar otros módulos\n",
    "VARIANT = 'XS'  # ✅ CORREGIDO: Checkpoint real es XS (dims=[48,96,192,384], depths=[3,3,9,3])\n",
    "# NOTA IMPORTANTE: Los archivos descargados como 'L', 'M', y 'S' contienen TODOS arquitectura XS\n",
    "# El análisis de log3.txt confirmó: checkpoint tiene dims=[48,96,192,384] y solo 9 bloques en stage 2\n",
    "# Ver CHECKPOINT_ARCHITECTURE_ANALYSIS.md para detalles completos\n",
    "CHECKPOINT_EPOCH = 83  # ← AJUSTAR según tu checkpoint\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  Testing ConvNeXtPose-{VARIANT}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "cfg.load_variant_config(VARIANT)\n",
    "cfg.set_args('0')  # GPU 0\n",
    "\n",
    "# 4. AHORA importar los demás módulos (config ya configuró sys.path)\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from base import Tester\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configurar CUDA solo si está disponible\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = False\n",
    "    cudnn.enabled = True\n",
    "    print(\"✅ CUDA habilitado\")\n",
    "else:\n",
    "    print(\"⚠️  Ejecutando en CPU (será muy lento)\")\n",
    "\n",
    "# 5. Crear tester y ejecutar\n",
    "tester = Tester()\n",
    "tester._make_batch_generator()\n",
    "tester._make_model(CHECKPOINT_EPOCH)\n",
    "\n",
    "print(f\"\\n🚀 Ejecutando testing en epoch {CHECKPOINT_EPOCH}...\\n\")\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for itr, input_img in enumerate(tqdm(tester.batch_generator)):\n",
    "        coord_out = tester.model(input_img)\n",
    "        \n",
    "        if cfg.flip_test:\n",
    "            from utils.pose_utils import flip\n",
    "            flipped_input_img = flip(input_img, dims=3)\n",
    "            flipped_coord_out = tester.model(flipped_input_img)\n",
    "            flipped_coord_out[:, :, 0] = cfg.output_shape[1] - flipped_coord_out[:, :, 0] - 1\n",
    "            for pair in tester.flip_pairs:\n",
    "                flipped_coord_out[:, pair[0], :], flipped_coord_out[:, pair[1], :] = \\\n",
    "                    flipped_coord_out[:, pair[1], :].clone(), flipped_coord_out[:, pair[0], :].clone()\n",
    "            coord_out = (coord_out + flipped_coord_out)/2.\n",
    "        \n",
    "        coord_out = coord_out.cpu().numpy()\n",
    "        preds.append(coord_out)\n",
    "\n",
    "# Evaluar\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "print(f\"\\n📊 Evaluando {len(preds)} predicciones...\\n\")\n",
    "tester._evaluate(preds, cfg.result_dir)\n",
    "\n",
    "print(f\"\\n✅ Testing completado!\")\n",
    "print(f\"📂 Resultados guardados en: {cfg.result_dir}\")\n",
    "print(f\"\\n💡 MPJPE esperado para XS: ~52.0 mm (Protocol 2)\")\n",
    "print(f\"💡 PA-MPJPE esperado para XS: ~36.5 mm (Protocol 1)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo M (Medium) - Opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-14T13:10:45.080382Z",
     "iopub.status.idle": "2025-10-14T13:10:45.080744Z",
     "shell.execute_reply": "2025-10-14T13:10:45.080576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Si tienes el checkpoint del modelo M, ejecuta esto:\n",
    "# !python test.py --gpu 0 --epochs {CHECKPOINT_EPOCH} --variant M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 PASO 5: Verificar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-14T13:10:45.081816Z",
     "iopub.status.idle": "2025-10-14T13:10:45.082089Z",
     "shell.execute_reply": "2025-10-14T13:10:45.081984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ver resultados generados\n",
    "%cd ..\n",
    "!ls -lh output/result/\n",
    "\n",
    "# Leer log de resultados\n",
    "import glob\n",
    "log_files = glob.glob('output/log/*.log')\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    print(f\"\\n📄 Últimas líneas del log ({os.path.basename(latest_log)}):\")\n",
    "    !tail -n 20 {latest_log}\n",
    "else:\n",
    "    print(\"⚠️  No se encontraron logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 PASO 6: Análisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-14T13:10:45.082667Z",
     "iopub.status.idle": "2025-10-14T13:10:45.082913Z",
     "shell.execute_reply": "2025-10-14T13:10:45.082809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_mpjpe_from_log(log_path):\n",
    "    \"\"\"Extrae el MPJPE del log\"\"\"\n",
    "    with open(log_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Buscar patrón de MPJPE\n",
    "    pattern = r'MPJPE.*?(\\d+\\.\\d+)'\n",
    "    matches = re.findall(pattern, content)\n",
    "    \n",
    "    if matches:\n",
    "        return float(matches[-1])  # Último valor\n",
    "    return None\n",
    "\n",
    "# Extraer resultados\n",
    "log_files = glob.glob('output/log/*.log')\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    mpjpe = extract_mpjpe_from_log(latest_log)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  📊 RESULTADOS FINALES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if mpjpe:\n",
    "        print(f\"\\n  MPJPE (Protocol 2): {mpjpe:.2f} mm\")\n",
    "        \n",
    "        # Comparar con paper\n",
    "        expected = {\n",
    "            'L': 42.3,\n",
    "            'M': 44.6\n",
    "        }\n",
    "        \n",
    "        # Determinar variante\n",
    "        for variant, expected_val in expected.items():\n",
    "            diff = abs(mpjpe - expected_val)\n",
    "            if diff < 5:\n",
    "                print(f\"\\n  Variante detectada: {variant}\")\n",
    "                print(f\"  Valor del paper: {expected_val:.2f} mm\")\n",
    "                print(f\"  Diferencia: {mpjpe - expected_val:+.2f} mm\")\n",
    "                \n",
    "                if diff < 2:\n",
    "                    print(\"  ✅ Resultado excelente (dentro de ±2mm)\")\n",
    "                elif diff < 5:\n",
    "                    print(\"  ✓ Resultado aceptable (dentro de ±5mm)\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"\\n⚠️  No se pudo extraer MPJPE del log\")\n",
    "        print(\"Revisa el log manualmente en output/log/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"❌ No se encontraron logs de testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 PASO 7: Guardar Outputs\n",
    "\n",
    "Kaggle guarda automáticamente todo en `/kaggle/working/`. Opcionalmente puedes copiar resultados específicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-14T13:10:45.083818Z",
     "iopub.status.idle": "2025-10-14T13:10:45.084254Z",
     "shell.execute_reply": "2025-10-14T13:10:45.084055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Crear resumen de resultados\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model': 'ConvNeXtPose-XS',  # ✅ CORREGIDO: Checkpoint real es XS\n",
    "    'checkpoint_epoch': CHECKPOINT_EPOCH,\n",
    "    'dataset': 'Human3.6M Protocol 2',\n",
    "    'mpjpe_mm': mpjpe if 'mpjpe' in locals() else None,\n",
    "    'expected_mpjpe_mm': 52.0,  # Valor esperado para XS\n",
    "    'expected_pa_mpjpe_mm': 36.5,  # Valor esperado para XS (Protocol 1)\n",
    "    'architecture': {\n",
    "        'dims': [48, 96, 192, 384],\n",
    "        'depths': [3, 3, 9, 3],\n",
    "        'head': '2-UP (2 deconv layers)'\n",
    "    },\n",
    "    'pytorch_version': torch.__version__,\n",
    "    'cuda_version': torch.version.cuda if torch.cuda.is_available() else None,\n",
    "    'note': 'Checkpoints etiquetados como L/M/S contienen arquitectura XS. Ver CHECKPOINT_ARCHITECTURE_ANALYSIS.md'\n",
    "}\n",
    "\n",
    "# Guardar resumen\n",
    "with open('output/result/test_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"✓ Resumen guardado en output/result/test_summary.json\")\n",
    "print(\"\\n📄 Contenido:\")\n",
    "print(json.dumps(summary, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Testing Completado!\n",
    "\n",
    "Los resultados están en:\n",
    "- **Logs**: `output/log/`\n",
    "- **Resultados**: `output/result/`\n",
    "- **Resumen JSON**: `output/result/test_summary.json`\n",
    "\n",
    "Todos los archivos en `/kaggle/working/ConvNeXtPose/output/` se guardarán automáticamente cuando hagas commit del notebook."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2200515,
     "sourceId": 5116687,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8460258,
     "sourceId": 13341353,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
