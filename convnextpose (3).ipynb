{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ ConvNeXtPose Testing en Kaggle - Modelo XS\n",
    "\n",
    "Este notebook eval√∫a el modelo ConvNeXtPose XS en Human3.6M Protocol 2.\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANTE:** Los checkpoints descargados etiquetados como \"L\", \"M\", y \"S\" contienen TODOS la arquitectura **XS**:\n",
    "- dims = `[48, 96, 192, 384]`\n",
    "- depths = `[3, 3, 9, 3]`\n",
    "\n",
    "Ver `CHECKPOINT_ARCHITECTURE_ANALYSIS.md` para an√°lisis completo.\n",
    "\n",
    "**Datasets requeridos:**\n",
    "- Human3.6M Dataset (con S9_ACT2_16, S11_ACT2_16, annotations)\n",
    "- ConvNeXtPose Pre-trained Models (checkpoints .tar)\n",
    "\n",
    "**GPU recomendada:** T4 x2 o P100\n",
    "\n",
    "**Resultados esperados (XS):**\n",
    "- MPJPE (Protocol 2): ~52.0 mm\n",
    "- PA-MPJPE (Protocol 1): ~36.5 mm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ PASO 1: Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:01.076350Z",
     "iopub.status.busy": "2025-10-14T13:09:01.075988Z",
     "iopub.status.idle": "2025-10-14T13:09:01.192919Z",
     "shell.execute_reply": "2025-10-14T13:09:01.191852Z",
     "shell.execute_reply.started": "2025-10-14T13:09:01.076305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:01.194721Z",
     "iopub.status.busy": "2025-10-14T13:09:01.194418Z",
     "iopub.status.idle": "2025-10-14T13:09:01.198544Z",
     "shell.execute_reply": "2025-10-14T13:09:01.197567Z",
     "shell.execute_reply.started": "2025-10-14T13:09:01.194691Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!rm -r ConvNeXtPose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:01.200474Z",
     "iopub.status.busy": "2025-10-14T13:09:01.200169Z",
     "iopub.status.idle": "2025-10-14T13:09:17.597159Z",
     "shell.execute_reply": "2025-10-14T13:09:17.596397Z",
     "shell.execute_reply.started": "2025-10-14T13:09:01.200452Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ConvNeXtPose'...\n",
      "remote: Enumerating objects: 1166, done.\u001b[K\n",
      "remote: Counting objects: 100% (288/288), done.\u001b[K\n",
      "remote: Compressing objects: 100% (225/225), done.\u001b[K\n",
      "remote: Total 1166 (delta 103), reused 222 (delta 62), pack-reused 878 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1166/1166), 318.73 MiB | 40.05 MiB/s, done.\n",
      "Resolving deltas: 100% (341/341), done.\n",
      "Updating files: 100% (207/207), done.\n",
      "/kaggle/working/ConvNeXtPose\n",
      "PyTorch: 2.5.1+cu121\n",
      "CUDA disponible: True\n",
      "GPU: Tesla T4\n",
      "Memoria GPU: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "# Clonar repositorio\n",
    "!git clone https://github.com/EstebanCabreraArbizu/ConvNeXtPose.git\n",
    "%cd ConvNeXtPose\n",
    "!git fetch origin\n",
    "\n",
    "# Verificar versiones\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è PASO 2: Configurar Dataset Human3.6M\n",
    "\n",
    "Usamos enlaces simb√≥licos para evitar copiar ~30GB de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:17.598891Z",
     "iopub.status.busy": "2025-10-14T13:09:17.598573Z",
     "iopub.status.idle": "2025-10-14T13:09:17.721633Z",
     "shell.execute_reply": "2025-10-14T13:09:17.720586Z",
     "shell.execute_reply.started": "2025-10-14T13:09:17.598872Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ConvNeXtPose\n"
     ]
    }
   ],
   "source": [
    "!pwd ConvNeXtPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:17.723001Z",
     "iopub.status.busy": "2025-10-14T13:09:17.722755Z",
     "iopub.status.idle": "2025-10-14T13:09:17.854934Z",
     "shell.execute_reply": "2025-10-14T13:09:17.853856Z",
     "shell.execute_reply.started": "2025-10-14T13:09:17.722979Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Dataset encontrado en /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net\n",
      "\n",
      "üìÇ Contenido:\n",
      "'annotations (1)'   S11_ACT2_16   S9_ACT2_16\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANTE: Ajusta este path al nombre real de tu dataset en Kaggle\n",
    "KAGGLE_DATASET_PATH = '/kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net'  # ‚Üê CAMBIAR SEG√öN TU DATASET\n",
    "\n",
    "# Verificar que el dataset existe\n",
    "import os\n",
    "if not os.path.exists(KAGGLE_DATASET_PATH):\n",
    "    print(f\"‚ùå Dataset no encontrado en {KAGGLE_DATASET_PATH}\")\n",
    "    print(\"\\nüìÇ Datasets disponibles:\")\n",
    "    !ls /kaggle/input/\n",
    "    raise FileNotFoundError(\"Verifica el nombre del dataset y actualiza KAGGLE_DATASET_PATH\")\n",
    "else:\n",
    "    print(f\"‚úì Dataset encontrado en {KAGGLE_DATASET_PATH}\")\n",
    "    print(\"\\nüìÇ Contenido:\")\n",
    "    !ls {KAGGLE_DATASET_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Opcional) Diagnosticar Estructura del Dataset\n",
    "\n",
    "Si tienes dudas sobre la estructura de tu dataset, ejecuta esta celda primero para ver c√≥mo est√°n organizadas las carpetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:17.856240Z",
     "iopub.status.busy": "2025-10-14T13:09:17.855965Z",
     "iopub.status.idle": "2025-10-14T13:09:17.859726Z",
     "shell.execute_reply": "2025-10-14T13:09:17.858790Z",
     "shell.execute_reply.started": "2025-10-14T13:09:17.856203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Diagnosticar estructura del dataset (√∫til para identificar carpetas anidadas)\n",
    "# !python diagnose_kaggle_dataset.py {KAGGLE_DATASET_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:17.860997Z",
     "iopub.status.busy": "2025-10-14T13:09:17.860710Z",
     "iopub.status.idle": "2025-10-14T13:09:18.107296Z",
     "shell.execute_reply": "2025-10-14T13:09:18.106454Z",
     "shell.execute_reply.started": "2025-10-14T13:09:17.860968Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  Configuraci√≥n de Dataset Human3.6M para ConvNeXtPose\n",
      "======================================================================\n",
      "üìÇ Dataset Kaggle:     /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net\n",
      "üìÇ Proyecto ConvNeXt:  /kaggle/working/ConvNeXtPose\n",
      "\n",
      "‚úì Directorio del proyecto encontrado: /kaggle/working/ConvNeXtPose/data/Human36M\n",
      "‚úì Manteniendo m√≥dulos Python originales en /kaggle/working/ConvNeXtPose/data\n",
      "\n",
      "üìÅ [1/3] Configurando annotations...\n",
      "  ‚úì Encontrado: annotations (1)/annotations\n",
      "    (21 archivos JSON detectados)\n",
      "  ‚úì Creado: annotations -> /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net/annotations (1)/annotations\n",
      "\n",
      "üë• [2/3] Configurando sujetos S9 y S11...\n",
      "  ‚úì Creado: S9 -> /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net/S9_ACT2_16\n",
      "  ‚úì Creado: S11 -> /kaggle/input/human3-6m-for-convnextpose-and-3dmpee-pose-net/S11_ACT2_16\n",
      "\n",
      "üì¶ [3/3] Configurando bbox_root...\n",
      "  ‚ö†Ô∏è  No se encontr√≥ bbox_root (opcional)\n",
      "\n",
      "======================================================================\n",
      "  ‚úÖ Configuraci√≥n Completada\n",
      "======================================================================\n",
      "\n",
      "üìÇ Estructura creada en: /kaggle/working/ConvNeXtPose/data/Human36M\n",
      "\n",
      "Contenido:\n",
      "  üìÅ __pycache__/\n",
      "  üîó annotations -> annotations\n",
      "  üìÅ bbox_root/\n",
      "  üìÅ bbox_root/Subject 9,11 (trained on subject 1,5,6,7,8)/\n",
      "  üìÅ images/\n",
      "  üîó images/S11 -> S11_ACT2_16\n",
      "  üîó images/S9 -> S9_ACT2_16\n",
      "\n",
      "======================================================================\n",
      "  ‚úÖ LISTO - NO necesitas configurar CONVNEXPOSE_DATA_DIR\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Los m√≥dulos Python originales est√°n intactos en:\n",
      "   /kaggle/working/ConvNeXtPose/data/dataset.py\n",
      "   /kaggle/working/ConvNeXtPose/data/Human36M/Human36M.py\n",
      "\n",
      "‚úÖ El dataset de Kaggle est√° enlazado en:\n",
      "   /kaggle/working/ConvNeXtPose/data/Human36M/images\n",
      "   /kaggle/working/ConvNeXtPose/data/Human36M/annotations\n",
      "   /kaggle/working/ConvNeXtPose/data/Human36M/bbox_root (si existe)\n",
      "\n",
      "üöÄ Puedes ejecutar el testing directamente:\n",
      "   %cd /kaggle/working/ConvNeXtPose/main\n",
      "   !python test.py --gpu 0 --epochs 70 --variant L\n",
      "\n",
      "\n",
      "üéâ Setup completado exitosamente!\n",
      "\n",
      "üí° Tip: Ejecuta con --verify para verificar la estructura:\n",
      "   !python setup_kaggle_dataset.py --verify /kaggle/working/ConvNeXtPose\n",
      "\n",
      "‚úÖ Dataset enlazado en data/Human36M/\n",
      "‚úÖ M√≥dulos Python originales intactos en data/\n",
      "‚úÖ Carpetas anidadas detectadas autom√°ticamente\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar script de configuraci√≥n\n",
    "# IMPORTANTE: Esto enlaza el dataset DENTRO de data/Human36M/, NO reemplaza data/\n",
    "# El script detecta autom√°ticamente carpetas anidadas (ej: annotations (1)/annotations/)\n",
    "!python setup_kaggle_dataset.py --kaggle-input {KAGGLE_DATASET_PATH} --project-root /kaggle/working/ConvNeXtPose\n",
    "\n",
    "print(\"\\n‚úÖ Dataset enlazado en data/Human36M/\")\n",
    "print(\"‚úÖ M√≥dulos Python originales intactos en data/\")\n",
    "print(\"‚úÖ Carpetas anidadas detectadas autom√°ticamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:18.108494Z",
     "iopub.status.busy": "2025-10-14T13:09:18.108262Z",
     "iopub.status.idle": "2025-10-14T13:09:18.326006Z",
     "shell.execute_reply": "2025-10-14T13:09:18.324873Z",
     "shell.execute_reply.started": "2025-10-14T13:09:18.108474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  üîç Verificaci√≥n de Estructura\n",
      "======================================================================\n",
      "  ‚úì data/dataset.py\n",
      "  ‚úì data/Human36M/Human36M.py\n",
      "  ‚úì data/Human36M/annotations\n",
      "  ‚úì data/Human36M/images\n",
      "  ‚úì data/Human36M/images/S9\n",
      "  ‚úì data/Human36M/images/S11\n",
      "  ‚úì data/Human36M/bbox_root (optional)\n",
      "\n",
      "  ‚úÖ Estructura verificada correctamente\n",
      "  ‚úÖ M√≥dulos Python intactos en data/\n",
      "  ‚úÖ Dataset enlazado en data/Human36M/\n"
     ]
    }
   ],
   "source": [
    "# Verificar que la estructura es correcta\n",
    "!python setup_kaggle_dataset.py --verify /kaggle/working/ConvNeXtPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:18.329365Z",
     "iopub.status.busy": "2025-10-14T13:09:18.329090Z",
     "iopub.status.idle": "2025-10-14T13:09:18.537978Z",
     "shell.execute_reply": "2025-10-14T13:09:18.536919Z",
     "shell.execute_reply.started": "2025-10-14T13:09:18.329338Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  üîç VERIFICACI√ìN R√ÅPIDA - Estructura del Proyecto\n",
      "======================================================================\n",
      "\n",
      "üìÑ M√≥dulos Python originales:\n",
      "  ‚úì data/dataset.py\n",
      "  ‚úì data/multiple_datasets.py\n",
      "  ‚úì data/Human36M/Human36M.py\n",
      "  ‚úì common/base.py\n",
      "  ‚úì main/config.py\n",
      "\n",
      "üìÇ Dataset de Kaggle (enlaces):\n",
      "  ‚úì data/Human36M/images/S9\n",
      "  ‚úì data/Human36M/images/S11\n",
      "  ‚úì data/Human36M/annotations\n",
      "  ‚úì data/Human36M/bbox_root\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ESTRUCTURA CORRECTA - Listo para testing\n",
      "\n",
      "üöÄ Siguiente paso:\n",
      "   %cd /kaggle/working/ConvNeXtPose/main\n",
      "   !python test.py --gpu 0 --epochs 83 --variant L\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar que la estructura es correcta\n",
    "!python verify_kaggle_structure.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ PASO 3: Preparar Checkpoints\n",
    "\n",
    "Extraer los modelos pre-entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:18.540716Z",
     "iopub.status.busy": "2025-10-14T13:09:18.540485Z",
     "iopub.status.idle": "2025-10-14T13:09:18.664481Z",
     "shell.execute_reply": "2025-10-14T13:09:18.663587Z",
     "shell.execute_reply.started": "2025-10-14T13:09:18.540696Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCHITECTURE_ADAPTATION_COMPLETE.md  KAGGLE_TESTING_GUIDE.md\n",
      "assets\t\t\t\t     kaggle_testing_notebook.ipynb\n",
      "AUTHOR_CONTACT_GUIDE.md\t\t     LICENSE\n",
      "CHECKLIST_TESTING.md\t\t     list_google_drive_contents.py\n",
      "CHECKPOINT_EXTRACTION_FIX.md\t     log2.txt\n",
      "CHECKPOINT_INVESTIGATION_REPORT.md   log.txt\n",
      "CHECKPOINT_MISLABELING_ISSUE.md      main\n",
      "common\t\t\t\t     NESTED_FOLDERS_SOLUTION.md\n",
      "CORRECCION_CONFIG_S.md\t\t     output\n",
      "data\t\t\t\t     PASOS_TESTING.md\n",
      "demo\t\t\t\t     PLAN_ACCION_INMEDIATO.md\n",
      "diagnose_kaggle_dataset.py\t     quick_start.sh\n",
      "EMAIL_TEMPLATE_AUTHORS.md\t     README.md\n",
      "ESTADO_PROYECTO.md\t\t     README_TESTING.md\n",
      "EXPLICACION_DIMS_INCORRECTOS.md      requirements.txt\n",
      "exports\t\t\t\t     RESUMEN_EJECUTIVO.md\n",
      "GITHUB_ISSUE_TEMPLATE.md\t     RESUMEN_RETESTING.md\n",
      "GUIA_TESTING_MODELOS_L_M.md\t     setup_kaggle_dataset.py\n",
      "identify_model_variant.py\t     tool\n",
      "KAGGLE_DATASET_FIX.md\t\t     UBUNTU_QUICKSTART.md\n",
      "KAGGLE_EXECUTION_GUIDE.md\t     ubuntu_quickstart.sh\n",
      "KAGGLE_QUICK_SOLUTION.md\t     verify_kaggle_structure.py\n",
      "KAGGLE_QUICKSTART.md\t\t     vis\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:18.665549Z",
     "iopub.status.busy": "2025-10-14T13:09:18.665297Z",
     "iopub.status.idle": "2025-10-14T13:09:22.944974Z",
     "shell.execute_reply": "2025-10-14T13:09:22.943903Z",
     "shell.execute_reply.started": "2025-10-14T13:09:18.665528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:09:22.946262Z",
     "iopub.status.busy": "2025-10-14T13:09:22.945999Z",
     "iopub.status.idle": "2025-10-14T13:10:15.430648Z",
     "shell.execute_reply": "2025-10-14T13:10:15.429886Z",
     "shell.execute_reply.started": "2025-10-14T13:09:22.946241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1eIaMqTYG-30CuPULs9LzSfeouAzYYHQW ConvNeXtPose_L.tar\n",
      "Processing file 1X_H-6S4xrQjW9GhJ3yWB-AXqUHddvkOI ConvNeXtPose_M.tar\n",
      "Processing file 1OriQPQ3uRY8MWPHP9KnwPaKawzrontqH ConvNeXtPose_S.tar\n",
      "Processing file 165D0rU2GImmRe7u7DNe6eKJG8voBIcGh ConvNeXtPose_XS.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1eIaMqTYG-30CuPULs9LzSfeouAzYYHQW\n",
      "To: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_L.tar\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101M/101M [00:02<00:00, 45.4MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1X_H-6S4xrQjW9GhJ3yWB-AXqUHddvkOI\n",
      "To: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_M.tar\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91.3M/91.3M [00:00<00:00, 136MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OriQPQ3uRY8MWPHP9KnwPaKawzrontqH\n",
      "To: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_S.tar\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 89.6M/89.6M [00:00<00:00, 89.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=165D0rU2GImmRe7u7DNe6eKJG8voBIcGh\n",
      "To: /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_XS.tar\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42.5M/42.5M [00:00<00:00, 153MB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_tar/ConvNeXtPose_L.tar',\n",
       " 'models_tar/ConvNeXtPose_M.tar',\n",
       " 'models_tar/ConvNeXtPose_S.tar',\n",
       " 'models_tar/ConvNeXtPose_XS.tar']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "folder_id = \"12H7zkLvmJtrkCmAUAPkQ6788WAnO60gI\"\n",
    "output = \"models_tar\"\n",
    "\n",
    "gdown.download_folder(id=folder_id, output=output, quiet=False, use_cookies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:15.431633Z",
     "iopub.status.busy": "2025-10-14T13:10:15.431280Z",
     "iopub.status.idle": "2025-10-14T13:10:15.554873Z",
     "shell.execute_reply": "2025-10-14T13:10:15.554094Z",
     "shell.execute_reply.started": "2025-10-14T13:10:15.431612Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARCHITECTURE_ADAPTATION_COMPLETE.md  kaggle_testing_notebook.ipynb\n",
      "assets\t\t\t\t     LICENSE\n",
      "AUTHOR_CONTACT_GUIDE.md\t\t     list_google_drive_contents.py\n",
      "CHECKLIST_TESTING.md\t\t     log2.txt\n",
      "CHECKPOINT_EXTRACTION_FIX.md\t     log.txt\n",
      "CHECKPOINT_INVESTIGATION_REPORT.md   main\n",
      "CHECKPOINT_MISLABELING_ISSUE.md      models_tar\n",
      "common\t\t\t\t     NESTED_FOLDERS_SOLUTION.md\n",
      "CORRECCION_CONFIG_S.md\t\t     output\n",
      "data\t\t\t\t     PASOS_TESTING.md\n",
      "demo\t\t\t\t     PLAN_ACCION_INMEDIATO.md\n",
      "diagnose_kaggle_dataset.py\t     quick_start.sh\n",
      "EMAIL_TEMPLATE_AUTHORS.md\t     README.md\n",
      "ESTADO_PROYECTO.md\t\t     README_TESTING.md\n",
      "EXPLICACION_DIMS_INCORRECTOS.md      requirements.txt\n",
      "exports\t\t\t\t     RESUMEN_EJECUTIVO.md\n",
      "GITHUB_ISSUE_TEMPLATE.md\t     RESUMEN_RETESTING.md\n",
      "GUIA_TESTING_MODELOS_L_M.md\t     setup_kaggle_dataset.py\n",
      "identify_model_variant.py\t     tool\n",
      "KAGGLE_DATASET_FIX.md\t\t     UBUNTU_QUICKSTART.md\n",
      "KAGGLE_EXECUTION_GUIDE.md\t     ubuntu_quickstart.sh\n",
      "KAGGLE_QUICK_SOLUTION.md\t     verify_kaggle_structure.py\n",
      "KAGGLE_QUICKSTART.md\t\t     vis\n",
      "KAGGLE_TESTING_GUIDE.md\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:15.556241Z",
     "iopub.status.busy": "2025-10-14T13:10:15.555925Z",
     "iopub.status.idle": "2025-10-14T13:10:15.677921Z",
     "shell.execute_reply": "2025-10-14T13:10:15.677131Z",
     "shell.execute_reply.started": "2025-10-14T13:10:15.556209Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'src': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:15.679251Z",
     "iopub.status.busy": "2025-10-14T13:10:15.678934Z",
     "iopub.status.idle": "2025-10-14T13:10:15.800238Z",
     "shell.execute_reply": "2025-10-14T13:10:15.799451Z",
     "shell.execute_reply.started": "2025-10-14T13:10:15.679218Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ConvNeXtPose\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:15.801407Z",
     "iopub.status.busy": "2025-10-14T13:10:15.801180Z",
     "iopub.status.idle": "2025-10-14T13:10:15.924046Z",
     "shell.execute_reply": "2025-10-14T13:10:15.923030Z",
     "shell.execute_reply.started": "2025-10-14T13:10:15.801387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 310M\n",
      "-rw-r--r-- 1 root root 97M Oct  4  2023 ConvNeXtPose_L.tar\n",
      "-rw-r--r-- 1 root root 88M Oct  4  2023 ConvNeXtPose_M.tar\n",
      "-rw-r--r-- 1 root root 86M Oct  4  2023 ConvNeXtPose_S.tar\n",
      "-rw-r--r-- 1 root root 41M Oct  4  2023 ConvNeXtPose_XS.tar\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /kaggle/working/ConvNeXtPose/models_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:15.925534Z",
     "iopub.status.busy": "2025-10-14T13:10:15.925198Z",
     "iopub.status.idle": "2025-10-14T13:10:16.048823Z",
     "shell.execute_reply": "2025-10-14T13:10:16.048039Z",
     "shell.execute_reply.started": "2025-10-14T13:10:15.925503Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Modelos disponibles:\n",
      "total 310M\n",
      "-rw-r--r-- 1 root root 97M Oct  4  2023 ConvNeXtPose_L.tar\n",
      "-rw-r--r-- 1 root root 88M Oct  4  2023 ConvNeXtPose_M.tar\n",
      "-rw-r--r-- 1 root root 86M Oct  4  2023 ConvNeXtPose_S.tar\n",
      "-rw-r--r-- 1 root root 41M Oct  4  2023 ConvNeXtPose_XS.tar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# IMPORTANTE: Ajusta seg√∫n el nombre de tu dataset de modelos\n",
    "MODELS_DATASET_PATH = '/kaggle/working/ConvNeXtPose/models_tar'\n",
    "# Verificar modelos disponibles\n",
    "if os.path.exists(MODELS_DATASET_PATH):\n",
    "    print(\"üì¶ Modelos disponibles:\")\n",
    "    !ls -lh {MODELS_DATASET_PATH}\n",
    "else:\n",
    "    print(f\"‚ùå Dataset de modelos no encontrado: {MODELS_DATASET_PATH}\")\n",
    "    print(\"\\nüìÇ Datasets disponibles:\")\n",
    "    !ls /kaggle/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:16.050370Z",
     "iopub.status.busy": "2025-10-14T13:10:16.050036Z",
     "iopub.status.idle": "2025-10-14T13:10:17.426976Z",
     "shell.execute_reply": "2025-10-14T13:10:17.425992Z",
     "shell.execute_reply.started": "2025-10-14T13:10:16.050336Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üì¶ Extrayendo modelo L desde /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_L.tar...\n",
      "   üìè Tama√±o del archivo: 96.19 MB\n",
      "   üîç Primeros bytes (hex): 504b03040000080800000000000000000000000000000000000018000a00736e617073686f745f38332e7074682f64617461\n",
      "   ‚úì Formato: ZIP - Extra√≠do: 808 archivos\n",
      "   ‚úì Checkpoint encontrado: snapshot_83.pth/\n",
      "   üîÑ Convirtiendo formato legacy ‚Üí formato moderno...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-2ab6ed486f7e>:162: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  typed_storage = torch.storage.TypedStorage(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Archivo creado: snapshot_83.pth (96.2 MB)\n",
      "   ‚úì Verificaci√≥n exitosa - Keys: ['epoch', 'network', 'optimizer']\n",
      "   ‚úì Conversi√≥n completada\n",
      "\n",
      "üì¶ Extrayendo modelo M desde /kaggle/working/ConvNeXtPose/models_tar/ConvNeXtPose_M.tar...\n",
      "   üìè Tama√±o del archivo: 87.10 MB\n",
      "   üîç Primeros bytes (hex): 504b03040000080800000000000000000000000000000000000010001200617263686976652f646174612e706b6c46420e00\n",
      "   ‚úì Formato: ZIP - Extra√≠do: 808 archivos\n",
      "   ‚úì Checkpoint encontrado: archive/\n",
      "   üîÑ Convirtiendo formato legacy ‚Üí formato moderno...\n",
      "   ‚úì Archivo creado: snapshot_70.pth (87.1 MB)\n",
      "   ‚úì Verificaci√≥n exitosa - Keys: ['epoch', 'network', 'optimizer']\n",
      "   ‚úì Conversi√≥n completada\n",
      "============================================================\n",
      "\n",
      "üìÇ Checkpoints disponibles:\n",
      "  ‚úì snapshot_70.pth (87.1 MB)\n",
      "    ‚Üí Keys: ['epoch', 'network', 'optimizer']\n",
      "    ‚Üí ‚úÖ Formato v√°lido (7,596,986 par√°metros)\n",
      "  ‚úì snapshot_83.pth (96.2 MB)\n",
      "    ‚Üí Keys: ['epoch', 'network', 'optimizer']\n",
      "    ‚Üí ‚úÖ Formato v√°lido (8,391,354 par√°metros)\n",
      "\n",
      "üí° Modelo L: Usa CHECKPOINT_EPOCH = 83\n",
      "üí° Modelo M: Usa CHECKPOINT_EPOCH = 70\n",
      "\n",
      "‚úÖ Los checkpoints est√°n listos para torch.load()\n",
      "   Formato: PyTorch moderno (.pth)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import tarfile\n",
    "import torch\n",
    "\n",
    "# Crear directorio para modelos\n",
    "os.makedirs('output/model_dump', exist_ok=True)\n",
    "\n",
    "# Funci√≥n para extraer y convertir checkpoints\n",
    "def extract_checkpoint(tar_path, model_name, expected_epoch=None):\n",
    "    \"\"\"Extrae checkpoint desde .tar/.zip y lo convierte en archivo .pth v√°lido\n",
    "    \n",
    "    Los archivos .tar de ConvNeXtPose son ZIP con estructura de directorio en formato legacy.\n",
    "    Usamos una conversi√≥n simple: empaquetar el directorio como TAR que PyTorch puede leer.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(tar_path):\n",
    "        print(f\"‚ö†Ô∏è  Modelo {model_name} no encontrado en {tar_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üì¶ Extrayendo modelo {model_name} desde {tar_path}...\")\n",
    "    \n",
    "    # Verificar tama√±o del archivo\n",
    "    file_size = os.path.getsize(tar_path)\n",
    "    print(f\"   üìè Tama√±o del archivo: {file_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    # Leer primeros bytes para diagnosticar el formato\n",
    "    with open(tar_path, 'rb') as f:\n",
    "        header = f.read(512)\n",
    "        print(f\"   üîç Primeros bytes (hex): {header[:50].hex()}\")\n",
    "    \n",
    "    # Si el archivo es muy peque√±o o empieza con HTML, es un error de descarga\n",
    "    if file_size < 1000 or header.startswith(b'<!DOCTYPE') or header.startswith(b'<html'):\n",
    "        print(f\"   ‚ùå ERROR: El archivo parece ser HTML (error de descarga)\")\n",
    "        print(f\"   üí° Soluci√≥n: Revisa que el folder de Google Drive sea p√∫blico\")\n",
    "        return None\n",
    "    \n",
    "    # Extraer a directorio temporal\n",
    "    temp_dir = 'output/model_dump/temp_extract'\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    # Detectar formato: intentar ZIP primero, luego TAR\n",
    "    extracted = False\n",
    "    try:\n",
    "        with zipfile.ZipFile(tar_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "            files = zip_ref.namelist()\n",
    "            print(f\"   ‚úì Formato: ZIP - Extra√≠do: {len(files)} archivos\")\n",
    "            extracted = True\n",
    "    except zipfile.BadZipFile:\n",
    "        try:\n",
    "            with tarfile.open(tar_path, 'r') as tar_ref:\n",
    "                tar_ref.extractall(temp_dir)\n",
    "                files = tar_ref.getnames()\n",
    "                print(f\"   ‚úì Formato: TAR - Extra√≠do: {len(files)} archivos\")\n",
    "                extracted = True\n",
    "        except (tarfile.ReadError, Exception) as e:\n",
    "            print(f\"   ‚ùå ERROR: No se pudo extraer el archivo\")\n",
    "            print(f\"   üí° Formato no reconocido: {type(e).__name__}: {e}\")\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "            return None\n",
    "    \n",
    "    if not extracted:\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        return None\n",
    "    \n",
    "    # Buscar la carpeta del checkpoint (snapshot_XX.pth/ o archive/)\n",
    "    found_checkpoints = []\n",
    "    for item in os.listdir(temp_dir):\n",
    "        item_path = os.path.join(temp_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            # Verificar que tenga data.pkl (indicador de checkpoint PyTorch)\n",
    "            if os.path.exists(os.path.join(item_path, 'data.pkl')):\n",
    "                found_checkpoints.append((item, item_path))\n",
    "                print(f\"   ‚úì Checkpoint encontrado: {item}/\")\n",
    "    \n",
    "    if not found_checkpoints:\n",
    "        print(f\"   ‚ùå No se encontr√≥ estructura de checkpoint v√°lida\")\n",
    "        print(f\"   üìÇ Contenido extra√≠do:\")\n",
    "        for item in os.listdir(temp_dir)[:10]:\n",
    "            print(f\"      - {item}\")\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "        return None\n",
    "    \n",
    "    # Convertir el checkpoint legacy a formato moderno\n",
    "    epoch = None\n",
    "    for ckpt_name, ckpt_path in found_checkpoints:\n",
    "        # Determinar el epoch desde el nombre\n",
    "        import re\n",
    "        match = re.search(r'snapshot_(\\d+)', ckpt_name)\n",
    "        if match:\n",
    "            epoch = match.group(1)\n",
    "            final_name = f'snapshot_{epoch}.pth'\n",
    "        else:\n",
    "            # Si no tiene snapshot_XX, usar archive/ con epoch esperado\n",
    "            if expected_epoch:\n",
    "                epoch = str(expected_epoch)\n",
    "                final_name = f'snapshot_{epoch}.pth'\n",
    "            else:\n",
    "                epoch = '0'\n",
    "                final_name = f'{model_name}_checkpoint.pth'\n",
    "        \n",
    "        dest_path = os.path.join('output/model_dump', final_name)\n",
    "        \n",
    "        print(f\"   üîÑ Convirtiendo formato legacy ‚Üí formato moderno...\")\n",
    "        \n",
    "        try:\n",
    "            # SOLUCI√ìN DEFINITIVA: Cargar manualmente el formato legacy y guardar como moderno\n",
    "            import pickle\n",
    "            import io\n",
    "            \n",
    "            # Cargar data.pkl\n",
    "            data_pkl_path = os.path.join(ckpt_path, 'data.pkl')\n",
    "            data_dir = os.path.join(ckpt_path, 'data')\n",
    "            \n",
    "            # Crear un unpickler personalizado que resuelve persistent IDs\n",
    "            class LegacyUnpickler(pickle.Unpickler):\n",
    "                def __init__(self, file, data_dir):\n",
    "                    super().__init__(file)\n",
    "                    self.data_dir = data_dir\n",
    "                    self.storage_cache = {}\n",
    "                \n",
    "                def persistent_load(self, pid):\n",
    "                    # pid es una tupla: ('storage', <type>, <key>, <location>, <size>)\n",
    "                    if isinstance(pid, tuple) and len(pid) >= 2 and pid[0] == 'storage':\n",
    "                        typename, key = pid[1:3]\n",
    "                        location = pid[3] if len(pid) > 3 else None\n",
    "                        \n",
    "                        # Cachear storages para evitar recargar\n",
    "                        if key in self.storage_cache:\n",
    "                            return self.storage_cache[key]\n",
    "                        \n",
    "                        # Leer el archivo de storage\n",
    "                        storage_file = os.path.join(self.data_dir, str(key))\n",
    "                        \n",
    "                        # Leer el contenido como raw binary\n",
    "                        with open(storage_file, 'rb') as f:\n",
    "                            raw_data = f.read()\n",
    "                            \n",
    "                            # Crear UntypedStorage desde el buffer\n",
    "                            untyped_storage = torch.UntypedStorage.from_buffer(raw_data, dtype=torch.uint8)\n",
    "                            \n",
    "                            # Mapear typename a dtype de PyTorch\n",
    "                            dtype_map = {\n",
    "                                'FloatStorage': torch.float32,\n",
    "                                'DoubleStorage': torch.float64,\n",
    "                                'HalfStorage': torch.float16,\n",
    "                                'LongStorage': torch.int64,\n",
    "                                'IntStorage': torch.int32,\n",
    "                                'ShortStorage': torch.int16,\n",
    "                                'CharStorage': torch.int8,\n",
    "                                'ByteStorage': torch.uint8,\n",
    "                                'BoolStorage': torch.bool,\n",
    "                            }\n",
    "                            \n",
    "                            # Obtener dtype desde typename\n",
    "                            # typename puede ser un objeto _LegacyStorageMeta, extraer el nombre\n",
    "                            type_str = str(typename).split('.')[-1].replace(\"'>\", \"\")\n",
    "                            dtype = dtype_map.get(type_str, torch.float32)\n",
    "                            \n",
    "                            # Crear TypedStorage desde UntypedStorage\n",
    "                            typed_storage = torch.storage.TypedStorage(\n",
    "                                wrap_storage=untyped_storage,\n",
    "                                dtype=dtype\n",
    "                            )\n",
    "                            \n",
    "                            self.storage_cache[key] = typed_storage\n",
    "                            return typed_storage\n",
    "                    \n",
    "                    raise pickle.UnpicklingError(f\"unsupported persistent id: {pid}\")\n",
    "            \n",
    "            # Cargar el checkpoint usando el unpickler personalizado\n",
    "            with open(data_pkl_path, 'rb') as f:\n",
    "                unpickler = LegacyUnpickler(f, data_dir)\n",
    "                checkpoint = unpickler.load()\n",
    "            \n",
    "            # Guardar en formato moderno\n",
    "            torch.save(checkpoint, dest_path)\n",
    "            \n",
    "            # Verificar tama√±o\n",
    "            size_mb = os.path.getsize(dest_path) / (1024 * 1024)\n",
    "            print(f\"   ‚úì Archivo creado: {final_name} ({size_mb:.1f} MB)\")\n",
    "            \n",
    "            # Verificar que se puede cargar\n",
    "            test_load = torch.load(dest_path, map_location='cpu', weights_only=False)\n",
    "            keys = list(test_load.keys())\n",
    "            print(f\"   ‚úì Verificaci√≥n exitosa - Keys: {keys}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå ERROR al convertir checkpoint: {type(e).__name__}\")\n",
    "            print(f\"      {str(e)[:200]}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "            return None\n",
    "    \n",
    "    # Limpiar temporal\n",
    "    shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "    print(f\"   ‚úì Conversi√≥n completada\")\n",
    "    \n",
    "    return epoch\n",
    "\n",
    "# Extraer modelo L (epoch 83 seg√∫n el paper)\n",
    "print(\"=\"*60)\n",
    "model_l_path = f'{MODELS_DATASET_PATH}/ConvNeXtPose_L.tar'\n",
    "epoch_l = extract_checkpoint(model_l_path, 'L', expected_epoch=83)\n",
    "\n",
    "print()\n",
    "\n",
    "# Extraer modelo M (epoch 70 seg√∫n el paper)\n",
    "model_m_path = f'{MODELS_DATASET_PATH}/ConvNeXtPose_M.tar'\n",
    "epoch_m = extract_checkpoint(model_m_path, 'M', expected_epoch=70)\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verificar checkpoints extra√≠dos\n",
    "print(\"\\nüìÇ Checkpoints disponibles:\")\n",
    "checkpoints = [f for f in os.listdir('output/model_dump') \n",
    "               if f.endswith('.pth') and os.path.isfile(os.path.join('output/model_dump', f))]\n",
    "\n",
    "if checkpoints:\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        ckpt_path = os.path.join('output/model_dump', ckpt)\n",
    "        size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n",
    "        print(f\"  ‚úì {ckpt} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        # Verificar contenido\n",
    "        try:\n",
    "            test_load = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "            keys = list(test_load.keys())\n",
    "            print(f\"    ‚Üí Keys: {keys}\")\n",
    "            if 'network' in test_load:\n",
    "                # Contar par√°metros\n",
    "                num_params = sum(p.numel() for p in test_load['network'].values() \n",
    "                                 if isinstance(p, torch.Tensor))\n",
    "                print(f\"    ‚Üí ‚úÖ Formato v√°lido ({num_params:,} par√°metros)\")\n",
    "            else:\n",
    "                print(f\"    ‚Üí ‚ö†Ô∏è  Falta key 'network'\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ‚Üí ‚ùå Error: {type(e).__name__}: {str(e)[:80]}\")\n",
    "\n",
    "# Mostrar informaci√≥n de epochs\n",
    "if epoch_l:\n",
    "    print(f\"\\nüí° Modelo L: Usa CHECKPOINT_EPOCH = {epoch_l}\")\n",
    "if epoch_m:\n",
    "    print(f\"üí° Modelo M: Usa CHECKPOINT_EPOCH = {epoch_m}\")\n",
    "\n",
    "if epoch_l or epoch_m:\n",
    "    print(\"\\n‚úÖ Los checkpoints est√°n listos para torch.load()\")\n",
    "    print(\"   Formato: PyTorch moderno (.pth)\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No se pudieron extraer los checkpoints\")\n",
    "    print(\"üí° Verifica que los archivos .tar se descargaron correctamente\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Nota sobre Extracci√≥n de Checkpoints\n",
    "\n",
    "Los archivos `.tar` de ConvNeXtPose son en realidad **archivos ZIP** con estructura anidada:\n",
    "```\n",
    "ConvNeXtPose_L.tar (archivo zip)\n",
    "‚îî‚îÄ‚îÄ snapshot_83.pth/        ‚Üê Directorio\n",
    "    ‚îú‚îÄ‚îÄ data.pkl\n",
    "    ‚îú‚îÄ‚îÄ version\n",
    "    ‚îî‚îÄ‚îÄ data/               ‚Üê Carpeta con el checkpoint real\n",
    "        ‚îî‚îÄ‚îÄ 0, 1, 2...      ‚Üê Archivos binarios\n",
    "```\n",
    "\n",
    "La siguiente celda extrae y reorganiza correctamente el archivo `.pth` real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:17.428421Z",
     "iopub.status.busy": "2025-10-14T13:10:17.428061Z",
     "iopub.status.idle": "2025-10-14T13:10:17.554586Z",
     "shell.execute_reply": "2025-10-14T13:10:17.553596Z",
     "shell.execute_reply.started": "2025-10-14T13:10:17.428386Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ConvNeXtPose\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:17.556076Z",
     "iopub.status.busy": "2025-10-14T13:10:17.555795Z",
     "iopub.status.idle": "2025-10-14T13:10:17.732607Z",
     "shell.execute_reply": "2025-10-14T13:10:17.731790Z",
     "shell.execute_reply.started": "2025-10-14T13:10:17.556053Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verificaci√≥n de Checkpoints:\n",
      "\n",
      "‚úÖ Checkpoints encontrados:\n",
      "\n",
      "  ‚úì snapshot_70.pth (87.1 MB)\n",
      "    ‚Üí Usa CHECKPOINT_EPOCH = 70\n",
      "    ‚Üí Keys: ['epoch', 'network', 'optimizer']\n",
      "    ‚Üí ‚úÖ Formato v√°lido (7,596,986 par√°metros)\n",
      "\n",
      "  ‚úì snapshot_83.pth (96.2 MB)\n",
      "    ‚Üí Usa CHECKPOINT_EPOCH = 83\n",
      "    ‚Üí Keys: ['epoch', 'network', 'optimizer']\n",
      "    ‚Üí ‚úÖ Formato v√°lido (8,391,354 par√°metros)\n",
      "\n",
      "\n",
      "============================================================\n",
      "üí° IMPORTANTE: Los checkpoints son archivos .pth modernos\n",
      "   Convertidos desde formato legacy a formato PyTorch est√°ndar\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verificar checkpoints extra√≠dos y detectar epoch\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "\n",
    "print(\"üîç Verificaci√≥n de Checkpoints:\\n\")\n",
    "\n",
    "# Buscar ARCHIVOS .pth\n",
    "checkpoint_dir = 'output/model_dump'\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) \n",
    "                   if f.endswith('.pth') and os.path.isfile(os.path.join(checkpoint_dir, f))]\n",
    "else:\n",
    "    checkpoints = []\n",
    "\n",
    "if checkpoints:\n",
    "    print(\"‚úÖ Checkpoints encontrados:\\n\")\n",
    "    for ckpt in sorted(checkpoints):\n",
    "        ckpt_path = os.path.join(checkpoint_dir, ckpt)\n",
    "        size_mb = os.path.getsize(ckpt_path) / (1024 * 1024)\n",
    "        \n",
    "        # Extraer epoch\n",
    "        match = re.search(r'snapshot_(\\d+)', ckpt)\n",
    "        if match:\n",
    "            epoch = match.group(1)\n",
    "            print(f\"  ‚úì {ckpt} ({size_mb:.1f} MB)\")\n",
    "            print(f\"    ‚Üí Usa CHECKPOINT_EPOCH = {epoch}\")\n",
    "            \n",
    "            # Verificar contenido del checkpoint\n",
    "            try:\n",
    "                test_load = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
    "                keys = list(test_load.keys())\n",
    "                print(f\"    ‚Üí Keys: {keys}\")\n",
    "                \n",
    "                if 'network' in test_load:\n",
    "                    # Contar par√°metros del modelo\n",
    "                    num_params = sum(p.numel() for p in test_load['network'].values() \n",
    "                                     if isinstance(p, torch.Tensor))\n",
    "                    print(f\"    ‚Üí ‚úÖ Formato v√°lido ({num_params:,} par√°metros)\")\n",
    "                else:\n",
    "                    print(f\"    ‚Üí ‚ö†Ô∏è  Falta key 'network'\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"    ‚Üí ‚ùå Error al verificar: {type(e).__name__}: {str(e)[:50]}\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"‚ùå No se encontraron checkpoints v√°lidos\\n\")\n",
    "    \n",
    "    # Diagnosticar problema\n",
    "    if os.path.exists(checkpoint_dir):\n",
    "        all_items = os.listdir(checkpoint_dir)\n",
    "        if all_items:\n",
    "            print(\"üìÇ Contenido de output/model_dump/:\")\n",
    "            for item in all_items[:15]:\n",
    "                item_path = os.path.join(checkpoint_dir, item)\n",
    "                if os.path.isdir(item_path):\n",
    "                    print(f\"    üìÅ {item}/ (directorio - no v√°lido)\")\n",
    "                else:\n",
    "                    size_mb = os.path.getsize(item_path) / (1024 * 1024)\n",
    "                    print(f\"    üìÑ {item} ({size_mb:.1f} MB)\")\n",
    "            \n",
    "            print(\"\\nüí° Soluci√≥n: Re-ejecuta la celda anterior de extracci√≥n\")\n",
    "        else:\n",
    "            print(\"üí° Directorio vac√≠o - verifica MODELS_DATASET_PATH\")\n",
    "    else:\n",
    "        print(\"üí° Soluci√≥n: Verifica que MODELS_DATASET_PATH es correcto\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí° IMPORTANTE: Los checkpoints son archivos .pth modernos\")\n",
    "print(\"   Convertidos desde formato legacy a formato PyTorch est√°ndar\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ö†Ô∏è IMPORTANTE:** Ajusta el valor de `CHECKPOINT_EPOCH` en las siguientes celdas seg√∫n el epoch de tu checkpoint extra√≠do. En este caso detectamos `snapshot_83.pth`, as√≠ que usa `CHECKPOINT_EPOCH = 83`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ PASO 4: Ejecutar Testing\n",
    "\n",
    "### Modelo XS (Extra Small)\n",
    "\n",
    "**‚ö†Ô∏è NOTA CR√çTICA:** Todos los checkpoints descargados (L.tar, M.tar, S.tar) contienen arquitectura XS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:17.733645Z",
     "iopub.status.busy": "2025-10-14T13:10:17.733442Z",
     "iopub.status.idle": "2025-10-14T13:10:17.751756Z",
     "shell.execute_reply": "2025-10-14T13:10:17.751008Z",
     "shell.execute_reply.started": "2025-10-14T13:10:17.733627Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verificaci√≥n de Componentes:\n",
      "\n",
      "1. Dataset (estructura del proyecto):\n",
      "   Project root: /kaggle/working/ConvNeXtPose\n",
      "   data/ exists: True\n",
      "   data/dataset.py: True\n",
      "   data/Human36M/ exists: True\n",
      "   - Human36M.py: True\n",
      "   - annotations: True\n",
      "   - images/S9: True\n",
      "   - images/S11: True\n",
      "\n",
      "2. Checkpoints: /kaggle/working/ConvNeXtPose/output/model_dump\n",
      "   Disponibles: snapshot_70.pth, snapshot_83.pth\n",
      "   üí° Usa CHECKPOINT_EPOCH = 70 en la siguiente celda\n",
      "   üí° Usa CHECKPOINT_EPOCH = 83 en la siguiente celda\n",
      "\n",
      "3. Estructura del proyecto:\n",
      "   ‚úì main/config.py\n",
      "   ‚úì common/base.py\n",
      "   ‚úì data/dataset.py\n",
      "   ‚úì data/Human36M/Human36M.py\n",
      "\n",
      "============================================================\n",
      "‚úÖ Todos los checks pasaron - Listo para testing\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Diagn√≥stico: Verificar que todos los componentes est√°n listos\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"üîç Verificaci√≥n de Componentes:\\n\")\n",
    "\n",
    "# 1. Dataset - Verificar estructura DENTRO del proyecto\n",
    "project_root = '/kaggle/working/ConvNeXtPose'\n",
    "data_dir = os.path.join(project_root, 'data')\n",
    "h36m_path = os.path.join(data_dir, 'Human36M')\n",
    "\n",
    "print(f\"1. Dataset (estructura del proyecto):\")\n",
    "print(f\"   Project root: {project_root}\")\n",
    "print(f\"   data/ exists: {os.path.exists(data_dir)}\")\n",
    "print(f\"   data/dataset.py: {os.path.exists(os.path.join(data_dir, 'dataset.py'))}\")\n",
    "print(f\"   data/Human36M/ exists: {os.path.exists(h36m_path)}\")\n",
    "\n",
    "if os.path.exists(h36m_path):\n",
    "    print(f\"   - Human36M.py: {os.path.exists(os.path.join(h36m_path, 'Human36M.py'))}\")\n",
    "    print(f\"   - annotations: {os.path.exists(os.path.join(h36m_path, 'annotations'))}\")\n",
    "    print(f\"   - images/S9: {os.path.exists(os.path.join(h36m_path, 'images', 'S9'))}\")\n",
    "    print(f\"   - images/S11: {os.path.exists(os.path.join(h36m_path, 'images', 'S11'))}\")\n",
    "\n",
    "# 2. Checkpoints\n",
    "checkpoint_dir = os.path.join(project_root, 'output/model_dump')\n",
    "print(f\"\\n2. Checkpoints: {checkpoint_dir}\")\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith('snapshot_')]\n",
    "    if checkpoints:\n",
    "        print(f\"   Disponibles: {', '.join(checkpoints)}\")\n",
    "        # Extraer epoch del checkpoint\n",
    "        import re\n",
    "        for ckpt in checkpoints:\n",
    "            match = re.search(r'snapshot_(\\d+)', ckpt)\n",
    "            if match:\n",
    "                epoch = match.group(1)\n",
    "                print(f\"   üí° Usa CHECKPOINT_EPOCH = {epoch} en la siguiente celda\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No se encontraron checkpoints\")\n",
    "else:\n",
    "    print(\"   ‚ùå Directorio no existe\")\n",
    "\n",
    "# 3. Estructura del proyecto\n",
    "print(f\"\\n3. Estructura del proyecto:\")\n",
    "critical_files = ['main/config.py', 'common/base.py', 'data/dataset.py', 'data/Human36M/Human36M.py']\n",
    "for file_path in critical_files:\n",
    "    full_path = os.path.join(project_root, file_path)\n",
    "    exists = os.path.exists(full_path)\n",
    "    status = \"‚úì\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {file_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all(os.path.exists(os.path.join(project_root, f)) for f in critical_files):\n",
    "    print(\"‚úÖ Todos los checks pasaron - Listo para testing\")\n",
    "else:\n",
    "    print(\"‚ùå Algunos archivos faltan - Revisa la configuraci√≥n\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar Testing desde Python\n",
    "\n",
    "**Estructura correcta:**\n",
    "- ‚úÖ M√≥dulos Python originales en `data/` (dataset.py, Human36M.py)\n",
    "- ‚úÖ Dataset de Kaggle enlazado en `data/Human36M/` (images, annotations)\n",
    "- ‚úÖ `config.py` configura autom√°ticamente los paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è IMPORTANTE: Verificar GPU Antes de Testing\n",
    "\n",
    "**El modelo REQUIERE GPU para correr en tiempo razonable.**\n",
    "\n",
    "- ‚úÖ **Con GPU T4 x2**: ~10-20 minutos\n",
    "- ‚ùå **Con CPU**: ~10-20 HORAS (no recomendado)\n",
    "\n",
    "**C√≥mo activar GPU en Kaggle:**\n",
    "1. Panel derecho ‚Üí **Settings**\n",
    "2. **Accelerator** ‚Üí Selecciona **GPU T4 x2** o **GPU P100**\n",
    "3. Click **Save**\n",
    "4. El notebook se reiniciar√° con GPU habilitada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:17.752776Z",
     "iopub.status.busy": "2025-10-14T13:10:17.752599Z",
     "iopub.status.idle": "2025-10-14T13:10:17.757975Z",
     "shell.execute_reply": "2025-10-14T13:10:17.757092Z",
     "shell.execute_reply.started": "2025-10-14T13:10:17.752760Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verificando hardware disponible...\n",
      "\n",
      "‚úÖ GPU disponible: Tesla T4\n",
      "   Memoria: 15.8 GB\n",
      "\n",
      "üí° Tiempo estimado: 10-20 minutos\n"
     ]
    }
   ],
   "source": [
    "# Verificar disponibilidad de GPU\n",
    "import torch\n",
    "\n",
    "print(\"üîç Verificando hardware disponible...\\n\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memoria: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"\\nüí° Tiempo estimado: 10-20 minutos\")\n",
    "    USE_GPU = True\n",
    "else:\n",
    "    print(\"‚ùå GPU NO disponible - usando CPU\")\n",
    "    print(\"\\n‚ö†Ô∏è  ADVERTENCIA: El testing en CPU puede tomar HORAS\")\n",
    "    print(\"   Se recomienda activar GPU T4 x2 en Kaggle\")\n",
    "    print(\"\\n¬øContinuar de todas formas? (no recomendado)\")\n",
    "    USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-14T13:10:17.759110Z",
     "iopub.status.busy": "2025-10-14T13:10:17.758902Z",
     "iopub.status.idle": "2025-10-14T13:10:45.079598Z",
     "shell.execute_reply": "2025-10-14T13:10:45.077104Z",
     "shell.execute_reply.started": "2025-10-14T13:10:17.759092Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Testing ConvNeXtPose-L\n",
      "============================================================\n",
      "\n",
      "‚úì Configuraci√≥n cargada para variante: L\n",
      "  - Backbone: depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536]\n",
      "  - HeadNet: 3-UP (3 capas de upsampling)\n",
      ">>> Using GPU: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "\u001b[92m10-14 13:10:24\u001b[0m Creating dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CUDA habilitado\n",
      "Load data of H36M Protocol 2\n",
      "creating index...\n",
      "index created!\n",
      "Get bounding box and root from groundtruth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\u001b[92m10-14 13:10:41\u001b[0m Load checkpoint from /kaggle/working/ConvNeXtPose/main/../output/model_dump/snapshot_83.pth\n",
      "\u001b[92m10-14 13:10:41\u001b[0m Creating graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìê Arquitectura: ConvNeXtPose-L\n",
      "   Backbone: 1536 canales de salida\n",
      "   HeadNet: 3-UP (3 capas de upsampling)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ConvNeXtPose/main/../common/base.py:205: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(model_path)\n",
      "\u001b[92m10-14 13:10:44\u001b[0m Aplicando checkpoint remapping para variante L...\n",
      "\u001b[92m10-14 13:10:44\u001b[0m \u001b[93mWRN: Detectadas claves incompatibles, aplicando remapping...\u001b[0m\n",
      "\u001b[92m10-14 13:10:44\u001b[0m \u001b[91mERR: ‚ùå Error cargando checkpoint remapeado: Error(s) in loading state_dict for ConvNeXtPose:\n",
      "\tsize mismatch for backbone.downsample_layers.0.0.weight: copying a param with shape torch.Size([48, 3, 4, 4]) from checkpoint, the shape in current model is torch.Size([192, 3, 4, 4]).\n",
      "\tsize mismatch for backbone.downsample_layers.0.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.0.1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.0.1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.0.1.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.0.1.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.0.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.0.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.0.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.1.weight: copying a param with shape torch.Size([96, 48, 2, 2]) from checkpoint, the shape in current model is torch.Size([384, 192, 2, 2]).\n",
      "\tsize mismatch for backbone.downsample_layers.1.1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.0.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.0.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.0.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.1.weight: copying a param with shape torch.Size([192, 96, 2, 2]) from checkpoint, the shape in current model is torch.Size([768, 384, 2, 2]).\n",
      "\tsize mismatch for backbone.downsample_layers.2.1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.0.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.0.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.0.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.0.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.1.weight: copying a param with shape torch.Size([384, 192, 2, 2]) from checkpoint, the shape in current model is torch.Size([1536, 768, 2, 2]).\n",
      "\tsize mismatch for backbone.downsample_layers.3.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.0.0.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.0.0.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.0.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.0.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.0.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.0.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.0.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.0.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.0.0.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.0.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.0.1.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.1.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.1.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.0.1.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.1.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.0.2.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.0.2.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.2.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.0.2.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.0.2.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n",
      "\tsize mismatch for backbone.stages.1.0.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.1.0.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.0.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.0.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.0.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.0.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.0.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.0.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.1.0.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.0.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.1.1.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.1.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.1.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.1.1.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.1.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.1.2.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.1.2.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.2.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.1.2.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.1.2.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n",
      "\tsize mismatch for backbone.stages.2.0.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.0.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.0.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.0.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.0.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.0.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.0.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.0.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.0.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.0.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.1.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.1.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.1.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.1.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.1.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.2.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.2.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.2.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.2.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.2.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.3.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.3.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.3.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.3.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.3.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.4.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.4.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.4.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.4.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.4.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.5.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.5.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.5.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.5.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.5.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.6.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.6.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.6.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.6.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.6.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.7.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.7.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.7.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.7.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.7.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.2.8.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.2.8.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.8.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n",
      "\tsize mismatch for backbone.stages.2.8.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.2.8.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n",
      "\tsize mismatch for backbone.stages.3.0.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.3.0.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.0.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.0.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.0.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.0.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.0.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.0.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "\tsize mismatch for backbone.stages.3.0.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.0.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.3.1.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.1.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.1.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "\tsize mismatch for backbone.stages.3.1.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.1.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n",
      "\tsize mismatch for backbone.stages.3.2.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.stages.3.2.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.2.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n",
      "\tsize mismatch for backbone.stages.3.2.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n",
      "\tsize mismatch for backbone.stages.3.2.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for backbone.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n",
      "\tsize mismatch for head.final_layer.weight: copying a param with shape torch.Size([1152, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 256, 1, 1]).\n",
      "\tsize mismatch for head.final_layer.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([576]).\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ConvNeXtPose:\n\tsize mismatch for backbone.downsample_layers.0.0.weight: copying a param with shape torch.Size([48, 3, 4, 4]) from checkpoint, the shape in current model is torch.Size([192, 3, 4, 4]).\n\tsize mismatch for backbone.downsample_layers.0.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.1.weight: copying a param with shape torch.Size([96, 48, 2, 2]) from checkpoint, the shape in current model is torch.Size([384, 192, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.1.1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.1.weight: copying a param with shape torch.Size([192, 96, 2, 2]) from checkpoint, the shape in current model is torch.Size([768, 384, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.2.1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.1.weight: copying a param with shape torch.Size([384, 192, 2, 2]) from checkpoint, the shape in current model is torch.Size([1536, 768, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.3.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.0.0.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.0.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.0.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.0.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.0.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.1.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.1.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.1.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.1.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.2.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.2.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.2.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.2.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.1.0.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.0.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.0.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.0.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.0.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.1.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.1.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.1.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.1.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.2.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.2.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.2.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.2.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.2.0.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.0.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.0.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.0.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.0.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.1.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.1.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.1.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.1.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.2.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.2.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.2.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.2.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.3.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.3.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.3.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.3.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.4.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.4.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.4.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.4.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.5.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.5.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.5.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.5.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.6.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.6.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.6.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.6.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.7.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.7.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.7.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.7.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.8.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.8.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.8.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.8.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.3.0.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.0.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.0.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.0.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.0.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.1.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.1.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.1.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.1.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.2.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.2.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.2.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.2.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for head.final_layer.weight: copying a param with shape torch.Size([1152, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 256, 1, 1]).\n\tsize mismatch for head.final_layer.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([576]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/kaggle/working/ConvNeXtPose/main/../common/base.py\u001b[0m in \u001b[0;36m_make_model\u001b[0;34m(self, test_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úì Checkpoint cargado sin necesidad de remapping\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DataParallel:\n\tMissing key(s) in state_dict: \"module.backbone.stages.2.9.dwconv.weight\", \"module.backbone.stages.2.9.dwconv.bias\", \"module.backbone.stages.2.9.norm.weight\", \"module.backbone.stages.2.9.norm.bias\", \"module.backbone.stages.2.9.norm.running_mean\", \"module.backbone.stages.2.9.norm.running_var\", \"module.backbone.stages.2.9.pwconv1.weight\", \"module.backbone.stages.2.9.pwconv1.bias\", \"module.backbone.stages.2.9.pwconv2.weight\", \"module.backbone.stages.2.9.pwconv2.bias\", \"module.backbone.stages.2.10.dwconv.weight\", \"module.backbone.stages.2.10.dwconv.bias\", \"module.backbone.stages.2.10.norm.weight\", \"module.backbone.stages.2.10.norm.bias\", \"module.backbone.stages.2.10.norm.running_mean\", \"module.backbone.stages.2.10.norm.running_var\", \"module.backbone.stages.2.10.pwconv1.weight\", \"module.backbone.stages.2.10.pwconv1.bias\", \"module.backbone.stages.2.10.pwconv2.weight\", \"module.backbone.stages.2.10.pwconv2.bias\", \"module.backbone.stages.2.11.dwconv.weight\", \"module.backbone.stages.2.11.dwconv.bias\", \"module.backbone.stages.2.11.norm.weight\", \"module.backbone.stages.2.11.norm.bias\", \"module.backbone.stages.2.11.norm.running_mean\", \"module.backbone.stages.2.11.norm.running_var\", \"module.backbone.stages.2.11.pwconv1.weight\", \"module.backbone.stages.2.11.pwconv1.bias\", \"module.backbone.stages.2.11.pwconv2.weight\", \"module.backbone.stages.2.11.pwconv2.bias\", \"module.backbone.stages.2.12.dwconv.weight\", \"module.backbone.stages.2.12.dwconv.bias\", \"module.backbone.stages.2.12.norm.weight\", \"module.backbone.stages.2.12.norm.bias\", \"module.backbone.stages.2.12.norm.running_mean\", \"module.backbone.stages.2.12.norm.running_var\", \"module.backbone.stages.2.12.pwconv1.weight\", \"module.backbone.stages.2.12.pwconv1.bias\", \"module.backbone.stages.2.12.pwconv2.weight\", \"module.backbone.stages.2.12.pwconv2.bias\", \"module.backbone.stages.2.13.dwconv.weight\", \"module.backbone.stages.2.13.dwconv.bias\", \"module.backbone.stages.2.13.norm.weight\", \"module.backbone.stages.2.13.norm.bias\", \"module.backbone.stages.2.13.norm.running_mean\", \"module.backbone.stages.2.13.norm.running_var\", \"module.backbone.stages.2.13.pwconv1.weight\", \"module.backbone.stages.2.13.pwconv1.bias\", \"module.backbone.stages.2.13.pwconv2.weight\", \"module.backbone.stages.2.13.pwconv2.bias\", \"module.backbone.stages.2.14.dwconv.weight\", \"module.backbone.stages.2.14.dwconv.bias\", \"module.backbone.stages.2.14.norm.weight\", \"module.backbone.stages.2.14.norm.bias\", \"module.backbone.stages.2.14.norm.running_mean\", \"module.backbone.stages.2.14.norm.running_var\", \"module.backbone.stages.2.14.pwconv1.weight\", \"module.backbone.stages.2.14.pwconv1.bias\", \"module.backbone.stages.2.14.pwconv2.weight\", \"module.backbone.stages.2.14.pwconv2.bias\", \"module.backbone.stages.2.15.dwconv.weight\", \"module.backbone.stages.2.15.dwconv.bias\", \"module.backbone.stages.2.15.norm.weight\", \"module.backbone.stages.2.15.norm.bias\", \"module.backbone.stages.2.15.norm.running_mean\", \"module.backbone.stages.2.15.norm.running_var\", \"module.backbone.stages.2.15.pwconv1.weight\", \"module.backbone.stages.2.15.pwconv1.bias\", \"module.backbone.stages.2.15.pwconv2.weight\", \"module.backbone.stages.2.15.pwconv2.bias\", \"module.backbone.stages.2.16.dwconv.weight\", \"module.backbone.stages.2.16.dwconv.bias\", \"module.backbone.stages.2.16.norm.weight\", \"module.backbone.stages.2.16.norm.bias\", \"module.backbone.stages.2.16.norm.running_mean\", \"module.backbone.stages.2.16.norm.running_var\", \"module.backbone.stages.2.16.pwconv1.weight\", \"module.backbone.stages.2.16.pwconv1.bias\", \"module.backbone.stages.2.16.pwconv2.weight\", \"module.backbone.stages.2.16.pwconv2.bias\", \"module.backbone.stages.2.17.dwconv.weight\", \"module.backbone.stages.2.17.dwconv.bias\", \"module.backbone.stages.2.17.norm.weight\", \"module.backbone.stages.2.17.norm.bias\", \"module.backbone.stages.2.17.norm.running_mean\", \"module.backbone.stages.2.17.norm.running_var\", \"module.backbone.stages.2.17.pwconv1.weight\", \"module.backbone.stages.2.17.pwconv1.bias\", \"module.backbone.stages.2.17.pwconv2.weight\", \"module.backbone.stages.2.17.pwconv2.bias\", \"module.backbone.stages.2.18.dwconv.weight\", \"module.backbone.stages.2.18.dwconv.bias\", \"module.backbone.stages.2.18.norm.weight\", \"module.backbone.stages.2.18.norm.bias\", \"module.backbone.stages.2.18.norm.running_mean\", \"module.backbone.stages.2.18.norm.running_var\", \"module.backbone.stages.2.18.pwconv1.weight\", \"module.backbone.stages.2.18.pwconv1.bias\", \"module.backbone.stages.2.18.pwconv2.weight\", \"module.backbone.stages.2.18.pwconv2.bias\", \"module.backbone.stages.2.19.dwconv.weight\", \"module.backbone.stages.2.19.dwconv.bias\", \"module.backbone.stages.2.19.norm.weight\", \"module.backbone.stages.2.19.norm.bias\", \"module.backbone.stages.2.19.norm.running_mean\", \"module.backbone.stages.2.19.norm.running_var\", \"module.backbone.stages.2.19.pwconv1.weight\", \"module.backbone.stages.2.19.pwconv1.bias\", \"module.backbone.stages.2.19.pwconv2.weight\", \"module.backbone.stages.2.19.pwconv2.bias\", \"module.backbone.stages.2.20.dwconv.weight\", \"module.backbone.stages.2.20.dwconv.bias\", \"module.backbone.stages.2.20.norm.weight\", \"module.backbone.stages.2.20.norm.bias\", \"module.backbone.stages.2.20.norm.running_mean\", \"module.backbone.stages.2.20.norm.running_var\", \"module.backbone.stages.2.20.pwconv1.weight\", \"module.backbone.stages.2.20.pwconv1.bias\", \"module.backbone.stages.2.20.pwconv2.weight\", \"module.backbone.stages.2.20.pwconv2.bias\", \"module.backbone.stages.2.21.dwconv.weight\", \"module.backbone.stages.2.21.dwconv.bias\", \"module.backbone.stages.2.21.norm.weight\", \"module.backbone.stages.2.21.norm.bias\", \"module.backbone.stages.2.21.norm.running_mean\", \"module.backbone.stages.2.21.norm.running_var\", \"module.backbone.stages.2.21.pwconv1.weight\", \"module.backbone.stages.2.21.pwconv1.bias\", \"module.backbone.stages.2.21.pwconv2.weight\", \"module.backbone.stages.2.21.pwconv2.bias\", \"module.backbone.stages.2.22.dwconv.weight\", \"module.backbone.stages.2.22.dwconv.bias\", \"module.backbone.stages.2.22.norm.weight\", \"module.backbone.stages.2.22.norm.bias\", \"module.backbone.stages.2.22.norm.running_mean\", \"module.backbone.stages.2.22.norm.running_var\", \"module.backbone.stages.2.22.pwconv1.weight\", \"module.backbone.stages.2.22.pwconv1.bias\", \"module.backbone.stages.2.22.pwconv2.weight\", \"module.backbone.stages.2.22.pwconv2.bias\", \"module.backbone.stages.2.23.dwconv.weight\", \"module.backbone.stages.2.23.dwconv.bias\", \"module.backbone.stages.2.23.norm.weight\", \"module.backbone.stages.2.23.norm.bias\", \"module.backbone.stages.2.23.norm.running_mean\", \"module.backbone.stages.2.23.norm.running_var\", \"module.backbone.stages.2.23.pwconv1.weight\", \"module.backbone.stages.2.23.pwconv1.bias\", \"module.backbone.stages.2.23.pwconv2.weight\", \"module.backbone.stages.2.23.pwconv2.bias\", \"module.backbone.stages.2.24.dwconv.weight\", \"module.backbone.stages.2.24.dwconv.bias\", \"module.backbone.stages.2.24.norm.weight\", \"module.backbone.stages.2.24.norm.bias\", \"module.backbone.stages.2.24.norm.running_mean\", \"module.backbone.stages.2.24.norm.running_var\", \"module.backbone.stages.2.24.pwconv1.weight\", \"module.backbone.stages.2.24.pwconv1.bias\", \"module.backbone.stages.2.24.pwconv2.weight\", \"module.backbone.stages.2.24.pwconv2.bias\", \"module.backbone.stages.2.25.dwconv.weight\", \"module.backbone.stages.2.25.dwconv.bias\", \"module.backbone.stages.2.25.norm.weight\", \"module.backbone.stages.2.25.norm.bias\", \"module.backbone.stages.2.25.norm.running_mean\", \"module.backbone.stages.2.25.norm.running_var\", \"module.backbone.stages.2.25.pwconv1.weight\", \"module.backbone.stages.2.25.pwconv1.bias\", \"module.backbone.stages.2.25.pwconv2.weight\", \"module.backbone.stages.2.25.pwconv2.bias\", \"module.backbone.stages.2.26.dwconv.weight\", \"module.backbone.stages.2.26.dwconv.bias\", \"module.backbone.stages.2.26.norm.weight\", \"module.backbone.stages.2.26.norm.bias\", \"module.backbone.stages.2.26.norm.running_mean\", \"module.backbone.stages.2.26.norm.running_var\", \"module.backbone.stages.2.26.pwconv1.weight\", \"module.backbone.stages.2.26.pwconv1.bias\", \"module.backbone.stages.2.26.pwconv2.weight\", \"module.backbone.stages.2.26.pwconv2.bias\", \"module.head.deconv_layers.0.dwconv.weight\", \"module.head.deconv_layers.0.dwconv.bias\", \"module.head.deconv_layers.0.norm.weight\", \"module.head.deconv_layers.0.norm.bias\", \"module.head.deconv_layers.0.norm.running_mean\", \"module.head.deconv_layers.0.norm.running_var\", \"module.head.deconv_layers.0.pwconv.weight\", \"module.head.deconv_layers.0.pwconv.bias\", \"module.head.deconv_layers.1.dwconv.weight\", \"module.head.deconv_layers.1.dwconv.bias\", \"module.head.deconv_layers.1.norm.weight\", \"module.head.deconv_layers.1.norm.bias\", \"module.head.deconv_layers.1.norm.running_mean\", \"module.head.deconv_layers.1.norm.running_var\", \"module.head.deconv_layers.1.pwconv.weight\", \"module.head.deconv_layers.1.pwconv.bias\", \"module.head.deconv_layers.2.dwconv.weight\", \"module.head.deconv_layers.2.dwconv.bias\", \"module.head.deconv_layers.2.norm.weight\", \"module.head.deconv_layers.2.norm.bias\", \"module.head.deconv_layers.2.norm.running_mean\", \"module.head.deconv_layers.2.norm.running_var\", \"module.head.deconv_layers.2.pwconv.weight\", \"module.head.deconv_layers.2.pwconv.bias\". \n\tUnexpected key(s) in state_dict: \"module.head.deconv_layers_1.0.weight\", \"module.head.deconv_layers_1.0.bias\", \"module.head.deconv_layers_1.1.weight\", \"module.head.deconv_layers_1.1.bias\", \"module.head.deconv_layers_1.1.running_mean\", \"module.head.deconv_layers_1.1.running_var\", \"module.head.deconv_layers_1.1.num_batches_tracked\", \"module.head.deconv_layers_1.2.weight\", \"module.head.deconv_layers_1.2.bias\", \"module.head.deconv_layers_2.0.weight\", \"module.head.deconv_layers_2.0.bias\", \"module.head.deconv_layers_2.1.weight\", \"module.head.deconv_layers_2.1.bias\", \"module.head.deconv_layers_2.1.running_mean\", \"module.head.deconv_layers_2.1.running_var\", \"module.head.deconv_layers_2.1.num_batches_tracked\", \"module.head.deconv_layers_2.2.weight\", \"module.head.deconv_layers_2.2.bias\", \"module.head.deconv_layers_3.0.weight\", \"module.head.deconv_layers_3.0.bias\", \"module.head.deconv_layers_3.1.weight\", \"module.head.deconv_layers_3.1.bias\", \"module.head.deconv_layers_3.1.running_mean\", \"module.head.deconv_layers_3.1.running_var\", \"module.head.deconv_layers_3.1.num_batches_tracked\", \"module.head.deconv_layers_3.2.weight\", \"module.head.deconv_layers_3.2.bias\". \n\tsize mismatch for module.backbone.downsample_layers.0.0.weight: copying a param with shape torch.Size([48, 3, 4, 4]) from checkpoint, the shape in current model is torch.Size([192, 3, 4, 4]).\n\tsize mismatch for module.backbone.downsample_layers.0.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.0.1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.0.1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.0.1.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.0.1.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.1.0.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.1.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.1.0.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.1.0.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.downsample_layers.1.1.weight: copying a param with shape torch.Size([96, 48, 2, 2]) from checkpoint, the shape in current model is torch.Size([384, 192, 2, 2]).\n\tsize mismatch for module.backbone.downsample_layers.1.1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.downsample_layers.2.0.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.downsample_layers.2.0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.downsample_layers.2.0.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.downsample_layers.2.0.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.downsample_layers.2.1.weight: copying a param with shape torch.Size([192, 96, 2, 2]) from checkpoint, the shape in current model is torch.Size([768, 384, 2, 2]).\n\tsize mismatch for module.backbone.downsample_layers.2.1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.downsample_layers.3.0.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.downsample_layers.3.0.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.downsample_layers.3.0.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.downsample_layers.3.0.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.downsample_layers.3.1.weight: copying a param with shape torch.Size([384, 192, 2, 2]) from checkpoint, the shape in current model is torch.Size([1536, 768, 2, 2]).\n\tsize mismatch for module.backbone.downsample_layers.3.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.0.0.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.0.0.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.0.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.0.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.0.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.0.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.0.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.0.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.0.0.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.0.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.0.1.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.1.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.1.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.0.1.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.1.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.0.2.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.0.2.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.2.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.0.2.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.0.2.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for module.backbone.stages.1.0.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.1.0.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.0.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.0.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.0.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.0.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.0.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.0.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.1.0.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.0.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.1.1.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.1.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.1.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.1.1.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.1.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.1.2.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.1.2.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.2.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.1.2.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.1.2.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for module.backbone.stages.2.0.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.0.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.0.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.0.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.0.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.0.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.0.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.0.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.0.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.0.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.1.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.1.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.1.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.1.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.1.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.2.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.2.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.2.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.2.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.2.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.3.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.3.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.3.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.3.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.3.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.4.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.4.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.4.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.4.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.4.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.5.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.5.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.5.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.5.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.5.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.6.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.6.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.6.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.6.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.6.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.7.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.7.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.7.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.7.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.7.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.2.8.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.2.8.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.8.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for module.backbone.stages.2.8.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for module.backbone.stages.2.8.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for module.backbone.stages.3.0.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.3.0.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.0.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.0.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.0.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.0.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.0.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.0.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for module.backbone.stages.3.0.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.0.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.3.1.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.1.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.1.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for module.backbone.stages.3.1.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.1.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for module.backbone.stages.3.2.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.stages.3.2.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.2.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for module.backbone.stages.3.2.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for module.backbone.stages.3.2.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.backbone.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for module.head.final_layer.weight: copying a param with shape torch.Size([1152, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 256, 1, 1]).\n\tsize mismatch for module.head.final_layer.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([576]).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-955a9c30cf2f>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mtester\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_batch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHECKPOINT_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nüöÄ Ejecutando testing en epoch {CHECKPOINT_EPOCH}...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/ConvNeXtPose/main/../common/base.py\u001b[0m in \u001b[0;36m_make_model\u001b[0;34m(self, test_epoch)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;31m# Intentar carga con state dict remapeado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremapped_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úì Checkpoint remapeado cargado exitosamente (strict=False)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2586\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ConvNeXtPose:\n\tsize mismatch for backbone.downsample_layers.0.0.weight: copying a param with shape torch.Size([48, 3, 4, 4]) from checkpoint, the shape in current model is torch.Size([192, 3, 4, 4]).\n\tsize mismatch for backbone.downsample_layers.0.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.0.1.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.0.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.downsample_layers.1.1.weight: copying a param with shape torch.Size([96, 48, 2, 2]) from checkpoint, the shape in current model is torch.Size([384, 192, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.1.1.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.0.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.downsample_layers.2.1.weight: copying a param with shape torch.Size([192, 96, 2, 2]) from checkpoint, the shape in current model is torch.Size([768, 384, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.2.1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.0.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.downsample_layers.3.1.weight: copying a param with shape torch.Size([384, 192, 2, 2]) from checkpoint, the shape in current model is torch.Size([1536, 768, 2, 2]).\n\tsize mismatch for backbone.downsample_layers.3.1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.0.0.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.0.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.0.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.0.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.0.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.0.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.1.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.1.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.1.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.1.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.1.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.dwconv.weight: copying a param with shape torch.Size([48, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([192, 1, 7, 7]).\n\tsize mismatch for backbone.stages.0.2.dwconv.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.running_mean: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.norm.running_var: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.0.2.pwconv1.weight: copying a param with shape torch.Size([192, 48, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 192, 1, 1]).\n\tsize mismatch for backbone.stages.0.2.pwconv1.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.0.2.pwconv2.weight: copying a param with shape torch.Size([48, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([192, 768, 1, 1]).\n\tsize mismatch for backbone.stages.0.2.pwconv2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for backbone.stages.1.0.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.0.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.0.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.0.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.0.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.0.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.1.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.1.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.1.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.1.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.1.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.dwconv.weight: copying a param with shape torch.Size([96, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([384, 1, 7, 7]).\n\tsize mismatch for backbone.stages.1.2.dwconv.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.weight: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.running_mean: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.norm.running_var: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.1.2.pwconv1.weight: copying a param with shape torch.Size([384, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 384, 1, 1]).\n\tsize mismatch for backbone.stages.1.2.pwconv1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.1.2.pwconv2.weight: copying a param with shape torch.Size([96, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([384, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.1.2.pwconv2.bias: copying a param with shape torch.Size([96]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for backbone.stages.2.0.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.0.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.0.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.0.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.0.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.0.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.1.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.1.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.1.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.1.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.1.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.2.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.2.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.2.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.2.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.2.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.3.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.3.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.3.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.3.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.3.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.4.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.4.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.4.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.4.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.4.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.5.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.5.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.5.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.5.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.5.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.6.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.6.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.6.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.6.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.6.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.7.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.7.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.7.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.7.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.7.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.dwconv.weight: copying a param with shape torch.Size([192, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([768, 1, 7, 7]).\n\tsize mismatch for backbone.stages.2.8.dwconv.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.weight: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.running_mean: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.norm.running_var: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.2.8.pwconv1.weight: copying a param with shape torch.Size([768, 192, 1, 1]) from checkpoint, the shape in current model is torch.Size([3072, 768, 1, 1]).\n\tsize mismatch for backbone.stages.2.8.pwconv1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for backbone.stages.2.8.pwconv2.weight: copying a param with shape torch.Size([192, 768, 1, 1]) from checkpoint, the shape in current model is torch.Size([768, 3072, 1, 1]).\n\tsize mismatch for backbone.stages.2.8.pwconv2.bias: copying a param with shape torch.Size([192]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for backbone.stages.3.0.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.0.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.0.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.0.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.0.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.0.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.1.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.1.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.1.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.1.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.1.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.dwconv.weight: copying a param with shape torch.Size([384, 1, 7, 7]) from checkpoint, the shape in current model is torch.Size([1536, 1, 7, 7]).\n\tsize mismatch for backbone.stages.3.2.dwconv.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.stages.3.2.pwconv1.weight: copying a param with shape torch.Size([1536, 384, 1, 1]) from checkpoint, the shape in current model is torch.Size([6144, 1536, 1, 1]).\n\tsize mismatch for backbone.stages.3.2.pwconv1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([6144]).\n\tsize mismatch for backbone.stages.3.2.pwconv2.weight: copying a param with shape torch.Size([384, 1536, 1, 1]) from checkpoint, the shape in current model is torch.Size([1536, 6144, 1, 1]).\n\tsize mismatch for backbone.stages.3.2.pwconv2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.running_mean: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for backbone.norm.running_var: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([1536]).\n\tsize mismatch for head.final_layer.weight: copying a param with shape torch.Size([1152, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([576, 256, 1, 1]).\n\tsize mismatch for head.final_layer.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([576])."
     ]
    }
   ],
   "source": [
    "# Testing con estructura correcta del proyecto\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. Cambiar al directorio main (donde est√° config.py)\n",
    "os.chdir('/kaggle/working/ConvNeXtPose/main')\n",
    "\n",
    "# 2. Importar config PRIMERO - esto configura autom√°ticamente los paths\n",
    "from config import cfg\n",
    "\n",
    "# 3. Cargar variante ANTES de importar otros m√≥dulos\n",
    "VARIANT = 'XS'  # ‚úÖ CORREGIDO: Checkpoint real es XS (dims=[48,96,192,384], depths=[3,3,9,3])\n",
    "# NOTA IMPORTANTE: Los archivos descargados como 'L', 'M', y 'S' contienen TODOS arquitectura XS\n",
    "# El an√°lisis de log3.txt confirm√≥: checkpoint tiene dims=[48,96,192,384] y solo 9 bloques en stage 2\n",
    "# Ver CHECKPOINT_ARCHITECTURE_ANALYSIS.md para detalles completos\n",
    "CHECKPOINT_EPOCH = 83  # ‚Üê AJUSTAR seg√∫n tu checkpoint\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  Testing ConvNeXtPose-{VARIANT}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "cfg.load_variant_config(VARIANT)\n",
    "cfg.set_args('0')  # GPU 0\n",
    "\n",
    "# 4. AHORA importar los dem√°s m√≥dulos (config ya configur√≥ sys.path)\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from base import Tester\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configurar CUDA solo si est√° disponible\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = False\n",
    "    cudnn.enabled = True\n",
    "    print(\"‚úÖ CUDA habilitado\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Ejecutando en CPU (ser√° muy lento)\")\n",
    "\n",
    "# 5. Crear tester y ejecutar\n",
    "tester = Tester()\n",
    "tester._make_batch_generator()\n",
    "tester._make_model(CHECKPOINT_EPOCH)\n",
    "\n",
    "print(f\"\\nüöÄ Ejecutando testing en epoch {CHECKPOINT_EPOCH}...\\n\")\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for itr, input_img in enumerate(tqdm(tester.batch_generator)):\n",
    "        coord_out = tester.model(input_img)\n",
    "        \n",
    "        if cfg.flip_test:\n",
    "            from utils.pose_utils import flip\n",
    "            flipped_input_img = flip(input_img, dims=3)\n",
    "            flipped_coord_out = tester.model(flipped_input_img)\n",
    "            flipped_coord_out[:, :, 0] = cfg.output_shape[1] - flipped_coord_out[:, :, 0] - 1\n",
    "            for pair in tester.flip_pairs:\n",
    "                flipped_coord_out[:, pair[0], :], flipped_coord_out[:, pair[1], :] = \\\n",
    "                    flipped_coord_out[:, pair[1], :].clone(), flipped_coord_out[:, pair[0], :].clone()\n",
    "            coord_out = (coord_out + flipped_coord_out)/2.\n",
    "        \n",
    "        coord_out = coord_out.cpu().numpy()\n",
    "        preds.append(coord_out)\n",
    "\n",
    "# Evaluar\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "print(f\"\\nüìä Evaluando {len(preds)} predicciones...\\n\")\n",
    "tester._evaluate(preds, cfg.result_dir)\n",
    "\n",
    "print(f\"\\n‚úÖ Testing completado!\")\n",
    "print(f\"üìÇ Resultados guardados en: {cfg.result_dir}\")\n",
    "print(f\"\\nüí° MPJPE esperado para XS: ~52.0 mm (Protocol 2)\")\n",
    "print(f\"üí° PA-MPJPE esperado para XS: ~36.5 mm (Protocol 1)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo M (Medium) - Opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-14T13:10:45.080382Z",
     "iopub.status.idle": "2025-10-14T13:10:45.080744Z",
     "shell.execute_reply": "2025-10-14T13:10:45.080576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Si tienes el checkpoint del modelo M, ejecuta esto:\n",
    "# !python test.py --gpu 0 --epochs {CHECKPOINT_EPOCH} --variant M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä PASO 5: Verificar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-14T13:10:45.081816Z",
     "iopub.status.idle": "2025-10-14T13:10:45.082089Z",
     "shell.execute_reply": "2025-10-14T13:10:45.081984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Ver resultados generados\n",
    "%cd ..\n",
    "!ls -lh output/result/\n",
    "\n",
    "# Leer log de resultados\n",
    "import glob\n",
    "log_files = glob.glob('output/log/*.log')\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    print(f\"\\nüìÑ √öltimas l√≠neas del log ({os.path.basename(latest_log)}):\")\n",
    "    !tail -n 20 {latest_log}\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No se encontraron logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà PASO 6: An√°lisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-14T13:10:45.082667Z",
     "iopub.status.idle": "2025-10-14T13:10:45.082913Z",
     "shell.execute_reply": "2025-10-14T13:10:45.082809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_mpjpe_from_log(log_path):\n",
    "    \"\"\"Extrae el MPJPE del log\"\"\"\n",
    "    with open(log_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Buscar patr√≥n de MPJPE\n",
    "    pattern = r'MPJPE.*?(\\d+\\.\\d+)'\n",
    "    matches = re.findall(pattern, content)\n",
    "    \n",
    "    if matches:\n",
    "        return float(matches[-1])  # √öltimo valor\n",
    "    return None\n",
    "\n",
    "# Extraer resultados\n",
    "log_files = glob.glob('output/log/*.log')\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    mpjpe = extract_mpjpe_from_log(latest_log)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"  üìä RESULTADOS FINALES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if mpjpe:\n",
    "        print(f\"\\n  MPJPE (Protocol 2): {mpjpe:.2f} mm\")\n",
    "        \n",
    "        # Comparar con paper\n",
    "        expected = {\n",
    "            'L': 42.3,\n",
    "            'M': 44.6\n",
    "        }\n",
    "        \n",
    "        # Determinar variante\n",
    "        for variant, expected_val in expected.items():\n",
    "            diff = abs(mpjpe - expected_val)\n",
    "            if diff < 5:\n",
    "                print(f\"\\n  Variante detectada: {variant}\")\n",
    "                print(f\"  Valor del paper: {expected_val:.2f} mm\")\n",
    "                print(f\"  Diferencia: {mpjpe - expected_val:+.2f} mm\")\n",
    "                \n",
    "                if diff < 2:\n",
    "                    print(\"  ‚úÖ Resultado excelente (dentro de ¬±2mm)\")\n",
    "                elif diff < 5:\n",
    "                    print(\"  ‚úì Resultado aceptable (dentro de ¬±5mm)\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No se pudo extraer MPJPE del log\")\n",
    "        print(\"Revisa el log manualmente en output/log/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"‚ùå No se encontraron logs de testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ PASO 7: Guardar Outputs\n",
    "\n",
    "Kaggle guarda autom√°ticamente todo en `/kaggle/working/`. Opcionalmente puedes copiar resultados espec√≠ficos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-14T13:10:45.083818Z",
     "iopub.status.idle": "2025-10-14T13:10:45.084254Z",
     "shell.execute_reply": "2025-10-14T13:10:45.084055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Crear resumen de resultados\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model': 'ConvNeXtPose-XS',  # ‚úÖ CORREGIDO: Checkpoint real es XS\n",
    "    'checkpoint_epoch': CHECKPOINT_EPOCH,\n",
    "    'dataset': 'Human3.6M Protocol 2',\n",
    "    'mpjpe_mm': mpjpe if 'mpjpe' in locals() else None,\n",
    "    'expected_mpjpe_mm': 52.0,  # Valor esperado para XS\n",
    "    'expected_pa_mpjpe_mm': 36.5,  # Valor esperado para XS (Protocol 1)\n",
    "    'architecture': {\n",
    "        'dims': [48, 96, 192, 384],\n",
    "        'depths': [3, 3, 9, 3],\n",
    "        'head': '2-UP (2 deconv layers)'\n",
    "    },\n",
    "    'pytorch_version': torch.__version__,\n",
    "    'cuda_version': torch.version.cuda if torch.cuda.is_available() else None,\n",
    "    'note': 'Checkpoints etiquetados como L/M/S contienen arquitectura XS. Ver CHECKPOINT_ARCHITECTURE_ANALYSIS.md'\n",
    "}\n",
    "\n",
    "# Guardar resumen\n",
    "with open('output/result/test_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"‚úì Resumen guardado en output/result/test_summary.json\")\n",
    "print(\"\\nüìÑ Contenido:\")\n",
    "print(json.dumps(summary, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Testing Completado!\n",
    "\n",
    "Los resultados est√°n en:\n",
    "- **Logs**: `output/log/`\n",
    "- **Resultados**: `output/result/`\n",
    "- **Resumen JSON**: `output/result/test_summary.json`\n",
    "\n",
    "Todos los archivos en `/kaggle/working/ConvNeXtPose/output/` se guardar√°n autom√°ticamente cuando hagas commit del notebook."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2200515,
     "sourceId": 5116687,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8460258,
     "sourceId": 13341353,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
